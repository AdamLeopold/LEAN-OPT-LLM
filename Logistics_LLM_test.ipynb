{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 16:40:01.966 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# pip install streamlit langchain openai faiss-cpu tiktoken\n",
    "\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "import tempfile\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import pandas as pd\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "import re\n",
    "from datetime import datetime, time\n",
    "\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import openai\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "user_api_key=\"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\"\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2', 'true')\n",
    "langchain_endpoint = os.getenv('LANGCHAIN_ENDPOINT', 'https://api.smith.langchain.com')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = langchain_tracing_v2\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = langchain_endpoint\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v1/1q5tbbdj0rn4wmlrxzfr2xxc0000gn/T/ipykernel_2411/952628972.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm1 = ChatOpenAI(\n",
      "/var/folders/v1/1q5tbbdj0rn4wmlrxzfr2xxc0000gn/T/ipykernel_2411/952628972.py:14: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
      "/var/folders/v1/1q5tbbdj0rn4wmlrxzfr2xxc0000gn/T/ipykernel_2411/952628972.py:75: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "llm1 = ChatOpenAI(\n",
    "    temperature=0.0, model_name=\"gpt-4o\", openai_api_key=user_api_key\n",
    ")\n",
    "\n",
    "# Load and process the data\n",
    "loader = CSVLoader(file_path=\"RAG_doc2.csv\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "\n",
    "# Each line is a document\n",
    "documents = data\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "vectors = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vectors.as_retriever()\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm1,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a tool using the RetrievalQA chain\n",
    "qa_tool = Tool(\n",
    "    name=\"FileQA\",\n",
    "    func=qa_chain.invoke,\n",
    "    description=(\n",
    "        \"Use this tool to answer questions about the problem type of the text. \"\n",
    "        \"Provide the question as input, and the tool will retrieve the relevant information from the file and use it to answer the question.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define few-shot examples as a string\n",
    "few_shot_examples = \"\"\"\n",
    "\n",
    "Question: What is the problem type in operation of the text? Please give the answer directly. Text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1,w_2,w_3.There is an independent demand stream for each of the products. The objective of the company is to decide which demands to be fufilled over a ﬁnite sales horizon [0,10] to maximize the total expected revenue from ﬁxed initial inventories. The on-hand inventories for the three items are c_1,c_2,c_3 respectively. During the sales horizon, replenishment is not allowed and there is no any in-transit inventories. Customers who want to purchase P1,P2,P3 arrive at each period accoring to a Poisson process with a_1,a_2,a_3 the arrival rates respectively. Decision variables y_1,y_2,y_3 correspond to the number of requests that the firm plans to fulfill for product 1,2,3. These variables are all positive integers.\n",
    "\n",
    "Thought: I need to determine the problem type of the text. I'll use the FileQA tool to retrieve the relevant information.\n",
    "\n",
    "Action: FileQA\n",
    "\n",
    "Action Input: \"What is the problem type in operation of the text? text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1, w_2, w_3. ...\"\n",
    "\n",
    "Observation: The problem type of the text is Network Revenue Management.\n",
    "\n",
    "Final Answer: Network Revenue Management.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create the prefix and suffix for the agent's prompt\n",
    "prefix = f\"\"\"You are a helpful assistant that can answer questions about operation problems. \n",
    "\n",
    "Use the following examples as a guide. Always use the FileQA tool when you need to retrieve information from the file:\n",
    "\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "When you need to find information from the file, use the provided tools. And answer the question by given the answer directly. For example,\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm1,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix.format(few_shot_examples=few_shot_examples),\n",
    "        \"suffix\": suffix,\n",
    "    },\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # Enable error handling\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "openai.api_request_timeout = 60  # 将超时时间设置为60秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa1 in position 22277: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogisticsLLM_test_nrm2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#test=test[8:9]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m test\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:636\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:1965\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa1 in position 22277: invalid start byte"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('LogisticsLLM_test_nrm2.csv')\n",
    "#test=test[8:9]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to determine the problem type of the text. I'll use the FileQA tool to retrieve the relevant information.\n",
      "\n",
      "Action: FileQA\n",
      "\n",
      "Action Input: \"What is the problem type in operation of the text? text:Zara offers a variety of popular products, each with its own independent demand stream. The data associated with these products is provided in the 'Revenue' column. ...\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'query': 'What is the problem type in operation of the text? text:Zara offers a variety of popular products, each with its own independent demand stream. The data associated with these products is provided in the \\'Revenue\\' column. ...\"\\n', 'result': 'The problem type in the operation of the text is a \"Network Revenue Management Problem.\"', 'source_documents': [Document(metadata={'source': 'RAG_doc2.csv', 'row': 3}, page_content=\"\\ufeffproblem type: Network Revenue Management Problem\\ntemplate id: 2\\ntext: There are three popular items (M1,M2, M3) in a local supermarket, each with a profit margin of w_1, w_2, and w_3 respectively. Each product has its own independent demand stream. The supermarket's goal is to determine which customer demands to meet over a fixed sales period [0,20] to maximize the total expected revenue based on the current stock levels. The inventory capacity for these three items is c_1, c_2, and c_3 respectively. During the sales period, restocking is not possible, and there are no goods currently being shipped. Customers who wish to buy P1, P2, and P3 arrive during each period following a Poisson process, with arrival rates of a_1, a_2, and a_3 respectively. The decision variables y_1, y_2, and y_3 represent the number of requests the supermarket plans to fulfill for products 1, 2, and 3, respectively. These decision variables must be positive integers.\\ninformation: Profit information: w_1 = 31,w_2 = 42,w_3 = 67; Inventory information: c_1 = 372, c_2 = 465, c_3 =892; Demand information: a_1 = 15, a_2 = 20, a_3 = 40.\\nlabel: max 31 42 67; 1 0 0 <= 372; 0 1 0 <= 465; 0 0 1 <= 892; 1 0 0 <= 300; 0 1 0 <= 400; 0 0 1 <= 800; Z+ Z+ Z+\"), Document(metadata={'source': 'RAG_doc2.csv', 'row': 2}, page_content='\\ufeffproblem type: Network Revenue Management Problem\\ntemplate id: 1\\ntext: There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1,w_2,w_3.There is an independent demand stream for each of the products. The objective of the company is to decide which demands to be fufilled over a 铿_ite sales horizon [0,10] to maximize the total expected revenue from 铿_ed initial inventories. The on-hand inventories for the three items are c_1,c_2,c_3 respectively. During the sales horizon, replenishment is not allowed and there is no any in-transit inventories. Customers who want to purchase P1,P2,P3 arrive at each period accoring to a Poisson process with a_1,a_2,a_3 the arrival rates respectively. Decision variables y_1,y_2,y_3 correspond to the number of requests that the firm plans to fulfill for product 1,2,3. These variables are all positive integers.\\ninformation: Profit information: w_1 = 20,w_2 = 10,w_3 = 30; Inventory information: c_1 = 50, c_2 = 70, c_3 =30; Demand information: a_1 = 3, a_2 = 8, a_3 = 2.\\nlabel: max 20 10 30; 1 0 0 <= 50; 0 1 0 <= 70; 0 0 1 <= 30; 1 0 0 <= 30; 0 1 0 <= 80; 0 0 1<= 20; Z+ Z+ Z+'), Document(metadata={'source': 'RAG_doc2.csv', 'row': 0}, page_content=\"\\ufeffproblem type: Network Revenue Management Problem\\ntemplate id: 9\\ntext: In a well-known coffee shop, there are two signature drinks (D1 and D2), each bringing in a profit of w_1 and w_2 respectively. The demand for each drink varies independently. The coffee shop's goal is to decide which customer orders to fulfill during a specific busy period [0,10] to maximize the total expected revenue, based on the available ingredients. The current inventory for these drinks is c_1 and c_2 respectively. During this period, restocking is not possible, and no additional supplies are expected. Customers interested in ordering D1 and D2 arrive at the shop according to a Poisson process, with arrival rates a_1 and a_2 respectively. The decision variables y_1 and y_2 represent the number of orders the coffee shop plans to fulfill for each of the two drinks, and these variables must be positive integers.\\ninformation: Profit information: w_1 = 30, w_2 = 19.8; Inventory information: c_1 = 72, c_2 = 68; Demand information: a_1 = 6, a_2 = 8.\\nlabel: max 30 19.8; 1 0 <= 72; 0 1 <= 68; 1 0 <= 60; 0 1 <= 80; Z+ Z+\"), Document(metadata={'source': 'RAG_doc2.csv', 'row': 1}, page_content=\"\\ufeffproblem type: Network Revenue Management Problem\\ntemplate id: 10\\ntext: In a popular bakery, there are three specialty pastries (S1, S2, S3), each offering a profit of w_1, w_2, and w_3 respectively. The demand for each pastry is distinct and varies from customer to customer. The bakery's goal is to determine which customer orders to fulfill during a single busy morning to maximize the total revenue, based on the limited quantity of pastries available. The current stock for these pastries is c_1, c_2, and c_3 respectively. Restocking is not an option during this period, and no additional batches will be made. Customers looking to purchase P1, P2, and P3 arrive at the bakery according to a Poisson process, with arrival rates a_1, a_2, and a_3 respectively. The decision variables y_1, y_2, and y_3 represent the number of orders the bakery plans to fulfill for each of the three pastries, and these must be positive integers.\\ninformation: Profit information: w_1 = 20.5,w_2 = 8.8,w_3 = 29.7; Inventory information: c_1 = 48, c_2 = 71, c_3 =30; Demand information: a_1 = 31, a_2 = 80, a_3 = 29.\\nlabel: max 20.5 8.8 29.7; 1 0 0 <= 48; 0 1 0 <= 71; 0 0 1 <= 30; 1 0 0 <= 31; 0 1 0 <= 80; 0 0 1 <= 29; Z+ Z+ Z+\")]}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The problem type in the operation of the text is a \"Network Revenue Management Problem.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Based on the provided description and data, please formulate a linear programming model. The data of the store offers several styles of Zara products is provided in the CSV file. The revenue of each product is listed in the column \"Revenue\". The demand for each style is independent. The retailer's objective is to maximize the total expected revenue based on the fixed initial inventories of the products classified under 'sku_2', which are detailed in the column \"Initial Inventory\". During the sales horizon, no restocking is allowed, and there are no in-transit inventories. Customer inquiries for 'sku_2' products arrive sequentially, following a Poisson process, with demand information specified in the column \"Demand\". The decision variables x_i represent the number of units of each 'sku_2' product i that Zara plans to fulfill, with each x_i being a positive integer.\n",
      "\n",
      "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to sku_2 to formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on a product with the name \"sku_2\" in the provided context. If you have more specific details or another product name, I might be able to help.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any specific product data related to 'sku_2' in the context provided. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any product with the identifier 'sku_2' in the provided context. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any product with the identifier 'sku_2' in the provided context. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any product with the identifier 'sku_2' in the provided context. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any product with the identifier 'sku_2' in the provided context. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to clarify the product classification or identifier to retrieve the correct data from the CSV file. The term \"sku_2\" might not be directly available in the dataset, or it might be labeled differently. I should check for any alternative identifiers or categories that could correspond to \"sku_2\" in the dataset.\n",
      "\n",
      "Action: CSVQA\n",
      "\n",
      "Action Input: \"Retrieve the product data related to Zara products to identify any potential matches for 'sku_2' and formulate the linear programming model.\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have any information on Zara products or any specific product data related to 'sku_2' in the context provided. Therefore, I cannot formulate a linear programming model for it. If you have more specific data or context, please provide it, and I will do my best to assist you.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that there is a lack of specific data or context regarding the \"sku_2\" products in the provided dataset. Without the necessary data, I am unable to formulate a linear programming model for the Zara products as described. If you can provide more detailed information or a different identifier that might be present in the dataset, I would be able to assist you further. Alternatively, if there is another dataset or specific details you can share, please do so, and I will do my best to help.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent stopped due to iteration limit or time limit.\n"
     ]
    }
   ],
   "source": [
    "for index, row in test.iterrows():\n",
    "    text = row['Query']\n",
    "    response = agent.invoke(f\"What is the problem type in operation of the text? text:{text}\")\n",
    "    \n",
    "    def extract_problem_type(output_text):\n",
    "    # 定义正则表达式模式，匹配问题类型\n",
    "        pattern = r'(Network Revenue Management|Resource Allocation|Transportation|其他问题类型)'\n",
    "        match = re.search(pattern, output_text, re.IGNORECASE)\n",
    "        return match.group(0) if match else None\n",
    "\n",
    "    selected_problem = extract_problem_type(response['output'])\n",
    "    \n",
    "    # 根据用户的选择，执行相应的代码\n",
    "    if selected_problem == \"Network Revenue Management\":\n",
    "\n",
    "        information = pd.read_csv('NRM_example/nike Shoes Sales.csv')\n",
    "        information_head = information[:36]\n",
    "\n",
    "        # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "        example_data_description = \"\\nHere is the product data:\\n\"\n",
    "        for i, r in information_head.iterrows():\n",
    "            example_data_description += f\"Product {i + 1}: {r['Product Name']}, revenue w_{i + 1} = {r['Revenue']}, demand rate a_{i + 1} = {r['Demand']}, initial inventory c_{i + 1} = {r['Initial Inventory']}\\n\"\n",
    "        \n",
    "\n",
    "        problem_description = 'The data of the store offers several styles of Nike shoes is provided in \"Nike Shoes Sales.csv\". Through the dataset, the revenue of each shoes is listed in the column \"revenue\". The demand for each style is independent. The store’s objective is to maximize the total expected revenue based on the fixed initial inventories of the Nike x Olivia Kim brand, which are detailed in column “inventory.” During the sales horizon, no replenishment is allowed, and there are no in-transit inventories. Customer arrivals, corresponding to demand for different styles of Nike shoes, occur in each period according to a Poisson process, with arrival rates specified in column “demand.” Moreover, the trade will be started only when the total demand is no less than 100 to ensure the trading efficiency. The decision variables y_i represent the number of customer requests the store intends to fulfill for Nike shoe style i, with each y_i being a positive integer.'\n",
    "\n",
    "        label = \"\"\"\n",
    "        Maximize\n",
    "           11197 x_1 + 9097 x_2 + 11197 x_3 + 9995 x_4\n",
    "        Subject To\n",
    "           inventory_constraint: \n",
    "           x_1 <= 97\n",
    "           x_2 <= 240\n",
    "           x_3 <= 322\n",
    "           x_4 <= 281\n",
    "           demand_constraint: \n",
    "           x_1 <= 17\n",
    "           x_2 <= 26\n",
    "           x_3 <= 50\n",
    "           x_4 <= 53\n",
    "           startup_constraint:\n",
    "           x_1+x_2+x_3+x_4 >=100\n",
    "        Where\n",
    "        x_i represents the number of customer requests the store intends to fulfill for Nike x Olivia Kim shoe style i, with each x_i being a positive integer.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        few_shot_examples = f\"\"\"\n",
    "\n",
    "        Question: Based on the following description and data, please formulate a linear programming model. {problem_description}\n",
    "\n",
    "        Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file.\n",
    "\n",
    "        Action: CSVQA\n",
    "\n",
    "        Action Input: \"Retrieve the product data related to Nike x OliviaKim to formulate the linear programming model.\"\n",
    "\n",
    "        Observation:\n",
    "\n",
    "        Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Nike x Olivia Kim' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "        Final Answer: \n",
    "        {label}\n",
    "        \"\"\"\n",
    "\n",
    "        # 加载实际的 CSV 文件\n",
    "\n",
    "        # 创建嵌入和向量存储\n",
    "        data = []\n",
    "        dfs=[]\n",
    "        \n",
    "        file_addresses = row['Dataset_address'].strip().split('\\n')\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                # 读取文件并添加到 dfs 列表\n",
    "                df = pd.read_csv(file_address)  # 如果是 Excel 文件，可用 pd.read_excel\n",
    "                file_name = file_address.split('/')[-1]  # 提取文件名\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        \n",
    "        for df_index, (file_name, df) in enumerate(dfs):\n",
    "            # 将文件名添加到描述中\n",
    "            data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "                \n",
    "        documents = [content for content in data]\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "        vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "        num_documents = len(documents)\n",
    "\n",
    "        # 创建检索器和 RetrievalQA 链\n",
    "        retriever = vectors.as_retriever(search_kwargs={'k': 250})\n",
    "        llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4o', openai_api_key=user_api_key)\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm2,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "        )\n",
    "\n",
    "        # 创建工具（Tool）\n",
    "        qa_tool = Tool(\n",
    "            name=\"CSVQA\",\n",
    "            func=qa_chain.run,\n",
    "            description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query.\"\n",
    "        )\n",
    "\n",
    "        # 更新 Agent 的提示（Prompt）\n",
    "        prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "        Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "        {few_shot_examples}\n",
    "\n",
    "        When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        suffix = \"\"\"\n",
    "\n",
    "        Begin!\n",
    "\n",
    "        User Description: {input}\n",
    "        {agent_scratchpad}\"\"\"\n",
    "\n",
    "        # 初始化 Agent\n",
    "        agent2 = initialize_agent(\n",
    "            tools=[qa_tool],\n",
    "            llm=llm2,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            agent_kwargs={\n",
    "                \"prefix\": prefix,\n",
    "                \"suffix\": suffix,\n",
    "            },\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "        )\n",
    "\n",
    "        def conversational_chat(query):\n",
    "\n",
    "            result = agent2.invoke(query)\n",
    "            return result['output']\n",
    "        \n",
    "        \n",
    "        output = conversational_chat(row['Query'])\n",
    "        print(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    if selected_problem == \"Resource Allocation\":\n",
    "        \n",
    "        \n",
    "        informationC = pd.read_csv('RA_example/Capacity.csv')\n",
    "        informationP = pd.read_csv('RA_example/Products.csv')\n",
    "        information=[]\n",
    "        information.append(informationC)\n",
    "        information.append(informationP)\n",
    "\n",
    "\n",
    "        # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "        example_data_description = \"\\nHere is the data:\\n\"\n",
    "\n",
    "        # 遍历每个 DataFrame 及其索引\n",
    "        for df_index, df in enumerate(information):\n",
    "            if df_index==0:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
    "            elif df_index==1:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
    "\n",
    "            # 遍历 DataFrame 的每一行并生成描述\n",
    "            for i, r in df.iterrows():\n",
    "                description=\"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                example_data_description += description + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "        # 构建 problem_description 和 label\n",
    "        problem_description = 'A supermarket needs to allocate various products, including high-demand items like the Sony Alpha Refrigerator, Sony Bravia XR, and Sony PlayStation 5, across different retail shelves. The product values and space requirements are provided in the \"Products.csv\" dataset. Additionally, the store has multiple shelves, each with a total space limit and specific space constraints for Sony and Apple products, as outlined in the \"Capacity.csv\" file. The goal is to determine the optimal number of units of each Sony product to place on each shelf to maximize total value while ensuring that the space used by Sony products on each shelf does not exceed the brand-specific limits. The decision variables x_ij represent the number of units of product i to be placed on shelf j.'\n",
    "\n",
    "        with open('RA_example/Sony.txt', 'r', encoding='utf-8') as file:\n",
    "            label = file.read()\n",
    "\n",
    "        few_shot_examples = f\"\"\"\n",
    "\n",
    "                Question: Based on the following description and data, please formulate a linear programming model. {problem_description}\n",
    "\n",
    "                Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "                Action: CSVQA\n",
    "\n",
    "                Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "                Observation: {example_data_description}\n",
    "\n",
    "                Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Sony' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "                Final Answer: \n",
    "                {label}\n",
    "                \"\"\"\n",
    "\n",
    "        # 加载实际的 CSV 文件\n",
    "        data = []\n",
    "        dfs=[]\n",
    "        \n",
    "        file_addresses = row['Dataset_address'].strip().split('\\n')\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                # 读取文件并添加到 dfs 列表\n",
    "                df = pd.read_csv(file_address)  # 如果是 Excel 文件，可用 pd.read_excel\n",
    "                file_name = file_address.split('/')[-1]  # 提取文件名\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        \n",
    "        for df_index, (file_name, df) in enumerate(dfs):\n",
    "            # 将文件名添加到描述中\n",
    "            data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "\n",
    "        documents = [content for content in data]\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "        vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "        num_documents = len(documents)\n",
    "\n",
    "        # 创建检索器和 RetrievalQA 链\n",
    "        retriever = vectors.as_retriever(search_kwargs={'k': 220})\n",
    "        llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4o', openai_api_key=user_api_key)\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm2,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "        )\n",
    "\n",
    "        # 创建工具（Tool）\n",
    "        qa_tool = Tool(\n",
    "            name=\"CSVQA\",\n",
    "            func=qa_chain.run,\n",
    "            description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "        )\n",
    "\n",
    "        # 更新 Agent 的提示（Prompt）\n",
    "        prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "                Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "                {few_shot_examples}\n",
    "\n",
    "                When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "        suffix = \"\"\"\n",
    "\n",
    "                Begin!\n",
    "\n",
    "                User Description: {input}\n",
    "                {agent_scratchpad}\"\"\"\n",
    "\n",
    "        # 初始化 Agent\n",
    "        agent2 = initialize_agent(\n",
    "            tools=[qa_tool],\n",
    "            llm=llm2,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            agent_kwargs={\n",
    "                \"prefix\": prefix,\n",
    "                \"suffix\": suffix,\n",
    "            },\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "        )\n",
    "\n",
    "        def conversational_chat(query):\n",
    "\n",
    "            result = agent2.invoke(query)\n",
    "            return result['output']\n",
    "        \n",
    "        output = conversational_chat(row['Query'])\n",
    "        print(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    if selected_problem == \"Transportation\":\n",
    "\n",
    "        informationCustomer = pd.read_csv('TP_example/customer_demand.csv')\n",
    "        informationSupply = pd.read_csv('TP_example/supply_capacity.csv')\n",
    "        informationCost = pd.read_csv('TP_example/transportation_costs.csv')\n",
    "        information = []\n",
    "        information.append(informationCustomer)\n",
    "        information.append(informationSupply)\n",
    "        information.append(informationCost)\n",
    "\n",
    "        # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "        example_data_description = \"\\nHere is the data:\\n\"\n",
    "\n",
    "        # 遍历每个 DataFrame 及其索引\n",
    "        for df_index, df in enumerate(information):\n",
    "            if df_index == 0:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Customer Demand\\n\"\n",
    "            elif df_index == 1:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Supply Capacity\\n\"\n",
    "            elif df_index == 2:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Transportation Cost\\n\"\n",
    "\n",
    "            # 遍历 DataFrame 的每一行并生成描述\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                example_data_description += description + \"\\n\"\n",
    "\n",
    "        # 构建 problem_description 和 label\n",
    "\n",
    "        with open('TP_example/transportation_problem2.txt', 'r', encoding='utf-8') as file:\n",
    "            label = file.read()\n",
    "\n",
    "        few_shot_examples = f\"\"\"\n",
    "\n",
    "                Question: Based on the following transportation problem description and data, please formulate a complete linear programming model using real data from retrieval. {problem_description}\n",
    "\n",
    "                Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "                Action: CSVQA\n",
    "\n",
    "                Action Input: Retrieve the capacity data and products data to formulate the linear programming model.\n",
    "\n",
    "                Observation:\n",
    "\n",
    "                Thought: Now that I have the necessary data, I can construct the objective function and constraints. And the answer I generate should only be similar to the format below. The expressions should not be simplified or abbreviated.\n",
    "\n",
    "                Final Answer: \n",
    "                {label}\n",
    "                \"\"\"\n",
    "\n",
    "        data = []\n",
    "        dfs=[]\n",
    "        \n",
    "        file_addresses = row['Dataset_address'].strip().split('\\n')\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                # 读取文件并添加到 dfs 列表\n",
    "                df = pd.read_csv(file_address)  # 如果是 Excel 文件，可用 pd.read_excel\n",
    "                file_name = file_address.split('/')[-1]  # 提取文件名\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        \n",
    "        for df_index, (file_name, df) in enumerate(dfs):\n",
    "            # 将文件名添加到描述中\n",
    "            data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "            for i, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "\n",
    "        documents = [content for content in data]\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "        vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "        num_documents = len(documents)\n",
    "\n",
    "        # 创建检索器和 RetrievalQA 链\n",
    "        retriever = vectors.as_retriever(search_kwargs={'k': 250})\n",
    "        llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm2,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "        )\n",
    "\n",
    "        # 创建工具（Tool）\n",
    "        qa_tool = Tool(\n",
    "            name=\"CSVQA\",\n",
    "            func=qa_chain.run,\n",
    "            description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "        )\n",
    "\n",
    "        # 更新 Agent 的提示（Prompt）\n",
    "        prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "                Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "                {few_shot_examples}\n",
    "\n",
    "                When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "        suffix = \"\"\"\n",
    "\n",
    "                Begin!\n",
    "\n",
    "                User Description: {input}\n",
    "                {agent_scratchpad}\"\"\"\n",
    "\n",
    "        # 初始化 Agent\n",
    "        agent2 = initialize_agent(\n",
    "            tools=[qa_tool],\n",
    "            llm=llm2,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            agent_kwargs={\n",
    "                \"prefix\": prefix,\n",
    "                \"suffix\": suffix,\n",
    "            },\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "        )\n",
    "\n",
    "        def conversational_chat(query):\n",
    "\n",
    "            result = agent2.invoke(query)\n",
    "            return result['output']\n",
    "        \n",
    "        output = conversational_chat(row['Query'])\n",
    "        print(output)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"Resource Allocation Problem\":\n",
    "\n",
    "#         informationC = pd.read_csv('RA_example/Capacity.csv')\n",
    "#         informationP = pd.read_csv('RA_example/Products.csv')\n",
    "#         information=[]\n",
    "#         information.append(informationC)\n",
    "#         information.append(informationP)\n",
    "\n",
    "\n",
    "#         # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the data:\\n\"\n",
    "#         # for index, row in informationC.iterrows():\n",
    "#         #     example_data_description += f\"platform id {index + 1}: {row['platform_id']}, capacity = {row['capacity']}\\n\"\n",
    "#         #\n",
    "#         # for index, row in informationP.iterrows():\n",
    "#         #     example_data_description += f\"genre {index + 1}: {row['genre']}, value = {row['value']}, memory requirement = {row['memory requirement']}\\n\"\n",
    "\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, df in enumerate(information):\n",
    "#             if df_index==0:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
    "#             elif df_index==1:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description=\"\"\n",
    "#     #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 example_data_description += description + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "#         # 构建 problem_description 和 label\n",
    "#         problem_description0 = problem_description = \"\"\"A digital game store needs to decide which games to list on different platforms, considering that these games belong to various brands such as Sony, Amazon, and Apple. Each platform has a limited memory capacity, with specific details provided in \"Capacity.csv.\" The predefined value and memory requirement of each game are available in \"Products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j to be listed on platform i. For example, x_12 denotes the number of units of a specific game product (e.g., Sony Alpha Refrigerator) to be listed on Platform 1.\"\"\"\n",
    "#         problem_description += example_data_description\n",
    "\n",
    "#         problem_description1 = 'A supermarket needs to allocate various products, including high-demand items like the Sony Alpha Refrigerator, Sony Bravia XR, and Sony PlayStation 5, across different retail shelves. The product values and space requirements are provided in the \"Products.csv\" dataset. Additionally, the store has multiple shelves, each with a total space limit and specific space constraints for Sony and Apple products, as outlined in the \"Capacity.csv\" file. The goal is to determine the optimal number of units of each Sony product to place on each shelf to maximize total value while ensuring that the space used by Sony products on each shelf does not exceed the brand-specific limits. The decision variables x_ij represent the number of units of product i to be placed on shelf j.'\n",
    "#         # label_head1 = \"\"\"\n",
    "#         #         Maximize\n",
    "#         #            11197 x_0 + 9097 x_1 + 11197 x_2 + 9995 x_3\n",
    "#         #         Subject To\n",
    "#         #          inventory_constraint: x_0 <= 97\n",
    "#         #          demand_constraint: x_0 <= 17\n",
    "#         #          x_1 <= 240\n",
    "#         #          x_1 <= 26\n",
    "#         #          x_2 <= 322\n",
    "#         #          x_2 <= 50\n",
    "#         #          x_3 <= 281\n",
    "#         #          x_3 <= 53\n",
    "#         #         \"\"\"\n",
    "\n",
    "#         with open('RA_example/Sony.txt', 'r', encoding='utf-8') as file:\n",
    "#             label = file.read()\n",
    "\n",
    "#         print(example_data_description)\n",
    "\n",
    "#         few_shot_examples = f\"\"\"\n",
    "\n",
    "#                 Question: {problem_description1}\n",
    "\n",
    "#                 Based on the above description and data, please formulate a linear programming model.\n",
    "\n",
    "#                 Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "#                 Action: CSVQA\n",
    "\n",
    "#                 Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "#                 Observation: {example_data_description}\n",
    "\n",
    "#                 Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Sony' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "#                 Final Answer: \n",
    "#                 {label}\n",
    "#                 \"\"\"\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "#             # 将文件名添加到描述中\n",
    "#             data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#     #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "#         # for line in data:\n",
    "#         #     st.text(line)  # 使用 Streamlit 显示内容\n",
    "#         #st.text(few_shot_examples)\n",
    "\n",
    "\n",
    "\n",
    "#         # df = pd.read_csv(tmp_file_path)\n",
    "#         #\n",
    "#         # # 创建嵌入和向量存储\n",
    "#         # data = []\n",
    "#         # for index, row in df.iterrows():\n",
    "#         #     content = f\"Product Name: {row['Product Name']}, Revenue: {row['Revenue']}, Demand: {row['Demand']}, Initial Inventory: {row['Initial Inventory']}\"\n",
    "#         #     data.append(content)\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 20})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "#                 Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         # 准备新的用户描述（不包含具体数据，让 Agent 自行检索）\n",
    "#         # user_description = 'A digital game store needs to decide which games to list on different platforms, considering that these games belong to various genres such as racing, sports, and others. Each platform has a limited memory capacity, with specific details provided in \"capacity.csv.\" The predefined value and memory requirement of each game are available in \"products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j (e.g.,sports) to be listed on platform i. For example, x_12 denotes the number of units of a specific genre of games (e.g., sports) to be listed on Platform 1.'\n",
    "\n",
    "#         # 运行 Agent 并获取答案\n",
    "#         # answer = agent.invoke(user_description)\n",
    "#         # print(\"Answer:\", answer['output'])\n",
    "\n",
    "#         memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "#         #    agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, memory=memory, verbose=True)\n",
    "\n",
    "#         def query_data(query):\n",
    "#             response = agent.invoke(query)\n",
    "#             return response\n",
    "\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\", placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                           key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"Knapsack Problem\":\n",
    "\n",
    "#         informationC = pd.read_csv('KP_example/KPcapacity.csv')\n",
    "#         informationP = pd.read_csv('KP_example/KPproducts.csv')\n",
    "#         information = []\n",
    "#         information.append(informationC)\n",
    "#         information.append(informationP)\n",
    "\n",
    "#         # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the data:\\n\"\n",
    "#         # for index, row in informationC.iterrows():\n",
    "#         #     example_data_description += f\"platform id {index + 1}: {row['platform_id']}, capacity = {row['capacity']}\\n\"\n",
    "#         #\n",
    "#         # for index, row in informationP.iterrows():\n",
    "#         #     example_data_description += f\"genre {index + 1}: {row['genre']}, value = {row['value']}, memory requirement = {row['memory requirement']}\\n\"\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, df in enumerate(information):\n",
    "#             if df_index == 0:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
    "#             elif df_index == 1:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 example_data_description += description + \"\\n\"\n",
    "\n",
    "#         # 构建 problem_description 和 label\n",
    "#         problem_description0 = problem_description = \"\"\"Amazon needs to allocate different types of air conditioning units across multiple warehouse storage areas. Each storage area has a specific capacity limit, which is provided in the \"KPcapacity.csv\". The value and size of each type of air conditioner are listed in the \"KPproduct.csv\". The objective is to determine the optimal number of each air conditioner type to store in each warehouse to maximize the total value across all storage areas. At the same time, the total space occupied by the units in each warehouse must not exceed its capacity limit. Decision variables represent the quantity of each air conditioner type stored in each warehouse.\"\"\"\n",
    "#         problem_description += example_data_description\n",
    "\n",
    "#         problem_description1 = 'Amazon needs to allocate different types of air conditioning units across multiple warehouse storage areas. Each storage area has a specific capacity limit, which is provided in the \"KPcapacity.csv\". The value and size of each type of air conditioner are listed in the \"KPproduct.csv\". The objective is to determine the optimal number of each air conditioner type to store in each warehouse to maximize the total value across all storage areas. At the same time, the total space occupied by the units in each warehouse must not exceed its capacity limit. Decision variables represent the quantity of each air conditioner type stored in each warehouse.'\n",
    "\n",
    "#         with open('KP_example/AmazonProductsSalesDataset2023.txt', 'r', encoding='utf-8') as file:\n",
    "#             label = file.read()\n",
    "\n",
    "#         few_shot_examples = f\"\"\"\n",
    "\n",
    "#                 Question: {problem_description1}\n",
    "\n",
    "#                 Based on the above description and data, please formulate a linear programming model.\n",
    "\n",
    "#                 Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "#                 Action: CSVQA\n",
    "\n",
    "#                 Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "#                 Observation: {example_data_description}\n",
    "\n",
    "#                 Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Nike x Olivia Kim' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "#                 Final Answer: \n",
    "#                 {label}\n",
    "#                 \"\"\"\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "#             # 将文件名添加到描述中\n",
    "#             data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "#         # for line in data:\n",
    "#         #     st.text(line)  # 使用 Streamlit 显示内容\n",
    "#         # st.text(few_shot_examples)\n",
    "\n",
    "#         # df = pd.read_csv(tmp_file_path)\n",
    "#         #\n",
    "#         # # 创建嵌入和向量存储\n",
    "#         # data = []\n",
    "#         # for index, row in df.iterrows():\n",
    "#         #     content = f\"Product Name: {row['Product Name']}, Revenue: {row['Revenue']}, Demand: {row['Demand']}, Initial Inventory: {row['Initial Inventory']}\"\n",
    "#         #     data.append(content)\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 40})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "#                 Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         # 准备新的用户描述（不包含具体数据，让 Agent 自行检索）\n",
    "#         # user_description = 'A digital game store needs to decide which games to list on different platforms, considering that these games belong to various genres such as racing, sports, and others. Each platform has a limited memory capacity, with specific details provided in \"capacity.csv.\" The predefined value and memory requirement of each game are available in \"products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j (e.g.,sports) to be listed on platform i. For example, x_12 denotes the number of units of a specific genre of games (e.g., sports) to be listed on Platform 1.'\n",
    "\n",
    "#         # 运行 Agent 并获取答案\n",
    "#         # answer = agent.invoke(user_description)\n",
    "#         # print(\"Answer:\", answer['output'])\n",
    "\n",
    "#         memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "#         #    agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, memory=memory, verbose=True)\n",
    "\n",
    "#         def query_data(query):\n",
    "#             response = agent.invoke(query)\n",
    "#             return response\n",
    "\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\",\n",
    "#                                             placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                             key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"Transportation Problem\":\n",
    "\n",
    "#         informationCustomer = pd.read_csv('TP_example/customer_demand.csv')\n",
    "#         informationSupply = pd.read_csv('TP_example/supply_capacity.csv')\n",
    "#         informationCost = pd.read_csv('TP_example/transportation_costs.csv')\n",
    "#         information = []\n",
    "#         information.append(informationCustomer)\n",
    "#         information.append(informationSupply)\n",
    "#         information.append(informationCost)\n",
    "\n",
    "#         # # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the data:\\n\"\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, df in enumerate(information):\n",
    "#             if df_index == 0:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Customer Demand\\n\"\n",
    "#             elif df_index == 1:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Supply Capacity\\n\"\n",
    "#             elif df_index == 2:\n",
    "#                 example_data_description += f\"\\nDataFrame {df_index + 1} - Transportation Cost\\n\"\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 example_data_description += description + \"\\n\"\n",
    "\n",
    "#         # 构建 problem_description 和 label\n",
    "#         problem_description0 = problem_description = \"\"\"Amazon has two distribution centers that need to supply essential goods daily to several customer groups. Each distribution center has a daily supply limit, with capacity data provided in “supply_capacity.csv.” Each customer group has a daily demand for these goods, with demand data detailed in “customer_demands.csv.” The transportation cost per unit of goods from each Amazon distribution center to each customer group is recorded in “transportation_costs.csv.” The objective is to determine the quantity of goods to be transported from each distribution center to each customer group, ensuring that demand is met while minimizing the total transportation cost. The decision variables  x_ij  represent the number of units of goods transported from Amazon distribution center  S_i  to customer group  C_j . For instance,  x_12  denotes the number of units of goods transported from Amazon distribution center  S_1  to customer group  C_2 . \"\"\"\n",
    "#         problem_description += example_data_description\n",
    "\n",
    "#         problem_description1 = 'Amazon has two distribution centers that need to supply essential goods daily to several customer groups. Each distribution center has a daily supply limit, with capacity data provided in “supply_capacity.csv.” Each customer group has a daily demand for these goods, with demand data detailed in “customer_demands.csv.” The transportation cost per unit of goods from each Amazon distribution center to each customer group is recorded in “transportation_costs.csv.” The objective is to determine the quantity of goods to be transported from each distribution center to each customer group, ensuring that demand is met while minimizing the total transportation cost. The decision variables  x_ij  represent the number of units of goods transported from Amazon distribution center  S_i  to customer group  C_j . For instance,  x_12  denotes the number of units of goods transported from Amazon distribution center  S_1  to customer group  C_2 . '\n",
    "\n",
    "\n",
    "#         with open('TP_example/transportation_problem2.txt', 'r', encoding='utf-8') as file:\n",
    "#             label = file.read()\n",
    "\n",
    "#         few_shot_examples = f\"\"\"\n",
    "\n",
    "#                 Question: {problem_description1}\n",
    "\n",
    "#                 Based on the above description and data, please formulate a linear programming model.\n",
    "\n",
    "#                 Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Particularly, I should fighure out which product and how many of them in total in the CSV should be considered.\n",
    "\n",
    "#                 Action: CSVQA\n",
    "\n",
    "#                 Action Input: \"Retrieve the capacity data and products data to formulate the linear programming model.\"\n",
    "\n",
    "#                 Observation: {example_data_description}\n",
    "\n",
    "#                 Thought: Now that I have the necessary data, I can construct the objective function and constraints. And I should generate the answer only using the format below. The expressions should not be simplified or abbreviated. I need to retrieve products similar to 'Nike x Olivia Kim' from the CSV file to formulate the linear programming model.\n",
    "\n",
    "#                 Final Answer: \n",
    "#                 {label}\n",
    "#                 \"\"\"\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "#             # 将文件名添加到描述中\n",
    "#             data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 #                    description = f\"Row {index + 1}: \"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "#         for line in data:\n",
    "#             st.text(line)  # 使用 Streamlit 显示内容\n",
    "#         # st.text(few_shot_examples)\n",
    "\n",
    "#         # df = pd.read_csv(tmp_file_path)\n",
    "#         #\n",
    "#         # # 创建嵌入和向量存储\n",
    "#         # data = []\n",
    "#         # for index, row in df.iterrows():\n",
    "#         #     content = f\"Product Name: {row['Product Name']}, Revenue: {row['Revenue']}, Demand: {row['Demand']}, Initial Inventory: {row['Initial Inventory']}\"\n",
    "#         #     data.append(content)\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 80})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "#                 Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         # 准备新的用户描述（不包含具体数据，让 Agent 自行检索）\n",
    "#         # user_description = 'A digital game store needs to decide which games to list on different platforms, considering that these games belong to various genres such as racing, sports, and others. Each platform has a limited memory capacity, with specific details provided in \"capacity.csv.\" The predefined value and memory requirement of each game are available in \"products.csv.\", with the column name being \"value\" and \"memory requirement\". The objective is to determine which genres and how many units of each game to list on each platform to maximize the total value of the games across all platforms, while ensuring that the total memory usage on each platform does not exceed its capacity. The decision variables  x_ij represent the number of units of games from genres j (e.g.,sports) to be listed on platform i. For example, x_12 denotes the number of units of a specific genre of games (e.g., sports) to be listed on Platform 1.'\n",
    "\n",
    "#         # 运行 Agent 并获取答案\n",
    "#         # answer = agent.invoke(user_description)\n",
    "#         # print(\"Answer:\", answer['output'])\n",
    "\n",
    "#         memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "#         #    agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, memory=memory, verbose=True)\n",
    "\n",
    "#         def query_data(query):\n",
    "#             response = agent.invoke(query)\n",
    "#             return response\n",
    "\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\",\n",
    "#                                             placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                             key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif selected_problem == \"SBLP Singapore Airline Use Case\":\n",
    "\n",
    "#         v1 = pd.read_csv('SBLP_example/AttractiveValues.csv', index_col=None)\n",
    "#         v2 = pd.read_csv('SBLP_example/adjusted_AttractiveValues.csv', index_col=None)\n",
    "#         v1 = v1.set_index(v1.columns[0])\n",
    "#         v2 = v2.set_index(v2.columns[0])\n",
    "#         v_br = v2 / v1\n",
    "#         v1 = v1.reset_index()\n",
    "#         v2 = v2.reset_index()\n",
    "\n",
    "#         information = pd.read_csv('SBLP_example/ticket_choices.csv')\n",
    "#         # 将示例数据转换为字符串，供 few_shot_examples 使用\n",
    "#         example_data_description = \"\\nHere is the flight data:\\n\"\n",
    "#         for index, row in information.iterrows():\n",
    "#             example_data_description += f\"{index + 1}: POS = {row['POS']}, departure_time t_{index + 1} = {row['Departure_Time_Flight1']}, Oneway_Product a_{index + 1} = {row['Oneway_Product']}, avg_pax d_{index + 1} = {row['avg_pax']}, avf_price p_{index + 1} = {row['avg_price']}, capacity c_{index + 1} = {row['capacity']} \\n\"\n",
    "\n",
    "\n",
    "#         def ticket_analysis(ticket_info: str):\n",
    "#             \"\"\"当你需要根据检索出的ticket信息，判断这些ticket的POS、departure_time区间、Oneway_Product，并从v1 和 v2中查找对应值时，请使用此工具。\"\"\"\n",
    "#             global v1, v2\n",
    "#             # Initialize lists to store results\n",
    "#             product_values = []\n",
    "#             no_purchase_values = []\n",
    "#             no_purchase_value_ratios = []\n",
    "\n",
    "#             # Split the ticket_info string into lines and filter out empty lines\n",
    "#             tickets = [line.strip() for line in ticket_info.strip().split('\\n') if line.strip()]\n",
    "\n",
    "#             for ticket in tickets:\n",
    "#                 # 提取 POS、departure_time、Oneway_Product\n",
    "#                 pos_match = re.search(r'POS\\s*=\\s*([A-Z])', ticket)\n",
    "#                 time_match = re.search(r'departure_time\\s*[t\\d]*\\s*=\\s*([\\d:]+)', ticket)\n",
    "#                 product_match = re.search(r'Oneway_product\\s*[a\\d]*\\s*=\\s*(\\w+)', ticket)\n",
    "\n",
    "#                 if not pos_match or not time_match or not product_match:\n",
    "#                     pos_match = re.search(r'POS\\s*=\\s*([A-Z])', ticket, re.IGNORECASE)\n",
    "#                     time_match = re.search(r'Departure\\s*Time\\s*=\\s*([\\d:]+)', ticket, re.IGNORECASE)\n",
    "#                     product_match = re.search(r'Product\\s*=\\s*(\\w+)', ticket, re.IGNORECASE)\n",
    "#                     pos_match = re.search(r'POS\\s*=\\s*([A-Z])', ticket)\n",
    "#                     time_match = re.search(r'Departure\\s*Time\\s*=\\s*([\\d:]+)', ticket)\n",
    "#                     product_match = re.search(r'Product\\s*=\\s*(\\w+)', ticket)\n",
    "\n",
    "#                 pos = pos_match.group(1)\n",
    "#                 departure_time_str = time_match.group(1)\n",
    "#                 product = product_match.group(1)\n",
    "#                 # Convert departure_time_str to a Python time object\n",
    "#                 departure_time = datetime.strptime(departure_time_str, '%H:%M').time()\n",
    "\n",
    "#                 # Define time intervals\n",
    "#                 intervals = {\n",
    "#                     '12pm~6pm': (time(12, 0), time(18, 0)),\n",
    "#                     '6pm~10pm': (time(18, 0), time(22, 0)),\n",
    "#                     '10pm~8am': (time(22, 0), time(8, 0)),\n",
    "#                     '8am~12pm': (time(8, 0), time(12, 0))\n",
    "#                 }\n",
    "\n",
    "#                 # Determine the time interval for the departure time\n",
    "#                 time_interval = None\n",
    "#                 for interval_name, (start_time, end_time) in intervals.items():\n",
    "#                     if start_time <= end_time:\n",
    "#                         if start_time <= departure_time < end_time:\n",
    "#                             time_interval = interval_name\n",
    "#                             break\n",
    "#                     else:\n",
    "#                         if departure_time >= start_time or departure_time < end_time:\n",
    "#                             time_interval = interval_name\n",
    "#                             break\n",
    "\n",
    "#                 # If no time interval is matched, skip this ticket\n",
    "#                 if time_interval is None:\n",
    "#                     continue\n",
    "\n",
    "#                 # Construct the column key based on Product and Time Interval\n",
    "#                 key = product + '*(' + time_interval + ')'\n",
    "\n",
    "#                 # Retrieve the value from v1\n",
    "#                 subset = v1[v1['POS'] == pos]\n",
    "#                 if key in subset.columns and not subset.empty:\n",
    "#                     value = subset[key].values[0]\n",
    "#                     product_values.append(value)\n",
    "#                 else:\n",
    "#                     print(f\"Warning: Key '{key}' not found in v1 for POS '{pos}'.\")\n",
    "\n",
    "#                 # Retrieve the value from v2\n",
    "#                 subset2 = v2[v2['POS'] == pos]\n",
    "#                 if key in subset2.columns and not subset2.empty:\n",
    "#                     value2 = subset2[key].values[0]\n",
    "#                     product_values.append(value2)\n",
    "#                 else:\n",
    "#                     print(f\"Warning: Key '{key}' not found in v2 for POS '{pos}'.\")\n",
    "\n",
    "#                 # Add no_purchase values for v1 (once per POS)\n",
    "#                 if 'no_purchase' in subset.columns and not subset.empty:\n",
    "#                     no_purchase_value = subset['no_purchase'].values[0]\n",
    "#                     if no_purchase_value not in no_purchase_values:\n",
    "#                         no_purchase_values.append(no_purchase_value)\n",
    "\n",
    "#                 # Add no_purchase value ratios for v2 (once per POS)\n",
    "#                 if 'no_purchase' in subset2.columns and not subset2.empty:\n",
    "#                     no_purchase_value_ratio = subset2['no_purchase'].values[0]\n",
    "#                     if no_purchase_value_ratio not in no_purchase_value_ratios:\n",
    "#                         no_purchase_value_ratios.append(no_purchase_value_ratio)\n",
    "\n",
    "#             # Combine all values into a single list\n",
    "#             result_values = product_values + no_purchase_values + no_purchase_value_ratios\n",
    "\n",
    "#             # Return the combined list of values\n",
    "#             return result_values\n",
    "\n",
    "\n",
    "#         coe_tool = Tool(\n",
    "#             name=\"coeff_retriever\",\n",
    "#             func=ticket_analysis,\n",
    "#             description=\"retriever the relevant coefficient from dataframe v1 and dataframe v2\"\n",
    "#         )\n",
    "\n",
    "#         # 加载实际的 CSV 文件\n",
    "#         data = []\n",
    "\n",
    "#         # 遍历每个 DataFrame 及其索引\n",
    "#         for df_index, (file_name, df) in enumerate(dfs):\n",
    "\n",
    "#             # data.append(f'\\nDataFrame {df_index + 1} - ticket_choices\\n')\n",
    "\n",
    "#             # 遍历 DataFrame 的每一行并生成描述\n",
    "#             for index, row in df.iterrows():\n",
    "#                 description = \"\"\n",
    "#                 description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "#                 data.append(description + \"\\n\")\n",
    "\n",
    "\n",
    "#         few_shot_examples = [\n",
    "#             f\"\"\"\n",
    "#             Question: For all flight ticket choices detailed in 'ticket_choice.csv',and the attraction values ratios are in the dataframe v2, and the attraction values are in the dataframe v1. write the sales-based linear formulation including objective functions, capacity constraints, balance constraints, scale constraints and nonnegative constraints for all flight ticket choices with POS A and departure time at 7:40.\n",
    "\n",
    "#             Thought: I need to retrieve relevant information of all the qualified ticket choices.\n",
    "\n",
    "#             Action: CSVQA\n",
    "\n",
    "#             Action Input: Retrieve the flight ticket choices information.\n",
    "\n",
    "#             Observation:\n",
    "#             {example_data_description}\n",
    "#             Of which the useful ticket choices are:\n",
    "#             POS = A, departure_time t2 = 7:40, Oneway_product a2 = Eco_flexi, avg_pax d2 = 5.351, avg_price p2 = 1630.291, capacity c2 = 79 ;\n",
    "#             POS = A, departure_time t3 = 7:40, Oneway_product a3 = Eco_lite, avg_pax d3 = 1.488, avg_price p3 = 483.509, capacity c_3 = 88 .\n",
    "\n",
    "#             Thought: Based on the previous observation, I now need to retrieve the attraction values from v1 and the attraction value ratios from v2 for the flight tickets and no_purchase choice based on the time range, POS, and Oneway_Product information using tools \"coeff_retriever\".\n",
    "\n",
    "#             Action: coeff_retriever\n",
    "\n",
    "#             Action Input:\n",
    "#             POS = A, departure_time t2 = 7:40, Oneway_product a2 = Eco_flexi, avg_pax d2 = 5.351, avg_price p2 = 1630.291, capacity c2 = 79 ;\n",
    "#             POS = A, departure_time t3 = 7:40, Oneway_product a3 = Eco_lite, avg_pax d3 = 1.488, avg_price p3 = 483.509, capacity c_3 = 88 .\n",
    "\n",
    "#             Observation:\n",
    "#             2.671, 0.740, 1.303, 0.361, 0.9, 0.249\n",
    "#             The attraction value and attraction value ratio retrieved for POS A, time 7:40, and Product Eco_flexi are 2.671 and 0.740,\n",
    "#             The attraction value and attraction value ratio retrieved for POS A, time 7:40, and Product Eco_lite are 1.303 and 0.361,\n",
    "#             The attraction value and attraction value ratio of no_purchase at POS A are 0.9 and 0.249;\n",
    "\n",
    "#             Final Answer:\n",
    "#             OBJECTIVE FUNCTION:\n",
    "#                 Max 1630.291 x_Af + 483.509 x_Al\n",
    "\n",
    "\n",
    "\n",
    "#             CONSTRAINTS:\n",
    "\n",
    "#             Capacity constraint: \n",
    "#                 x_Af <= 79\n",
    "#                 x_Al <= 88\n",
    "\n",
    "#             Balance constraint:\n",
    "#                 0.740 x_Af + 0.361 x_Al + 0.249 x_Ao = 5.351+1.488\n",
    "\n",
    "#             Scale constraint:\n",
    "#                 x_Af/2.61 <= x_Ao/0.9\n",
    "#                 x_Al/1.303 <= x_Ao/0.9\n",
    "\n",
    "#             Nonnegativity: \n",
    "#                 x_Af>=0\n",
    "#                 x_Al>=0\n",
    "#         \"\"\",\n",
    "#         f\"\"\"\n",
    "#         Question: For all flight ticket choices detailed in 'ticket_choice.csv',and the attraction values ratios are in the dataframe v2, and the attraction values are in the dataframe v1. write the sales-based linear formulation including objective functions, capacity constraints, balance constraints, scale constraints and nonnegative constraints for all flight ticket choices with POS C and departure time at 09:05 and all flight ticket choices with POS B and departure time at 11:20.\n",
    "\n",
    "\n",
    "#         Thought: I need to retrieve relevant information of all the qualified ticket choices.\n",
    "\n",
    "#         Action: CSVQA\n",
    "\n",
    "#         Action Input: Retrieve the flight ticket choices information.\n",
    "\n",
    "#         Observation:\n",
    "#         {example_data_description}\n",
    "#         Of which the useful ticket choices are:\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_flexi, Average Passengers = 1.423, Average Price = 1494.511, Capacity = 13\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_flexi, Average Passengers = 2.339, Average Price = 1439.146, Capacity = 118\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_lite, Average Passengers = 1.25, Average Price = 409.85, Capacity = 138\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_lite, Average Passengers = 1.077, Average Price = 483.846, Capacity = 77\n",
    "\n",
    "\n",
    "#         Thought:Based on the previous observation, I now need to retrieve the attraction values from v1 and the attraction value ratios from v2 for the flight tickets and no_purchase choice based on the time range, POS, and Oneway_Product information using tools \"coeff_retriever\".\n",
    "\n",
    "#         Action: coeff_retriever\n",
    "\n",
    "#         Action Input:\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_flexi, Average Passengers = 1.423, Average Price = 1494.511, Capacity = 13\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_flexi, Average Passengers = 2.339, Average Price = 1439.146, Capacity = 118\n",
    "#         POS = C, Departure Time = 09:05, Product = Eco_lite, Average Passengers = 1.25, Average Price = 409.85, Capacity = 138\n",
    "#         POS = B, Departure Time = 11:20, Product = Eco_lite, Average Passengers = 1.077, Average Price = 483.846, Capacity = 77 \n",
    "\n",
    "#         Observation: [1.916, 0.061, 1.864, 0.19, 1, 0.032, 1, 0.102, 1.2, 2.0, 0.038, 0.204]\n",
    "#         Thought:I now know the final answer\n",
    "\n",
    "#         Final Answer:\n",
    "\n",
    "#         OBJECTIVE FUNCTION:\n",
    "#         Max  483.846 x_Bl + 1439.146 x_Bf + 409.85 x_Cl + 1494.511 x_Cf\n",
    "\n",
    "#         CONSTRAINTS:\n",
    "\n",
    "#         Capacity constraint: \n",
    "#         x_Cf <= 13\n",
    "#         x_Bf <= 118\n",
    "#         x_Cl <= 138\n",
    "#         x_Bl <= 77\n",
    "\n",
    "#         Balance constraint:\n",
    "#         0.061 x_Cf + 0.032 x_Cl + 0.038 x_Co  = 1.423  + 1.25 \n",
    "#         0.19 x_Bf + 0.102 x_Bl + 0.204 x_Bo = 2.339 + 1.077\n",
    "\n",
    "#         Scale constraint:\n",
    "#         x_Cf/1.916 <= x_Co/1.2\n",
    "#         x_Bf/1.864 <= x_Bo/2.0\n",
    "#         x_Cl/1 <= x_Co/1.2\n",
    "#         x_Bl/1 <= x_Bo/2.0\n",
    "\n",
    "#         Nonnegativity: \n",
    "#         x_Cf>=0\n",
    "#         x_Bf>=0\n",
    "#         x_Cl>=0\n",
    "#         x_Bl>=0\n",
    "\n",
    "#         \"\"\"\n",
    "\n",
    "#         ]\n",
    "\n",
    "#         documents = [content for content in data]\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "#         vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "#         num_documents = len(documents)\n",
    "\n",
    "#         # 创建检索器和 RetrievalQA 链\n",
    "#         retriever = vectors.as_retriever(search_kwargs={'k': 20})\n",
    "#         llm = ChatOpenAI(temperature=0.0, model_name='gpt-4', openai_api_key=user_api_key)\n",
    "#         qa_chain = RetrievalQA.from_chain_type(\n",
    "#             llm=llm,\n",
    "#             chain_type=\"stuff\",\n",
    "#             retriever=retriever,\n",
    "#             return_source_documents=False,\n",
    "#         )\n",
    "\n",
    "#         # 创建工具（Tool）\n",
    "#         qa_tool = Tool(\n",
    "#             name=\"CSVQA\",\n",
    "#             func=qa_chain.run,\n",
    "#             description=\"Use this tool to answer questions based on the provided CSV data and retrieve product data similar to the input query..\"\n",
    "#         )\n",
    "\n",
    "#         # 更新 Agent 的提示（Prompt）\n",
    "#         prefix = f\"\"\"You are an assistant that generates linear programming models based on the user's description and provided CSV data.\n",
    "\n",
    "\n",
    "#                 {few_shot_examples}\n",
    "\n",
    "#                 When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "#                 \"\"\"\n",
    "\n",
    "#         suffix = \"\"\"\n",
    "\n",
    "#                 Begin!\n",
    "\n",
    "#                 User Description: {input}\n",
    "#                 {agent_scratchpad}\"\"\"\n",
    "\n",
    "#         # 初始化 Agent\n",
    "#         agent = initialize_agent(\n",
    "#             tools=[qa_tool, coe_tool],\n",
    "#             llm=llm,\n",
    "#             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#             agent_kwargs={\n",
    "#                 \"prefix\": prefix,\n",
    "#                 \"suffix\": suffix,\n",
    "#             },\n",
    "#             verbose=True,\n",
    "#             handle_parsing_errors=True,\n",
    "#         )\n",
    "\n",
    "#         def conversational_chat(query):\n",
    "\n",
    "#             result = agent.invoke(query)\n",
    "#             st.session_state['history'].append((query, result['output']))\n",
    "\n",
    "#             return result['output']\n",
    "\n",
    "\n",
    "#         if 'history' not in st.session_state:\n",
    "#             st.session_state['history'] = []\n",
    "\n",
    "#         if 'generated' not in st.session_state:\n",
    "#             #            st.session_state['generated'] = []\n",
    "#             st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" 🤗\"]\n",
    "\n",
    "#         if 'past' not in st.session_state:\n",
    "#             st.session_state['past'] = []\n",
    "#         #            st.session_state['past'] = [\"Hey ! 👋\"]\n",
    "\n",
    "#         # container for the chat history\n",
    "#         response_container = st.container()\n",
    "#         # container for the user's text input\n",
    "#         container = st.container()\n",
    "\n",
    "#         with container:\n",
    "#             with st.form(key='my_form', clear_on_submit=True):\n",
    "#                 user_input = st.text_area(\"Query:\",\n",
    "#                                             placeholder=f\"What {selected_problem} do you want to ask :)\",\n",
    "#                                             key='input', height=150)\n",
    "#                 submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "#             if submit_button and user_input:\n",
    "#                 # **修改2：在调用生成回答之前，先添加用户输入并显示**\n",
    "#                 st.session_state['past'].append(user_input)\n",
    "\n",
    "#                 # 在界面上立即显示用户的问题\n",
    "#                 with response_container:\n",
    "#                     message(user_input, is_user=True, key=str(len(st.session_state['past']) - 1) + '_user',\n",
    "#                             avatar_style=\"big-smile\")\n",
    "\n",
    "#                 # 显示一个进度条或加载动画\n",
    "#                 with st.spinner('Generating response...'):\n",
    "#                     output = conversational_chat(user_input)\n",
    "\n",
    "#                 st.session_state['generated'].append(output)\n",
    "\n",
    "#                 # 显示 AI 的回答\n",
    "#                 with response_container:\n",
    "#                     message(output, key=str(len(st.session_state['generated']) - 1), avatar_style=\"thumbs\")\n",
    "\n",
    "#                 # **修改3：在用户提交后，立即显示聊天记录**\n",
    "#             if st.session_state['generated']:\n",
    "#                 with response_container:\n",
    "#                     for i in range(len(st.session_state['generated'])):\n",
    "#                         # 已经在上面显示过最新的消息，这里避免重复显示\n",
    "#                         if i < len(st.session_state['past']) - 1:\n",
    "#                             message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user',\n",
    "#                                     avatar_style=\"big-smile\")\n",
    "#                             message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     else:\n",
    "#         st.write(f\"You choose {selected_problem}. This type of problem is under construction :(\")\n",
    "#     # streamlit run gptrag_2.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
